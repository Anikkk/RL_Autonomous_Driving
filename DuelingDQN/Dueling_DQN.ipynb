{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e953598",
   "metadata": {},
   "source": [
    "## Dueling DQN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b27537ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m[INFO] Environment: MetaDriveEnv\u001b[0m\n",
      "\u001b[38;20m[INFO] MetaDrive version: 0.4.3\u001b[0m\n",
      "\u001b[38;20m[INFO] Sensors: [lidar: Lidar(), side_detector: SideDetector(), lane_line_detector: LaneLineDetector(), main_camera: MainCamera(1200, 900), dashboard: DashBoard()]\u001b[0m\n",
      "\u001b[38;20m[INFO] Render Mode: onscreen\u001b[0m\n",
      "\u001b[38;20m[INFO] Horizon (Max steps per agent): 1000\u001b[0m\n",
      "\u001b[38;20m[INFO] Assets version: 0.4.3\u001b[0m\n",
      "\u001b[38;20m[INFO] Known Pipes: CocoaGraphicsPipe\u001b[0m\n",
      "\u001b[33;20m[WARNING] Since your screen is too small (1470, 956), we resize the window to (1147, 860). (engine_core.py:234)\u001b[0m\n",
      "\u001b[38;20m[INFO] Start Scenario Index: 42, Num Scenarios : 1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.29\n",
      "Intersection detected: Velocity=0.29, Min Distance=0.00\n",
      "Moving: Velocity=0.29\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.03, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.03, Min Distance=0.00\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.04\n",
      "Intersection detected: Velocity=0.04, Min Distance=0.00\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.02, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.02, Min Distance=0.00\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.02, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.02, Min Distance=0.00\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.01, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.01, Min Distance=0.00\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.27\n",
      "Intersection detected: Velocity=0.27, Min Distance=0.00\n",
      "Moving: Velocity=0.27\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.55\n",
      "Intersection detected: Velocity=0.55, Min Distance=0.00\n",
      "Moving: Velocity=0.55\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.50\n",
      "Intersection detected: Velocity=0.50, Min Distance=0.00\n",
      "Moving: Velocity=0.50\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.46, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.46, Min Distance=0.00\n",
      "Moving: Velocity=0.46\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.43, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.43, Min Distance=0.00\n",
      "Moving: Velocity=0.43\n",
      "Observation space: Box(-0.0, 1.0, (259,), float32)\n",
      "Action space: Discrete(5)\n",
      "Episode 1 started\n",
      "Initial observation shape: (259,)\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.03\n",
      "Intersection detected: Velocity=0.03, Min Distance=0.00\n",
      "Step 1: Action: 1, Reward: 1.2610, Total Reward: 1.2610, Epsilon: 1.000\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.31\n",
      "Intersection detected: Velocity=0.31, Min Distance=0.00\n",
      "Moving: Velocity=0.31\n",
      "Step 2: Action: 2, Reward: 0.9723, Total Reward: 2.2333, Epsilon: 0.999\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.55\n",
      "Intersection detected: Velocity=0.55, Min Distance=0.00\n",
      "Moving: Velocity=0.55\n",
      "Step 3: Action: 3, Reward: 0.9821, Total Reward: 3.2155, Epsilon: 0.999\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.77\n",
      "Intersection detected: Velocity=0.77, Min Distance=0.00\n",
      "Moving: Velocity=0.77\n",
      "Step 4: Action: 2, Reward: 0.9909, Total Reward: 4.2064, Epsilon: 0.998\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.05\n",
      "Intersection detected: Velocity=1.05, Min Distance=0.00\n",
      "Moving: Velocity=1.05\n",
      "Step 5: Action: 0, Reward: 1.0020, Total Reward: 5.2084, Epsilon: 0.998\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.27\n",
      "Intersection detected: Velocity=1.27, Min Distance=0.00\n",
      "Moving: Velocity=1.27\n",
      "Step 6: Action: 3, Reward: 1.0108, Total Reward: 6.2193, Epsilon: 0.997\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.40\n",
      "Intersection detected: Velocity=1.40, Min Distance=0.00\n",
      "Moving: Velocity=1.40\n",
      "Step 7: Action: 2, Reward: 1.0160, Total Reward: 7.2353, Epsilon: 0.997\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.68\n",
      "Intersection detected: Velocity=1.68, Min Distance=0.00\n",
      "Moving: Velocity=1.68\n",
      "Step 8: Action: 0, Reward: 1.0272, Total Reward: 8.2625, Epsilon: 0.996\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.64, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.64, Min Distance=0.00\n",
      "Moving: Velocity=1.64\n",
      "Step 9: Brake action applied! Velocity: 1.64\n",
      "Step 9: Action: 4, Reward: 1.5657, Total Reward: 9.8282, Epsilon: 0.996\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.84\n",
      "Intersection detected: Velocity=1.84, Min Distance=0.00\n",
      "Moving: Velocity=1.84\n",
      "Step 10: Action: 3, Reward: 1.0334, Total Reward: 10.8617, Epsilon: 0.995\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.78\n",
      "Intersection detected: Velocity=1.78, Min Distance=0.00\n",
      "Moving: Velocity=1.78\n",
      "Step 11: Action: 1, Reward: 1.0311, Total Reward: 11.8928, Epsilon: 0.995\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.94\n",
      "Intersection detected: Velocity=1.94, Min Distance=0.00\n",
      "Moving: Velocity=1.94\n",
      "Step 12: Action: 2, Reward: 1.0376, Total Reward: 12.9304, Epsilon: 0.994\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.88\n",
      "Intersection detected: Velocity=1.88, Min Distance=0.00\n",
      "Moving: Velocity=1.88\n",
      "Step 13: Action: 1, Reward: 1.0353, Total Reward: 13.9657, Epsilon: 0.994\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.85, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.85, Min Distance=0.00\n",
      "Moving: Velocity=1.85\n",
      "Step 14: Brake action applied! Velocity: 1.85\n",
      "Step 14: Action: 4, Reward: 1.5738, Total Reward: 15.5395, Epsilon: 0.993\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.13\n",
      "Intersection detected: Velocity=2.13, Min Distance=0.00\n",
      "Moving: Velocity=2.13\n",
      "Step 15: Action: 0, Reward: 1.3453, Total Reward: 16.8848, Epsilon: 0.993\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.42\n",
      "Intersection detected: Velocity=2.42, Min Distance=0.00\n",
      "Moving: Velocity=2.42\n",
      "Step 16: Action: 0, Reward: 1.3568, Total Reward: 18.2416, Epsilon: 0.992\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.56\n",
      "Intersection detected: Velocity=2.56, Min Distance=0.00\n",
      "Moving: Velocity=2.56\n",
      "Step 17: Action: 3, Reward: 1.0625, Total Reward: 19.3041, Epsilon: 0.992\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.59\n",
      "Intersection detected: Velocity=2.59, Min Distance=0.00\n",
      "Moving: Velocity=2.59\n",
      "Step 18: Action: 2, Reward: 1.0634, Total Reward: 20.3675, Epsilon: 0.991\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.70\n",
      "Intersection detected: Velocity=2.70, Min Distance=0.00\n",
      "Moving: Velocity=2.70\n",
      "Step 19: Action: 3, Reward: 1.0680, Total Reward: 21.4355, Epsilon: 0.991\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.94\n",
      "Intersection detected: Velocity=2.94, Min Distance=0.00\n",
      "Moving: Velocity=2.94\n",
      "Step 20: Action: 3, Reward: 1.3775, Total Reward: 22.8129, Epsilon: 0.990\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.93\n",
      "Intersection detected: Velocity=2.93, Min Distance=0.00\n",
      "Moving: Velocity=2.93\n",
      "Step 21: Action: 2, Reward: 1.0771, Total Reward: 23.8901, Epsilon: 0.990\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.89, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.89, Min Distance=0.00\n",
      "Moving: Velocity=2.89\n",
      "Step 22: Brake action applied! Velocity: 2.89\n",
      "Step 22: Action: 4, Reward: 1.3157, Total Reward: 25.2057, Epsilon: 0.989\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.18\n",
      "Intersection detected: Velocity=3.18, Min Distance=0.00\n",
      "Moving: Velocity=3.18\n",
      "Step 23: Action: 0, Reward: 1.3871, Total Reward: 26.5929, Epsilon: 0.989\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.14\n",
      "Intersection detected: Velocity=3.14, Min Distance=0.00\n",
      "Moving: Velocity=3.14\n",
      "Step 24: Action: 1, Reward: 1.3857, Total Reward: 27.9785, Epsilon: 0.988\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.24\n",
      "Intersection detected: Velocity=3.24, Min Distance=0.00\n",
      "Moving: Velocity=3.24\n",
      "Step 25: Action: 3, Reward: 1.0897, Total Reward: 29.0682, Epsilon: 0.988\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.18\n",
      "Intersection detected: Velocity=3.18, Min Distance=0.00\n",
      "Moving: Velocity=3.18\n",
      "Step 26: Action: 1, Reward: 1.0874, Total Reward: 30.1556, Epsilon: 0.987\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.32\n",
      "Intersection detected: Velocity=3.32, Min Distance=0.00\n",
      "Moving: Velocity=3.32\n",
      "Step 27: Action: 3, Reward: 1.0928, Total Reward: 31.2484, Epsilon: 0.987\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.26, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.26, Min Distance=0.00\n",
      "Moving: Velocity=3.26\n",
      "Step 28: Brake action applied! Velocity: 3.26\n",
      "Step 28: Action: 4, Reward: 1.3303, Total Reward: 32.5787, Epsilon: 0.986\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.39\n",
      "Intersection detected: Velocity=3.39, Min Distance=0.00\n",
      "Moving: Velocity=3.39\n",
      "Step 29: Action: 3, Reward: 1.0958, Total Reward: 33.6744, Epsilon: 0.986\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.63\n",
      "Intersection detected: Velocity=3.63, Min Distance=0.00\n",
      "Moving: Velocity=3.63\n",
      "Step 30: Action: 3, Reward: 1.4054, Total Reward: 35.0798, Epsilon: 0.985\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.83\n",
      "Intersection detected: Velocity=3.83, Min Distance=0.00\n",
      "Moving: Velocity=3.83\n",
      "Step 31: Action: 0, Reward: 1.1133, Total Reward: 36.1932, Epsilon: 0.985\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.79\n",
      "Intersection detected: Velocity=3.79, Min Distance=0.00\n",
      "Moving: Velocity=3.79\n",
      "Step 32: Action: 1, Reward: 1.4117, Total Reward: 37.6049, Epsilon: 0.984\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.08\n",
      "Intersection detected: Velocity=4.08, Min Distance=0.00\n",
      "Moving: Velocity=4.08\n",
      "Step 33: Action: 0, Reward: 1.4232, Total Reward: 39.0281, Epsilon: 0.984\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.37\n",
      "Intersection detected: Velocity=4.37, Min Distance=0.00\n",
      "Moving: Velocity=4.37\n",
      "Step 34: Action: 0, Reward: 1.4347, Total Reward: 40.4628, Epsilon: 0.983\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.65\n",
      "Intersection detected: Velocity=4.65, Min Distance=0.00\n",
      "Moving: Velocity=4.65\n",
      "Step 35: Action: 0, Reward: 1.4462, Total Reward: 41.9089, Epsilon: 0.983\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.71\n",
      "Intersection detected: Velocity=4.71, Min Distance=0.00\n",
      "Moving: Velocity=4.71\n",
      "Step 36: Action: 3, Reward: 1.1484, Total Reward: 43.0574, Epsilon: 0.982\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.66, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.66, Min Distance=0.00\n",
      "Moving: Velocity=4.66\n",
      "Step 37: Brake action applied! Velocity: 4.66\n",
      "Step 37: Action: 4, Reward: 1.3866, Total Reward: 44.4439, Epsilon: 0.982\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.70\n",
      "Intersection detected: Velocity=4.70, Min Distance=0.00\n",
      "Moving: Velocity=4.70\n",
      "Step 38: Action: 2, Reward: 1.1479, Total Reward: 45.5918, Epsilon: 0.981\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.65\n",
      "Intersection detected: Velocity=4.65, Min Distance=0.00\n",
      "Moving: Velocity=4.65\n",
      "Step 39: Action: 1, Reward: 1.1460, Total Reward: 46.7378, Epsilon: 0.981\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.69\n",
      "Intersection detected: Velocity=4.69, Min Distance=0.00\n",
      "Moving: Velocity=4.69\n",
      "Step 40: Action: 3, Reward: 1.1475, Total Reward: 47.8853, Epsilon: 0.980\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.64\n",
      "Intersection detected: Velocity=4.64, Min Distance=0.00\n",
      "Moving: Velocity=4.64\n",
      "Step 41: Action: 1, Reward: 1.1456, Total Reward: 49.0309, Epsilon: 0.980\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.60, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.60, Min Distance=0.00\n",
      "Moving: Velocity=4.60\n",
      "Step 42: Brake action applied! Velocity: 4.60\n",
      "Step 42: Action: 4, Reward: 1.6842, Total Reward: 50.7151, Epsilon: 0.979\n",
      "Q-values: [-0.03274219  0.04290808  0.00499135  0.04045045  0.14902599]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.57, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.57, Min Distance=0.00\n",
      "Moving: Velocity=4.57\n",
      "Step 43: Brake action applied! Velocity: 4.57\n",
      "Step 43: Action: 4, Reward: 1.6827, Total Reward: 52.3978, Epsilon: 0.979\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.85\n",
      "Intersection detected: Velocity=4.85, Min Distance=0.00\n",
      "Moving: Velocity=4.85\n",
      "Step 44: Action: 0, Reward: 1.4542, Total Reward: 53.8520, Epsilon: 0.978\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.82, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.82, Min Distance=0.00\n",
      "Moving: Velocity=4.82\n",
      "Step 45: Brake action applied! Velocity: 4.82\n",
      "Step 45: Action: 4, Reward: 1.6927, Total Reward: 55.5447, Epsilon: 0.978\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.87\n",
      "Intersection detected: Velocity=4.87, Min Distance=0.00\n",
      "Moving: Velocity=4.87\n",
      "Step 46: Action: 3, Reward: 1.1547, Total Reward: 56.6994, Epsilon: 0.977\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.98\n",
      "Intersection detected: Velocity=4.98, Min Distance=0.00\n",
      "Moving: Velocity=4.98\n",
      "Step 47: Action: 3, Reward: 1.4593, Total Reward: 58.1588, Epsilon: 0.977\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.92\n",
      "Intersection detected: Velocity=4.92, Min Distance=0.00\n",
      "Moving: Velocity=4.92\n",
      "Step 48: Action: 1, Reward: 1.1568, Total Reward: 59.3156, Epsilon: 0.976\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.00\n",
      "Intersection detected: Velocity=5.00, Min Distance=0.00\n",
      "Moving: Velocity=5.00\n",
      "Step 49: Action: 3, Reward: 1.1601, Total Reward: 60.4757, Epsilon: 0.976\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.17\n",
      "Intersection detected: Velocity=5.17, Min Distance=0.00\n",
      "Off-road detected: Penalty applied\n",
      "Moving: Velocity=5.17\n",
      "Step 50: Action: 3, Reward: -1.4330, Total Reward: 59.0426, Epsilon: 0.975\n",
      "Episode 1 ended early: Terminated=True, Truncated=False\n",
      "Episode 1 completed. Total Reward: 59.0426\n",
      "Target network updated\n",
      "Episode 2 started\n",
      "Initial observation shape: (259,)\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.28\n",
      "Intersection detected: Velocity=0.28, Min Distance=0.00\n",
      "Moving: Velocity=0.28\n",
      "Step 1: Action: 2, Reward: 0.9712, Total Reward: 0.9712, Epsilon: 0.975\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.56\n",
      "Intersection detected: Velocity=0.56, Min Distance=0.00\n",
      "Moving: Velocity=0.56\n",
      "Step 2: Action: 0, Reward: 0.9826, Total Reward: 1.9538, Epsilon: 0.974\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.53\n",
      "Intersection detected: Velocity=0.53, Min Distance=0.00\n",
      "Moving: Velocity=0.53\n",
      "Step 3: Action: 1, Reward: 1.2811, Total Reward: 3.2350, Epsilon: 0.974\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.78\n",
      "Intersection detected: Velocity=0.78, Min Distance=0.00\n",
      "Moving: Velocity=0.78\n",
      "Step 4: Action: 3, Reward: 0.9912, Total Reward: 4.2262, Epsilon: 0.973\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.06\n",
      "Intersection detected: Velocity=1.06, Min Distance=0.00\n",
      "Moving: Velocity=1.06\n",
      "Step 5: Action: 0, Reward: 1.0022, Total Reward: 5.2284, Epsilon: 0.973\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.29\n",
      "Intersection detected: Velocity=1.29, Min Distance=0.00\n",
      "Moving: Velocity=1.29\n",
      "Step 6: Action: 3, Reward: 1.0117, Total Reward: 6.2401, Epsilon: 0.972\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.56\n",
      "Intersection detected: Velocity=1.56, Min Distance=0.00\n",
      "Moving: Velocity=1.56\n",
      "Step 7: Action: 3, Reward: 1.3225, Total Reward: 7.5626, Epsilon: 0.972\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.63\n",
      "Intersection detected: Velocity=1.63, Min Distance=0.00\n",
      "Moving: Velocity=1.63\n",
      "Step 8: Action: 2, Reward: 1.0251, Total Reward: 8.5877, Epsilon: 0.971\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.59, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.59, Min Distance=0.00\n",
      "Moving: Velocity=1.59\n",
      "Step 9: Brake action applied! Velocity: 1.59\n",
      "Step 9: Action: 4, Reward: 1.2635, Total Reward: 9.8512, Epsilon: 0.971\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.55\n",
      "Intersection detected: Velocity=1.55, Min Distance=0.00\n",
      "Moving: Velocity=1.55\n",
      "Step 10: Action: 1, Reward: 1.3220, Total Reward: 11.1732, Epsilon: 0.970\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.51, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.51, Min Distance=0.00\n",
      "Moving: Velocity=1.51\n",
      "Step 11: Brake action applied! Velocity: 1.51\n",
      "Step 11: Action: 4, Reward: 1.5606, Total Reward: 12.7338, Epsilon: 0.970\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.48\n",
      "Intersection detected: Velocity=1.48, Min Distance=0.00\n",
      "Moving: Velocity=1.48\n",
      "Step 12: Action: 1, Reward: 1.3191, Total Reward: 14.0529, Epsilon: 0.969\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.76\n",
      "Intersection detected: Velocity=1.76, Min Distance=0.00\n",
      "Moving: Velocity=1.76\n",
      "Step 13: Action: 0, Reward: 1.3306, Total Reward: 15.3835, Epsilon: 0.969\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.73\n",
      "Intersection detected: Velocity=1.73, Min Distance=0.00\n",
      "Moving: Velocity=1.73\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 1.8162\n",
      "Step 14: Action: 1, Reward: 1.3291, Total Reward: 16.7126, Epsilon: 0.968\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.69, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.69, Min Distance=0.00\n",
      "Moving: Velocity=1.69\n",
      "Step 15: Brake action applied! Velocity: 1.69\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 1.7250\n",
      "Step 15: Action: 4, Reward: 1.5677, Total Reward: 18.2802, Epsilon: 0.968\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.98\n",
      "Intersection detected: Velocity=1.98, Min Distance=0.00\n",
      "Moving: Velocity=1.98\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 1.6599\n",
      "Step 16: Action: 0, Reward: 1.3391, Total Reward: 19.6194, Epsilon: 0.967\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.94\n",
      "Intersection detected: Velocity=1.94, Min Distance=0.00\n",
      "Moving: Velocity=1.94\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 1.5541\n",
      "Step 17: Action: 1, Reward: 1.3377, Total Reward: 20.9571, Epsilon: 0.967\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.12\n",
      "Intersection detected: Velocity=2.12, Min Distance=0.00\n",
      "Moving: Velocity=2.12\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 1.4953\n",
      "Step 18: Action: 3, Reward: 1.0448, Total Reward: 22.0019, Epsilon: 0.966\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.06, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.06, Min Distance=0.00\n",
      "Moving: Velocity=2.06\n",
      "Step 19: Brake action applied! Velocity: 2.06\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 1.3763\n",
      "Step 19: Action: 4, Reward: 1.2825, Total Reward: 23.2844, Epsilon: 0.966\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.26\n",
      "Intersection detected: Velocity=2.26, Min Distance=0.00\n",
      "Moving: Velocity=2.26\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 1.2909\n",
      "Step 20: Action: 3, Reward: 1.0504, Total Reward: 24.3348, Epsilon: 0.965\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.28\n",
      "Intersection detected: Velocity=2.28, Min Distance=0.00\n",
      "Moving: Velocity=2.28\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 1.1983\n",
      "Step 21: Action: 2, Reward: 1.0513, Total Reward: 25.3861, Epsilon: 0.965\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.46\n",
      "Intersection detected: Velocity=2.46, Min Distance=0.00\n",
      "Moving: Velocity=2.46\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 1.0941\n",
      "Step 22: Action: 2, Reward: 1.3583, Total Reward: 26.7445, Epsilon: 0.964\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.39, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.39, Min Distance=0.00\n",
      "Moving: Velocity=2.39\n",
      "Step 23: Brake action applied! Velocity: 2.39\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 1.0068\n",
      "Step 23: Action: 4, Reward: 1.2958, Total Reward: 28.0402, Epsilon: 0.964\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.36\n",
      "Intersection detected: Velocity=2.36, Min Distance=0.00\n",
      "Moving: Velocity=2.36\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.8698\n",
      "Step 24: Action: 1, Reward: 1.3542, Total Reward: 29.3944, Epsilon: 0.963\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.32, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.32, Min Distance=0.00\n",
      "Moving: Velocity=2.32\n",
      "Step 25: Brake action applied! Velocity: 2.32\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.8092\n",
      "Step 25: Action: 4, Reward: 1.5928, Total Reward: 30.9872, Epsilon: 0.963\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.47\n",
      "Intersection detected: Velocity=2.47, Min Distance=0.00\n",
      "Moving: Velocity=2.47\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6754\n",
      "Step 26: Action: 2, Reward: 1.0589, Total Reward: 32.0461, Epsilon: 0.962\n",
      "Q-values: [0.73954284 0.5860486  0.47727942 0.7377824  0.81373787]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.41, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.41, Min Distance=0.00\n",
      "Moving: Velocity=2.41\n",
      "Step 27: Brake action applied! Velocity: 2.41\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.5672\n",
      "Step 27: Action: 4, Reward: 1.2965, Total Reward: 33.3426, Epsilon: 0.962\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.59\n",
      "Intersection detected: Velocity=2.59, Min Distance=0.00\n",
      "Moving: Velocity=2.59\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.4851\n",
      "Step 28: Action: 2, Reward: 1.0637, Total Reward: 34.4063, Epsilon: 0.961\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.84\n",
      "Intersection detected: Velocity=2.84, Min Distance=0.00\n",
      "Moving: Velocity=2.84\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3957\n",
      "Step 29: Action: 0, Reward: 1.0738, Total Reward: 35.4801, Epsilon: 0.961\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.81\n",
      "Intersection detected: Velocity=2.81, Min Distance=0.00\n",
      "Moving: Velocity=2.81\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2429\n",
      "Step 30: Action: 1, Reward: 1.3723, Total Reward: 36.8524, Epsilon: 0.960\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.77\n",
      "Intersection detected: Velocity=2.77, Min Distance=0.00\n",
      "Moving: Velocity=2.77\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1653\n",
      "Step 31: Action: 1, Reward: 1.3708, Total Reward: 38.2233, Epsilon: 0.960\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.73\n",
      "Intersection detected: Velocity=2.73, Min Distance=0.00\n",
      "Moving: Velocity=2.73\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2130\n",
      "Step 32: Action: 1, Reward: 1.3694, Total Reward: 39.5926, Epsilon: 0.959\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.70, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.70, Min Distance=0.00\n",
      "Moving: Velocity=2.70\n",
      "Step 33: Brake action applied! Velocity: 2.70\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1751\n",
      "Step 33: Action: 4, Reward: 1.6079, Total Reward: 41.2006, Epsilon: 0.959\n",
      "Q-values: [1.4177482 1.2438093 0.9089786 1.3069775 1.6199793]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.66, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.66, Min Distance=0.00\n",
      "Moving: Velocity=2.66\n",
      "Step 34: Brake action applied! Velocity: 2.66\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1604\n",
      "Step 34: Action: 4, Reward: 1.6065, Total Reward: 42.8071, Epsilon: 0.958\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.79\n",
      "Intersection detected: Velocity=2.79, Min Distance=0.00\n",
      "Moving: Velocity=2.79\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1607\n",
      "Step 35: Action: 2, Reward: 1.0717, Total Reward: 43.8787, Epsilon: 0.958\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.03\n",
      "Intersection detected: Velocity=3.03, Min Distance=0.00\n",
      "Moving: Velocity=3.03\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0395\n",
      "Step 36: Action: 2, Reward: 1.3814, Total Reward: 45.2601, Epsilon: 0.957\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.02\n",
      "Intersection detected: Velocity=3.02, Min Distance=0.00\n",
      "Moving: Velocity=3.02\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1867\n",
      "Step 37: Action: 3, Reward: 1.0810, Total Reward: 46.3411, Epsilon: 0.957\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.99\n",
      "Intersection detected: Velocity=2.99, Min Distance=0.00\n",
      "Moving: Velocity=2.99\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2178\n",
      "Step 38: Action: 1, Reward: 1.0795, Total Reward: 47.4205, Epsilon: 0.956\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.09\n",
      "Intersection detected: Velocity=3.09, Min Distance=0.00\n",
      "Moving: Velocity=3.09\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2473\n",
      "Step 39: Action: 3, Reward: 1.0836, Total Reward: 48.5041, Epsilon: 0.956\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.32\n",
      "Intersection detected: Velocity=3.32, Min Distance=0.00\n",
      "Moving: Velocity=3.32\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1117\n",
      "Step 40: Action: 3, Reward: 1.3929, Total Reward: 49.8970, Epsilon: 0.955\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.25, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.25, Min Distance=0.00\n",
      "Moving: Velocity=3.25\n",
      "Step 41: Brake action applied! Velocity: 3.25\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2385\n",
      "Step 41: Action: 4, Reward: 1.3299, Total Reward: 51.2269, Epsilon: 0.955\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.53\n",
      "Intersection detected: Velocity=3.53, Min Distance=0.00\n",
      "Moving: Velocity=3.53\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2341\n",
      "Step 42: Action: 0, Reward: 1.4012, Total Reward: 52.6281, Epsilon: 0.954\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.49, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.49, Min Distance=0.00\n",
      "Moving: Velocity=3.49\n",
      "Step 43: Brake action applied! Velocity: 3.49\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2126\n",
      "Step 43: Action: 4, Reward: 1.6398, Total Reward: 54.2679, Epsilon: 0.954\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.58\n",
      "Intersection detected: Velocity=3.58, Min Distance=0.00\n",
      "Moving: Velocity=3.58\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1800\n",
      "Step 44: Action: 3, Reward: 1.1031, Total Reward: 55.3709, Epsilon: 0.953\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.58\n",
      "Intersection detected: Velocity=3.58, Min Distance=0.00\n",
      "Moving: Velocity=3.58\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0578\n",
      "Step 45: Action: 2, Reward: 1.1033, Total Reward: 56.4742, Epsilon: 0.953\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.87\n",
      "Intersection detected: Velocity=3.87, Min Distance=0.00\n",
      "Moving: Velocity=3.87\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0407\n",
      "Step 46: Action: 0, Reward: 1.1148, Total Reward: 57.5890, Epsilon: 0.952\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.83\n",
      "Intersection detected: Velocity=3.83, Min Distance=0.00\n",
      "Moving: Velocity=3.83\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1387\n",
      "Step 47: Action: 1, Reward: 1.4133, Total Reward: 59.0023, Epsilon: 0.952\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.80\n",
      "Intersection detected: Velocity=3.80, Min Distance=0.00\n",
      "Moving: Velocity=3.80\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0304\n",
      "Step 48: Action: 1, Reward: 1.4119, Total Reward: 60.4142, Epsilon: 0.951\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.87\n",
      "Intersection detected: Velocity=3.87, Min Distance=0.00\n",
      "Moving: Velocity=3.87\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1306\n",
      "Step 49: Action: 3, Reward: 1.1147, Total Reward: 61.5289, Epsilon: 0.951\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.81\n",
      "Intersection detected: Velocity=3.81, Min Distance=0.00\n",
      "Moving: Velocity=3.81\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1357\n",
      "Step 50: Action: 1, Reward: 1.1126, Total Reward: 62.6414, Epsilon: 0.951\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.91\n",
      "Intersection detected: Velocity=3.91, Min Distance=0.00\n",
      "Moving: Velocity=3.91\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0439\n",
      "Step 51: Action: 3, Reward: 1.1165, Total Reward: 63.7579, Epsilon: 0.950\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.13\n",
      "Intersection detected: Velocity=4.13, Min Distance=0.00\n",
      "Moving: Velocity=4.13\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1538\n",
      "Step 52: Action: 3, Reward: 1.4250, Total Reward: 65.1829, Epsilon: 0.950\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.05\n",
      "Intersection detected: Velocity=4.05, Min Distance=0.00\n",
      "Moving: Velocity=4.05\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1610\n",
      "Step 53: Action: 1, Reward: 1.1222, Total Reward: 66.3051, Epsilon: 0.949\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.19\n",
      "Intersection detected: Velocity=4.19, Min Distance=0.00\n",
      "Moving: Velocity=4.19\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1426\n",
      "Step 54: Action: 3, Reward: 1.1276, Total Reward: 67.4327, Epsilon: 0.949\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.42\n",
      "Intersection detected: Velocity=4.42, Min Distance=0.00\n",
      "Moving: Velocity=4.42\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1419\n",
      "Step 55: Action: 0, Reward: 1.1367, Total Reward: 68.5694, Epsilon: 0.948\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.51\n",
      "Intersection detected: Velocity=4.51, Min Distance=0.00\n",
      "Moving: Velocity=4.51\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1436\n",
      "Step 56: Action: 3, Reward: 1.1403, Total Reward: 69.7096, Epsilon: 0.948\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.76\n",
      "Intersection detected: Velocity=4.76, Min Distance=0.00\n",
      "Moving: Velocity=4.76\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0538\n",
      "Step 57: Action: 0, Reward: 1.1502, Total Reward: 70.8599, Epsilon: 0.947\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.83\n",
      "Intersection detected: Velocity=4.83, Min Distance=0.00\n",
      "Moving: Velocity=4.83\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1479\n",
      "Step 58: Action: 3, Reward: 1.1531, Total Reward: 72.0130, Epsilon: 0.947\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.09\n",
      "Intersection detected: Velocity=5.09, Min Distance=0.00\n",
      "Moving: Velocity=5.09\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1384\n",
      "Step 59: Action: 0, Reward: 1.1635, Total Reward: 73.1764, Epsilon: 0.946\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.37\n",
      "Intersection detected: Velocity=5.37, Min Distance=0.00\n",
      "Moving: Velocity=5.37\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1305\n",
      "Step 60: Action: 0, Reward: 1.4749, Total Reward: 74.6514, Epsilon: 0.946\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.34, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.34, Min Distance=0.00\n",
      "Moving: Velocity=5.34\n",
      "Step 61: Brake action applied! Velocity: 5.34\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1393\n",
      "Step 61: Action: 4, Reward: 1.7135, Total Reward: 76.3648, Epsilon: 0.945\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.38\n",
      "Intersection detected: Velocity=5.38, Min Distance=0.00\n",
      "Moving: Velocity=5.38\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0313\n",
      "Step 62: Action: 2, Reward: 1.1750, Total Reward: 77.5399, Epsilon: 0.945\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.33\n",
      "Intersection detected: Velocity=5.33, Min Distance=0.00\n",
      "Moving: Velocity=5.33\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1350\n",
      "Step 63: Action: 1, Reward: 1.1732, Total Reward: 78.7130, Epsilon: 0.944\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.62\n",
      "Intersection detected: Velocity=5.62, Min Distance=0.00\n",
      "Moving: Velocity=5.62\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1321\n",
      "Step 64: Action: 0, Reward: 1.4846, Total Reward: 80.1976, Epsilon: 0.944\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.66\n",
      "Intersection detected: Velocity=5.66, Min Distance=0.00\n",
      "Moving: Velocity=5.66\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0229\n",
      "Step 65: Action: 3, Reward: 1.1862, Total Reward: 81.3838, Epsilon: 0.943\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.61\n",
      "Intersection detected: Velocity=5.61, Min Distance=0.00\n",
      "Moving: Velocity=5.61\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0197\n",
      "Step 66: Action: 1, Reward: 1.1844, Total Reward: 82.5683, Epsilon: 0.943\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.57\n",
      "Intersection detected: Velocity=5.57, Min Distance=0.00\n",
      "Moving: Velocity=5.57\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1381\n",
      "Step 67: Action: 1, Reward: 1.4830, Total Reward: 84.0512, Epsilon: 0.942\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.54\n",
      "Intersection detected: Velocity=5.54, Min Distance=0.00\n",
      "Moving: Velocity=5.54\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1352\n",
      "Step 68: Action: 1, Reward: 1.4815, Total Reward: 85.5328, Epsilon: 0.942\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.57\n",
      "Intersection detected: Velocity=5.57, Min Distance=0.00\n",
      "Moving: Velocity=5.57\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1366\n",
      "Step 69: Action: 3, Reward: 1.1829, Total Reward: 86.7157, Epsilon: 0.941\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.53, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.53, Min Distance=0.00\n",
      "Moving: Velocity=5.53\n",
      "Step 70: Brake action applied! Velocity: 5.53\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0190\n",
      "Step 70: Action: 4, Reward: 1.4211, Total Reward: 88.1368, Epsilon: 0.941\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.55\n",
      "Intersection detected: Velocity=5.55, Min Distance=0.00\n",
      "Moving: Velocity=5.55\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1396\n",
      "Step 71: Action: 2, Reward: 1.1821, Total Reward: 89.3189, Epsilon: 0.940\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.51\n",
      "Intersection detected: Velocity=5.51, Min Distance=0.00\n",
      "Moving: Velocity=5.51\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1368\n",
      "Step 72: Action: 1, Reward: 1.1804, Total Reward: 90.4992, Epsilon: 0.940\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.80\n",
      "Intersection detected: Velocity=5.80, Min Distance=0.00\n",
      "Moving: Velocity=5.80\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0230\n",
      "Step 73: Action: 0, Reward: 1.4918, Total Reward: 91.9910, Epsilon: 0.939\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.76, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.76, Min Distance=0.00\n",
      "Off-road detected: Penalty applied\n",
      "Moving: Velocity=5.76\n",
      "Step 74: Brake action applied! Velocity: 5.76\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1344\n",
      "Step 74: Action: 4, Reward: -1.1696, Total Reward: 90.8214, Epsilon: 0.939\n",
      "Episode 2 ended early: Terminated=True, Truncated=False\n",
      "Episode 2 completed. Total Reward: 90.8214\n",
      "Episode 3 started\n",
      "Initial observation shape: (259,)\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.29\n",
      "Intersection detected: Velocity=0.29, Min Distance=0.00\n",
      "Moving: Velocity=0.29\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0243\n",
      "Step 1: Action: 0, Reward: 1.2715, Total Reward: 1.2715, Epsilon: 0.938\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.57\n",
      "Intersection detected: Velocity=0.57, Min Distance=0.00\n",
      "Moving: Velocity=0.57\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1499\n",
      "Step 2: Action: 0, Reward: 1.2830, Total Reward: 2.5544, Epsilon: 0.938\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.54, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.54, Min Distance=0.00\n",
      "Moving: Velocity=0.54\n",
      "Step 3: Brake action applied! Velocity: 0.54\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1480\n",
      "Step 3: Action: 4, Reward: 1.5215, Total Reward: 4.0759, Epsilon: 0.937\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.79\n",
      "Intersection detected: Velocity=0.79, Min Distance=0.00\n",
      "Moving: Velocity=0.79\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0233\n",
      "Step 4: Action: 3, Reward: 0.9916, Total Reward: 5.0676, Epsilon: 0.937\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.74\n",
      "Intersection detected: Velocity=0.74, Min Distance=0.00\n",
      "Moving: Velocity=0.74\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1273\n",
      "Step 5: Action: 1, Reward: 0.9897, Total Reward: 6.0573, Epsilon: 0.936\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.71, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.71, Min Distance=0.00\n",
      "Moving: Velocity=0.71\n",
      "Step 6: Brake action applied! Velocity: 0.71\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2543\n",
      "Step 6: Action: 4, Reward: 1.5282, Total Reward: 7.5855, Epsilon: 0.936\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.67\n",
      "Intersection detected: Velocity=0.67, Min Distance=0.00\n",
      "Moving: Velocity=0.67\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0265\n",
      "Step 7: Action: 1, Reward: 1.2868, Total Reward: 8.8723, Epsilon: 0.935\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.92\n",
      "Intersection detected: Velocity=0.92, Min Distance=0.00\n",
      "Moving: Velocity=0.92\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0266\n",
      "Step 8: Action: 2, Reward: 0.9967, Total Reward: 9.8690, Epsilon: 0.935\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.87\n",
      "Intersection detected: Velocity=0.87, Min Distance=0.00\n",
      "Moving: Velocity=0.87\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1349\n",
      "Step 9: Action: 1, Reward: 0.9947, Total Reward: 10.8637, Epsilon: 0.934\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.83, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.83, Min Distance=0.00\n",
      "Moving: Velocity=0.83\n",
      "Step 10: Brake action applied! Velocity: 0.83\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2476\n",
      "Step 10: Action: 4, Reward: 1.5332, Total Reward: 12.3969, Epsilon: 0.934\n",
      "Q-values: [1.3641517 1.3726823 1.1936808 1.1902788 1.5488924]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.79, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.79, Min Distance=0.00\n",
      "Moving: Velocity=0.79\n",
      "Step 11: Brake action applied! Velocity: 0.79\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1382\n",
      "Step 11: Action: 4, Reward: 1.5318, Total Reward: 13.9287, Epsilon: 0.933\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.03\n",
      "Intersection detected: Velocity=1.03, Min Distance=0.00\n",
      "Moving: Velocity=1.03\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1372\n",
      "Step 12: Action: 2, Reward: 1.0014, Total Reward: 14.9301, Epsilon: 0.933\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.31\n",
      "Intersection detected: Velocity=1.31, Min Distance=0.00\n",
      "Moving: Velocity=1.31\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2414\n",
      "Step 13: Action: 0, Reward: 1.0123, Total Reward: 15.9424, Epsilon: 0.932\n",
      "Q-values: [1.3804386 1.3870556 1.2041471 1.189103  1.5446423]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.27, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.27, Min Distance=0.00\n",
      "Moving: Velocity=1.27\n",
      "Step 14: Brake action applied! Velocity: 1.27\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0261\n",
      "Step 14: Action: 4, Reward: 1.5508, Total Reward: 17.4932, Epsilon: 0.932\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.49\n",
      "Intersection detected: Velocity=1.49, Min Distance=0.00\n",
      "Moving: Velocity=1.49\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1463\n",
      "Step 15: Action: 2, Reward: 1.0196, Total Reward: 18.5129, Epsilon: 0.931\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.59\n",
      "Intersection detected: Velocity=1.59, Min Distance=0.00\n",
      "Moving: Velocity=1.59\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0244\n",
      "Step 16: Action: 3, Reward: 1.0237, Total Reward: 19.5366, Epsilon: 0.931\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.55, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.55, Min Distance=0.00\n",
      "Moving: Velocity=1.55\n",
      "Step 17: Brake action applied! Velocity: 1.55\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1317\n",
      "Step 17: Action: 4, Reward: 1.2619, Total Reward: 20.7985, Epsilon: 0.930\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.73\n",
      "Intersection detected: Velocity=1.73, Min Distance=0.00\n",
      "Moving: Velocity=1.73\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1361\n",
      "Step 18: Action: 2, Reward: 1.0294, Total Reward: 21.8278, Epsilon: 0.930\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.68\n",
      "Intersection detected: Velocity=1.68, Min Distance=0.00\n",
      "Moving: Velocity=1.68\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1425\n",
      "Step 19: Action: 1, Reward: 1.0272, Total Reward: 22.8551, Epsilon: 0.929\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.85\n",
      "Intersection detected: Velocity=1.85, Min Distance=0.00\n",
      "Moving: Velocity=1.85\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0205\n",
      "Step 20: Action: 3, Reward: 1.0340, Total Reward: 23.8891, Epsilon: 0.929\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.12\n",
      "Intersection detected: Velocity=2.12, Min Distance=0.00\n",
      "Moving: Velocity=2.12\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0240\n",
      "Step 21: Action: 0, Reward: 1.0447, Total Reward: 24.9338, Epsilon: 0.928\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.08, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.08, Min Distance=0.00\n",
      "Moving: Velocity=2.08\n",
      "Step 22: Brake action applied! Velocity: 2.08\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1338\n",
      "Step 22: Action: 4, Reward: 1.5832, Total Reward: 26.5170, Epsilon: 0.928\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.26\n",
      "Intersection detected: Velocity=2.26, Min Distance=0.00\n",
      "Moving: Velocity=2.26\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1363\n",
      "Step 23: Action: 3, Reward: 1.0502, Total Reward: 27.5672, Epsilon: 0.927\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.20, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.20, Min Distance=0.00\n",
      "Moving: Velocity=2.20\n",
      "Step 24: Brake action applied! Velocity: 2.20\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2482\n",
      "Step 24: Action: 4, Reward: 1.2879, Total Reward: 28.8550, Epsilon: 0.927\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.33\n",
      "Intersection detected: Velocity=2.33, Min Distance=0.00\n",
      "Moving: Velocity=2.33\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2463\n",
      "Step 25: Action: 2, Reward: 1.0530, Total Reward: 29.9081, Epsilon: 0.926\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.27, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.27, Min Distance=0.00\n",
      "Moving: Velocity=2.27\n",
      "Step 26: Brake action applied! Velocity: 2.27\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0254\n",
      "Step 26: Action: 4, Reward: 1.2907, Total Reward: 31.1988, Epsilon: 0.926\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.46\n",
      "Intersection detected: Velocity=2.46, Min Distance=0.00\n",
      "Moving: Velocity=2.46\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0230\n",
      "Step 27: Action: 2, Reward: 1.0582, Total Reward: 32.2570, Epsilon: 0.925\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.39, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.39, Min Distance=0.00\n",
      "Moving: Velocity=2.39\n",
      "Step 28: Brake action applied! Velocity: 2.39\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0181\n",
      "Step 28: Action: 4, Reward: 1.2957, Total Reward: 33.5527, Epsilon: 0.925\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.50\n",
      "Intersection detected: Velocity=2.50, Min Distance=0.00\n",
      "Moving: Velocity=2.50\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1377\n",
      "Step 29: Action: 3, Reward: 1.0601, Total Reward: 34.6128, Epsilon: 0.924\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.53\n",
      "Intersection detected: Velocity=2.53, Min Distance=0.00\n",
      "Moving: Velocity=2.53\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2438\n",
      "Step 30: Action: 2, Reward: 1.0613, Total Reward: 35.6741, Epsilon: 0.924\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.63\n",
      "Intersection detected: Velocity=2.63, Min Distance=0.00\n",
      "Moving: Velocity=2.63\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1297\n",
      "Step 31: Action: 3, Reward: 1.0654, Total Reward: 36.7395, Epsilon: 0.923\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.58\n",
      "Intersection detected: Velocity=2.58, Min Distance=0.00\n",
      "Moving: Velocity=2.58\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1296\n",
      "Step 32: Action: 1, Reward: 1.0633, Total Reward: 37.8027, Epsilon: 0.923\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.75\n",
      "Intersection detected: Velocity=2.75, Min Distance=0.00\n",
      "Moving: Velocity=2.75\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1257\n",
      "Step 33: Action: 3, Reward: 1.0698, Total Reward: 38.8725, Epsilon: 0.922\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.68\n",
      "Intersection detected: Velocity=2.68, Min Distance=0.00\n",
      "Moving: Velocity=2.68\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1319\n",
      "Step 34: Action: 1, Reward: 1.0673, Total Reward: 39.9398, Epsilon: 0.922\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.97\n",
      "Intersection detected: Velocity=2.97, Min Distance=0.00\n",
      "Moving: Velocity=2.97\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2425\n",
      "Step 35: Action: 0, Reward: 1.3787, Total Reward: 41.3185, Epsilon: 0.921\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.07\n",
      "Intersection detected: Velocity=3.07, Min Distance=0.00\n",
      "Moving: Velocity=3.07\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0230\n",
      "Step 36: Action: 2, Reward: 1.0827, Total Reward: 42.4012, Epsilon: 0.921\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.01\n",
      "Intersection detected: Velocity=3.01, Min Distance=0.00\n",
      "Moving: Velocity=3.01\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1289\n",
      "Step 37: Action: 1, Reward: 1.0805, Total Reward: 43.4817, Epsilon: 0.920\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.09\n",
      "Intersection detected: Velocity=3.09, Min Distance=0.00\n",
      "Moving: Velocity=3.09\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0293\n",
      "Step 38: Action: 3, Reward: 1.0836, Total Reward: 44.5653, Epsilon: 0.920\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.04\n",
      "Intersection detected: Velocity=3.04, Min Distance=0.00\n",
      "Moving: Velocity=3.04\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1405\n",
      "Step 39: Action: 1, Reward: 1.0815, Total Reward: 45.6468, Epsilon: 0.919\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.00\n",
      "Intersection detected: Velocity=3.00, Min Distance=0.00\n",
      "Moving: Velocity=3.00\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2460\n",
      "Step 40: Action: 1, Reward: 1.3800, Total Reward: 47.0269, Epsilon: 0.919\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.10\n",
      "Intersection detected: Velocity=3.10, Min Distance=0.00\n",
      "Moving: Velocity=3.10\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1380\n",
      "Step 41: Action: 2, Reward: 1.0841, Total Reward: 48.1109, Epsilon: 0.918\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.11\n",
      "Intersection detected: Velocity=3.11, Min Distance=0.00\n",
      "Moving: Velocity=3.11\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0197\n",
      "Step 42: Action: 3, Reward: 1.0845, Total Reward: 49.1955, Epsilon: 0.918\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.08, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.08, Min Distance=0.00\n",
      "Moving: Velocity=3.08\n",
      "Step 43: Brake action applied! Velocity: 3.08\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1310\n",
      "Step 43: Action: 4, Reward: 1.3230, Total Reward: 50.5185, Epsilon: 0.917\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.04, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.04, Min Distance=0.00\n",
      "Moving: Velocity=3.04\n",
      "Step 44: Brake action applied! Velocity: 3.04\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2399\n",
      "Step 44: Action: 4, Reward: 1.6216, Total Reward: 52.1401, Epsilon: 0.917\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.00\n",
      "Intersection detected: Velocity=3.00, Min Distance=0.00\n",
      "Moving: Velocity=3.00\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1421\n",
      "Step 45: Action: 1, Reward: 1.3801, Total Reward: 53.5202, Epsilon: 0.916\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.11\n",
      "Intersection detected: Velocity=3.11, Min Distance=0.00\n",
      "Moving: Velocity=3.11\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2454\n",
      "Step 46: Action: 3, Reward: 1.0845, Total Reward: 54.6047, Epsilon: 0.916\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.05, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.05, Min Distance=0.00\n",
      "Moving: Velocity=3.05\n",
      "Step 47: Brake action applied! Velocity: 3.05\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0290\n",
      "Step 47: Action: 4, Reward: 1.3221, Total Reward: 55.9269, Epsilon: 0.915\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.02\n",
      "Intersection detected: Velocity=3.02, Min Distance=0.00\n",
      "Moving: Velocity=3.02\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0190\n",
      "Step 48: Action: 1, Reward: 1.3806, Total Reward: 57.3075, Epsilon: 0.915\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.98\n",
      "Intersection detected: Velocity=2.98, Min Distance=0.00\n",
      "Moving: Velocity=2.98\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1313\n",
      "Step 49: Action: 1, Reward: 1.3792, Total Reward: 58.6867, Epsilon: 0.914\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.94, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.94, Min Distance=0.00\n",
      "Moving: Velocity=2.94\n",
      "Step 50: Brake action applied! Velocity: 2.94\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1403\n",
      "Step 50: Action: 4, Reward: 1.6177, Total Reward: 60.3045, Epsilon: 0.914\n",
      "Q-values: [1.4109603 1.3832715 1.2339444 1.219765  1.5060762]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.91, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.91, Min Distance=0.00\n",
      "Moving: Velocity=2.91\n",
      "Step 51: Brake action applied! Velocity: 2.91\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0242\n",
      "Step 51: Action: 4, Reward: 1.6163, Total Reward: 61.9207, Epsilon: 0.913\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.02\n",
      "Intersection detected: Velocity=3.02, Min Distance=0.00\n",
      "Moving: Velocity=3.02\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1395\n",
      "Step 52: Action: 2, Reward: 1.0808, Total Reward: 63.0016, Epsilon: 0.913\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.03\n",
      "Intersection detected: Velocity=3.03, Min Distance=0.00\n",
      "Moving: Velocity=3.03\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0216\n",
      "Step 53: Action: 3, Reward: 1.0812, Total Reward: 64.0828, Epsilon: 0.912\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.32\n",
      "Intersection detected: Velocity=3.32, Min Distance=0.00\n",
      "Moving: Velocity=3.32\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2477\n",
      "Step 54: Action: 0, Reward: 1.0927, Total Reward: 65.1755, Epsilon: 0.912\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.41\n",
      "Intersection detected: Velocity=3.41, Min Distance=0.00\n",
      "Moving: Velocity=3.41\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2461\n",
      "Step 55: Action: 2, Reward: 1.0963, Total Reward: 66.2718, Epsilon: 0.911\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.61\n",
      "Intersection detected: Velocity=3.61, Min Distance=0.00\n",
      "Moving: Velocity=3.61\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0263\n",
      "Step 56: Action: 2, Reward: 1.4044, Total Reward: 67.6762, Epsilon: 0.911\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.54, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.54, Min Distance=0.00\n",
      "Moving: Velocity=3.54\n",
      "Step 57: Brake action applied! Velocity: 3.54\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0274\n",
      "Step 57: Action: 4, Reward: 1.3416, Total Reward: 69.0178, Epsilon: 0.910\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.58\n",
      "Intersection detected: Velocity=3.58, Min Distance=0.00\n",
      "Moving: Velocity=3.58\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0267\n",
      "Step 58: Action: 3, Reward: 1.1031, Total Reward: 70.1209, Epsilon: 0.910\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.53\n",
      "Intersection detected: Velocity=3.53, Min Distance=0.00\n",
      "Moving: Velocity=3.53\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1317\n",
      "Step 59: Action: 1, Reward: 1.1012, Total Reward: 71.2221, Epsilon: 0.909\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.63\n",
      "Intersection detected: Velocity=3.63, Min Distance=0.00\n",
      "Moving: Velocity=3.63\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1334\n",
      "Step 60: Action: 3, Reward: 1.1053, Total Reward: 72.3274, Epsilon: 0.909\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.63\n",
      "Intersection detected: Velocity=3.63, Min Distance=0.00\n",
      "Moving: Velocity=3.63\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1313\n",
      "Step 61: Action: 2, Reward: 1.1052, Total Reward: 73.4326, Epsilon: 0.908\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.72\n",
      "Intersection detected: Velocity=3.72, Min Distance=0.00\n",
      "Moving: Velocity=3.72\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2448\n",
      "Step 62: Action: 3, Reward: 1.1088, Total Reward: 74.5415, Epsilon: 0.908\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.93\n",
      "Intersection detected: Velocity=3.93, Min Distance=0.00\n",
      "Moving: Velocity=3.93\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0166\n",
      "Step 63: Action: 3, Reward: 1.4171, Total Reward: 75.9585, Epsilon: 0.907\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.86\n",
      "Intersection detected: Velocity=3.86, Min Distance=0.00\n",
      "Moving: Velocity=3.86\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1409\n",
      "Step 64: Action: 1, Reward: 1.1142, Total Reward: 77.0727, Epsilon: 0.907\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.99\n",
      "Intersection detected: Velocity=3.99, Min Distance=0.00\n",
      "Moving: Velocity=3.99\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0262\n",
      "Step 65: Action: 3, Reward: 1.1196, Total Reward: 78.1923, Epsilon: 0.906\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.93\n",
      "Intersection detected: Velocity=3.93, Min Distance=0.00\n",
      "Moving: Velocity=3.93\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2426\n",
      "Step 66: Action: 1, Reward: 1.1170, Total Reward: 79.3094, Epsilon: 0.906\n",
      "Q-values: [1.389263  1.364257  1.2414291 1.1995764 1.5243486]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.89, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.89, Min Distance=0.00\n",
      "Moving: Velocity=3.89\n",
      "Step 67: Brake action applied! Velocity: 3.89\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0254\n",
      "Step 67: Action: 4, Reward: 1.6555, Total Reward: 80.9649, Epsilon: 0.905\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.85\n",
      "Intersection detected: Velocity=3.85, Min Distance=0.00\n",
      "Moving: Velocity=3.85\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0196\n",
      "Step 68: Action: 1, Reward: 1.4141, Total Reward: 82.3789, Epsilon: 0.905\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.92\n",
      "Intersection detected: Velocity=3.92, Min Distance=0.00\n",
      "Moving: Velocity=3.92\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1357\n",
      "Step 69: Action: 3, Reward: 1.1169, Total Reward: 83.4958, Epsilon: 0.904\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.93\n",
      "Intersection detected: Velocity=3.93, Min Distance=0.00\n",
      "Moving: Velocity=3.93\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1392\n",
      "Step 70: Action: 2, Reward: 1.1171, Total Reward: 84.6129, Epsilon: 0.904\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.99\n",
      "Intersection detected: Velocity=3.99, Min Distance=0.00\n",
      "Moving: Velocity=3.99\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0229\n",
      "Step 71: Action: 3, Reward: 1.1196, Total Reward: 85.7325, Epsilon: 0.903\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.94, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.94, Min Distance=0.00\n",
      "Moving: Velocity=3.94\n",
      "Step 72: Brake action applied! Velocity: 3.94\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1393\n",
      "Step 72: Action: 4, Reward: 1.3576, Total Reward: 87.0901, Epsilon: 0.903\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.99\n",
      "Intersection detected: Velocity=3.99, Min Distance=0.00\n",
      "Moving: Velocity=3.99\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0208\n",
      "Step 73: Action: 2, Reward: 1.1197, Total Reward: 88.2098, Epsilon: 0.902\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.26\n",
      "Intersection detected: Velocity=4.26, Min Distance=0.00\n",
      "Moving: Velocity=4.26\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1342\n",
      "Step 74: Action: 0, Reward: 1.1305, Total Reward: 89.3404, Epsilon: 0.902\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.23, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.23, Min Distance=0.00\n",
      "Moving: Velocity=4.23\n",
      "Step 75: Brake action applied! Velocity: 4.23\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0212\n",
      "Step 75: Action: 4, Reward: 1.6691, Total Reward: 91.0094, Epsilon: 0.901\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.28\n",
      "Intersection detected: Velocity=4.28, Min Distance=0.00\n",
      "Moving: Velocity=4.28\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1298\n",
      "Step 76: Action: 3, Reward: 1.1314, Total Reward: 92.1408, Epsilon: 0.901\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.23\n",
      "Intersection detected: Velocity=4.23, Min Distance=0.00\n",
      "Moving: Velocity=4.23\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2479\n",
      "Step 77: Action: 1, Reward: 1.1294, Total Reward: 93.2701, Epsilon: 0.901\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.52\n",
      "Intersection detected: Velocity=4.52, Min Distance=0.00\n",
      "Moving: Velocity=4.52\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0225\n",
      "Step 78: Action: 0, Reward: 1.4408, Total Reward: 94.7109, Epsilon: 0.900\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.58\n",
      "Intersection detected: Velocity=4.58, Min Distance=0.00\n",
      "Moving: Velocity=4.58\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0175\n",
      "Step 79: Action: 3, Reward: 1.1432, Total Reward: 95.8541, Epsilon: 0.900\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.53\n",
      "Intersection detected: Velocity=4.53, Min Distance=0.00\n",
      "Moving: Velocity=4.53\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1279\n",
      "Step 80: Action: 1, Reward: 1.1413, Total Reward: 96.9954, Epsilon: 0.899\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.50\n",
      "Intersection detected: Velocity=4.50, Min Distance=0.00\n",
      "Moving: Velocity=4.50\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1374\n",
      "Step 81: Action: 1, Reward: 1.4398, Total Reward: 98.4352, Epsilon: 0.899\n",
      "Q-values: [1.3765863 1.3950586 1.2301521 1.2072345 1.5359932]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.46, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.46, Min Distance=0.00\n",
      "Moving: Velocity=4.46\n",
      "Step 82: Brake action applied! Velocity: 4.46\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1322\n",
      "Step 82: Action: 4, Reward: 1.6784, Total Reward: 100.1136, Epsilon: 0.898\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.42\n",
      "Intersection detected: Velocity=4.42, Min Distance=0.00\n",
      "Moving: Velocity=4.42\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0149\n",
      "Step 83: Action: 1, Reward: 1.4369, Total Reward: 101.5505, Epsilon: 0.898\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.48\n",
      "Intersection detected: Velocity=4.48, Min Distance=0.00\n",
      "Moving: Velocity=4.48\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0248\n",
      "Step 84: Action: 2, Reward: 1.1391, Total Reward: 102.6897, Epsilon: 0.897\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.75\n",
      "Intersection detected: Velocity=4.75, Min Distance=0.00\n",
      "Moving: Velocity=4.75\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0223\n",
      "Step 85: Action: 0, Reward: 1.1499, Total Reward: 103.8395, Epsilon: 0.897\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.71\n",
      "Intersection detected: Velocity=4.71, Min Distance=0.00\n",
      "Moving: Velocity=4.71\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1339\n",
      "Step 86: Action: 1, Reward: 1.4484, Total Reward: 105.2879, Epsilon: 0.896\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.67, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.67, Min Distance=0.00\n",
      "Moving: Velocity=4.67\n",
      "Step 87: Brake action applied! Velocity: 4.67\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0214\n",
      "Step 87: Action: 4, Reward: 1.6869, Total Reward: 106.9748, Epsilon: 0.896\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.72\n",
      "Intersection detected: Velocity=4.72, Min Distance=0.00\n",
      "Moving: Velocity=4.72\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1308\n",
      "Step 88: Action: 2, Reward: 1.1488, Total Reward: 108.1237, Epsilon: 0.895\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.67\n",
      "Intersection detected: Velocity=4.67, Min Distance=0.00\n",
      "Moving: Velocity=4.67\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0249\n",
      "Step 89: Action: 1, Reward: 1.1469, Total Reward: 109.2705, Epsilon: 0.895\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.71\n",
      "Intersection detected: Velocity=4.71, Min Distance=0.00\n",
      "Moving: Velocity=4.71\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0181\n",
      "Step 90: Action: 3, Reward: 1.1483, Total Reward: 110.4188, Epsilon: 0.894\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.72\n",
      "Intersection detected: Velocity=4.72, Min Distance=0.00\n",
      "Moving: Velocity=4.72\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0190\n",
      "Step 91: Action: 2, Reward: 1.1486, Total Reward: 111.5674, Epsilon: 0.894\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.78\n",
      "Intersection detected: Velocity=4.78, Min Distance=0.00\n",
      "Moving: Velocity=4.78\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1421\n",
      "Step 92: Action: 2, Reward: 1.4513, Total Reward: 113.0187, Epsilon: 0.893\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.93\n",
      "Intersection detected: Velocity=4.93, Min Distance=0.00\n",
      "Moving: Velocity=4.93\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1357\n",
      "Step 93: Action: 2, Reward: 1.4572, Total Reward: 114.4758, Epsilon: 0.893\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.86, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.86, Min Distance=0.00\n",
      "Moving: Velocity=4.86\n",
      "Step 94: Brake action applied! Velocity: 4.86\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2574\n",
      "Step 94: Action: 4, Reward: 1.3946, Total Reward: 115.8704, Epsilon: 0.892\n",
      "Q-values: [1.3823446 1.386505  1.275498  1.2447379 1.6280758]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.82, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.82, Min Distance=0.00\n",
      "Moving: Velocity=4.82\n",
      "Step 95: Brake action applied! Velocity: 4.82\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2525\n",
      "Step 95: Action: 4, Reward: 1.6929, Total Reward: 117.5633, Epsilon: 0.892\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.87\n",
      "Intersection detected: Velocity=4.87, Min Distance=0.00\n",
      "Moving: Velocity=4.87\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1305\n",
      "Step 96: Action: 2, Reward: 1.1550, Total Reward: 118.7183, Epsilon: 0.891\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.14\n",
      "Intersection detected: Velocity=5.14, Min Distance=0.00\n",
      "Moving: Velocity=5.14\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0216\n",
      "Step 97: Action: 0, Reward: 1.1656, Total Reward: 119.8839, Epsilon: 0.891\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.18\n",
      "Intersection detected: Velocity=5.18, Min Distance=0.00\n",
      "Moving: Velocity=5.18\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1305\n",
      "Step 98: Action: 3, Reward: 1.1671, Total Reward: 121.0510, Epsilon: 0.890\n",
      "Q-values: [1.3734794 1.3971106 1.2465222 1.183032  1.5807079]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.13, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.13, Min Distance=0.00\n",
      "Moving: Velocity=5.13\n",
      "Step 99: Brake action applied! Velocity: 5.13\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0194\n",
      "Step 99: Action: 4, Reward: 1.4054, Total Reward: 122.4564, Epsilon: 0.890\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.42\n",
      "Intersection detected: Velocity=5.42, Min Distance=0.00\n",
      "Moving: Velocity=5.42\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0207\n",
      "Step 100: Action: 0, Reward: 1.4769, Total Reward: 123.9333, Epsilon: 0.889\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.71\n",
      "Intersection detected: Velocity=5.71, Min Distance=0.00\n",
      "Moving: Velocity=5.71\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0210\n",
      "Step 101: Action: 0, Reward: 1.4883, Total Reward: 125.4217, Epsilon: 0.889\n",
      "Q-values: [1.3888116 1.4205179 1.2451134 1.1682677 1.5825322]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.67, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.67, Min Distance=0.00\n",
      "Moving: Velocity=5.67\n",
      "Step 102: Brake action applied! Velocity: 5.67\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1307\n",
      "Step 102: Action: 4, Reward: 1.7269, Total Reward: 127.1486, Epsilon: 0.888\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.71\n",
      "Intersection detected: Velocity=5.71, Min Distance=0.00\n",
      "Moving: Velocity=5.71\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1333\n",
      "Step 103: Action: 2, Reward: 1.1883, Total Reward: 128.3368, Epsilon: 0.888\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.66\n",
      "Intersection detected: Velocity=5.66, Min Distance=0.00\n",
      "Moving: Velocity=5.66\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0242\n",
      "Step 104: Action: 1, Reward: 1.1865, Total Reward: 129.5233, Epsilon: 0.887\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.95\n",
      "Intersection detected: Velocity=5.95, Min Distance=0.00\n",
      "Moving: Velocity=5.95\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1425\n",
      "Step 105: Action: 0, Reward: 1.4979, Total Reward: 131.0212, Epsilon: 0.887\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.91, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.91, Min Distance=0.00\n",
      "Moving: Velocity=5.91\n",
      "Step 106: Brake action applied! Velocity: 5.91\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0302\n",
      "Step 106: Action: 4, Reward: 1.7365, Total Reward: 132.7577, Epsilon: 0.886\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.95\n",
      "Intersection detected: Velocity=5.95, Min Distance=0.00\n",
      "Moving: Velocity=5.95\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1304\n",
      "Step 107: Action: 2, Reward: 1.1978, Total Reward: 133.9555, Epsilon: 0.886\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.22\n",
      "Intersection detected: Velocity=6.22, Min Distance=0.00\n",
      "Moving: Velocity=6.22\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1327\n",
      "Step 108: Action: 0, Reward: 1.2088, Total Reward: 135.1644, Epsilon: 0.885\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.18, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.18, Min Distance=0.00\n",
      "Moving: Velocity=6.18\n",
      "Step 109: Brake action applied! Velocity: 6.18\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0238\n",
      "Step 109: Action: 4, Reward: 1.7473, Total Reward: 136.9117, Epsilon: 0.885\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.21\n",
      "Intersection detected: Velocity=6.21, Min Distance=0.00\n",
      "Moving: Velocity=6.21\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1298\n",
      "Step 110: Action: 2, Reward: 1.2086, Total Reward: 138.1202, Epsilon: 0.884\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.21\n",
      "Intersection detected: Velocity=6.21, Min Distance=0.00\n",
      "Moving: Velocity=6.21\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0227\n",
      "Step 111: Action: 3, Reward: 1.2084, Total Reward: 139.3287, Epsilon: 0.884\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.23\n",
      "Intersection detected: Velocity=6.23, Min Distance=0.00\n",
      "Moving: Velocity=6.23\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1304\n",
      "Step 112: Action: 2, Reward: 1.2092, Total Reward: 140.5379, Epsilon: 0.883\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.51\n",
      "Intersection detected: Velocity=6.51, Min Distance=0.00\n",
      "Moving: Velocity=6.51\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1475\n",
      "Step 113: Action: 0, Reward: 1.2203, Total Reward: 141.7582, Epsilon: 0.883\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.80\n",
      "Intersection detected: Velocity=6.80, Min Distance=0.00\n",
      "Moving: Velocity=6.80\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1443\n",
      "Step 114: Action: 0, Reward: 1.5318, Total Reward: 143.2900, Epsilon: 0.882\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=7.08\n",
      "Intersection detected: Velocity=7.08, Min Distance=0.00\n",
      "Moving: Velocity=7.08\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0167\n",
      "Step 115: Action: 0, Reward: 1.5433, Total Reward: 144.8333, Epsilon: 0.882\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=7.11\n",
      "Intersection detected: Velocity=7.11, Min Distance=0.00\n",
      "Moving: Velocity=7.11\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1359\n",
      "Step 116: Action: 2, Reward: 1.2445, Total Reward: 146.0778, Epsilon: 0.881\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=7.39\n",
      "Intersection detected: Velocity=7.39, Min Distance=0.00\n",
      "Moving: Velocity=7.39\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1272\n",
      "Step 117: Action: 0, Reward: 1.2557, Total Reward: 147.3335, Epsilon: 0.881\n",
      "Q-values: [1.3707553 1.3140815 1.2558353 1.1744574 1.5853153]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=7.36, Min Distance=0.00\n",
      "Intersection detected: Velocity=7.36, Min Distance=0.00\n",
      "Moving: Velocity=7.36\n",
      "Step 118: Brake action applied! Velocity: 7.36\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0372\n",
      "Step 118: Action: 4, Reward: 1.7942, Total Reward: 149.1277, Epsilon: 0.880\n",
      "Q-values: [1.3791984 1.317306  1.2564406 1.1822834 1.5851511]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=7.32, Min Distance=0.00\n",
      "Intersection detected: Velocity=7.32, Min Distance=0.00\n",
      "Moving: Velocity=7.32\n",
      "Step 119: Brake action applied! Velocity: 7.32\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1258\n",
      "Step 119: Action: 4, Reward: 1.7928, Total Reward: 150.9205, Epsilon: 0.880\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=7.61\n",
      "Intersection detected: Velocity=7.61, Min Distance=0.00\n",
      "Moving: Velocity=7.61\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2536\n",
      "Step 120: Action: 0, Reward: 1.5642, Total Reward: 152.4847, Epsilon: 0.879\n",
      "Q-values: [1.3947208 1.3237164 1.261172  1.1902196 1.5901635]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=7.57, Min Distance=0.00\n",
      "Intersection detected: Velocity=7.57, Min Distance=0.00\n",
      "Moving: Velocity=7.57\n",
      "Step 121: Brake action applied! Velocity: 7.57\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0265\n",
      "Step 121: Action: 4, Reward: 1.8028, Total Reward: 154.2875, Epsilon: 0.879\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=7.53, Min Distance=0.00\n",
      "Intersection detected: Velocity=7.53, Min Distance=0.00\n",
      "Moving: Velocity=7.53\n",
      "Step 122: Brake action applied! Velocity: 7.53\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2508\n",
      "Step 122: Action: 4, Reward: 1.8013, Total Reward: 156.0888, Epsilon: 0.878\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=7.50, Min Distance=0.00\n",
      "Intersection detected: Velocity=7.50, Min Distance=0.00\n",
      "Moving: Velocity=7.50\n",
      "Step 123: Brake action applied! Velocity: 7.50\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0257\n",
      "Step 123: Action: 4, Reward: 1.7999, Total Reward: 157.8887, Epsilon: 0.878\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=7.51\n",
      "Intersection detected: Velocity=7.51, Min Distance=0.00\n",
      "Moving: Velocity=7.51\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1388\n",
      "Step 124: Action: 2, Reward: 1.2605, Total Reward: 159.1492, Epsilon: 0.877\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=7.47, Min Distance=0.00\n",
      "Intersection detected: Velocity=7.47, Min Distance=0.00\n",
      "Moving: Velocity=7.47\n",
      "Step 125: Brake action applied! Velocity: 7.47\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0233\n",
      "Step 125: Action: 4, Reward: 1.4988, Total Reward: 160.6479, Epsilon: 0.877\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=7.43\n",
      "Intersection detected: Velocity=7.43, Min Distance=0.00\n",
      "Moving: Velocity=7.43\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1450\n",
      "Step 126: Action: 1, Reward: 1.5573, Total Reward: 162.2053, Epsilon: 0.876\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=7.72\n",
      "Intersection detected: Velocity=7.72, Min Distance=0.00\n",
      "Moving: Velocity=7.72\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2553\n",
      "Step 127: Action: 0, Reward: 1.5688, Total Reward: 163.7741, Epsilon: 0.876\n",
      "Q-values: [1.4811223 1.3975115 1.2959057 1.2222016 1.630056 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=7.68, Min Distance=0.00\n",
      "Intersection detected: Velocity=7.68, Min Distance=0.00\n",
      "Moving: Velocity=7.68\n",
      "Step 128: Brake action applied! Velocity: 7.68\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0234\n",
      "Step 128: Action: 4, Reward: 1.8073, Total Reward: 165.5814, Epsilon: 0.875\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=7.97\n",
      "Intersection detected: Velocity=7.97, Min Distance=0.00\n",
      "Moving: Velocity=7.97\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0216\n",
      "Step 129: Action: 0, Reward: 1.5788, Total Reward: 167.1602, Epsilon: 0.875\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=7.99\n",
      "Intersection detected: Velocity=7.99, Min Distance=0.00\n",
      "Moving: Velocity=7.99\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0260\n",
      "Step 130: Action: 2, Reward: 1.2798, Total Reward: 168.4400, Epsilon: 0.874\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection detected: Velocity=8.03, Min Distance=0.00\n",
      "Moving: Velocity=8.03\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1520\n",
      "Step 131: Action: 2, Reward: 0.5214, Total Reward: 168.9614, Epsilon: 0.874\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection detected: Velocity=8.10, Min Distance=0.00\n",
      "Moving: Velocity=8.10\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0328\n",
      "Step 132: Action: 2, Reward: 0.5239, Total Reward: 169.4853, Epsilon: 0.873\n",
      "Q-values: [1.5069273 1.4305432 1.3108443 1.2490114 1.6685125]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=8.05, Min Distance=0.00\n",
      "Intersection detected: Velocity=8.05, Min Distance=0.00\n",
      "Moving: Velocity=8.05\n",
      "Step 133: Brake action applied! Velocity: 8.05\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0192\n",
      "Step 133: Action: 4, Reward: 1.0221, Total Reward: 170.5074, Epsilon: 0.873\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection detected: Velocity=8.08, Min Distance=0.00\n",
      "Moving: Velocity=8.08\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1483\n",
      "Step 134: Action: 2, Reward: 0.2231, Total Reward: 170.7305, Epsilon: 0.872\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=8.03, Min Distance=0.00\n",
      "Intersection detected: Velocity=8.03, Min Distance=0.00\n",
      "Moving: Velocity=8.03\n",
      "Step 135: Brake action applied! Velocity: 8.03\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1509\n",
      "Step 135: Action: 4, Reward: 1.0214, Total Reward: 171.7519, Epsilon: 0.872\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection detected: Velocity=8.04, Min Distance=0.00\n",
      "Moving: Velocity=8.04\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0226\n",
      "Step 136: Action: 3, Reward: 0.2216, Total Reward: 171.9735, Epsilon: 0.871\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=8.00, Min Distance=0.00\n",
      "Intersection detected: Velocity=8.00, Min Distance=0.00\n",
      "Moving: Velocity=8.00\n",
      "Step 137: Brake action applied! Velocity: 8.00\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0391\n",
      "Step 137: Action: 4, Reward: 1.0200, Total Reward: 172.9936, Epsilon: 0.871\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection detected: Velocity=8.01, Min Distance=0.00\n",
      "Moving: Velocity=8.01\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0432\n",
      "Step 138: Action: 2, Reward: 0.2204, Total Reward: 173.2140, Epsilon: 0.870\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=7.97, Min Distance=0.00\n",
      "Intersection detected: Velocity=7.97, Min Distance=0.00\n",
      "Moving: Velocity=7.97\n",
      "Step 139: Brake action applied! Velocity: 7.97\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0245\n",
      "Step 139: Action: 4, Reward: 1.5188, Total Reward: 174.7327, Epsilon: 0.870\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=7.98\n",
      "Intersection detected: Velocity=7.98, Min Distance=0.00\n",
      "Moving: Velocity=7.98\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0415\n",
      "Step 140: Action: 3, Reward: 1.2791, Total Reward: 176.0118, Epsilon: 0.869\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection detected: Velocity=8.01, Min Distance=0.00\n",
      "Moving: Velocity=8.01\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1492\n",
      "Step 141: Action: 3, Reward: 0.5206, Total Reward: 176.5324, Epsilon: 0.869\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection detected: Velocity=8.08, Min Distance=0.00\n",
      "Moving: Velocity=8.08\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1261\n",
      "Step 142: Action: 3, Reward: 0.5232, Total Reward: 177.0557, Epsilon: 0.868\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection detected: Velocity=8.31, Min Distance=0.00\n",
      "Moving: Velocity=8.31\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1548\n",
      "Step 143: Action: 0, Reward: 0.2322, Total Reward: 177.2879, Epsilon: 0.868\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection detected: Velocity=8.34, Min Distance=0.00\n",
      "Moving: Velocity=8.34\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0346\n",
      "Step 144: Action: 3, Reward: 0.2335, Total Reward: 177.5214, Epsilon: 0.867\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=8.30, Min Distance=0.00\n",
      "Intersection detected: Velocity=8.30, Min Distance=0.00\n",
      "Moving: Velocity=8.30\n",
      "Step 145: Brake action applied! Velocity: 8.30\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0655\n",
      "Step 145: Action: 4, Reward: 1.0319, Total Reward: 178.5533, Epsilon: 0.867\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection detected: Velocity=8.26, Min Distance=0.00\n",
      "Moving: Velocity=8.26\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2877\n",
      "Step 146: Action: 1, Reward: 0.5304, Total Reward: 179.0837, Epsilon: 0.866\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection detected: Velocity=8.55, Min Distance=0.00\n",
      "Moving: Velocity=8.55\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0558\n",
      "Step 147: Action: 0, Reward: 0.5419, Total Reward: 179.6256, Epsilon: 0.866\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection detected: Velocity=8.57, Min Distance=0.00\n",
      "Moving: Velocity=8.57\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0250\n",
      "Step 148: Action: 3, Reward: 0.2428, Total Reward: 179.8683, Epsilon: 0.865\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection detected: Velocity=8.53, Min Distance=0.00\n",
      "Moving: Velocity=8.53\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1774\n",
      "Step 149: Action: 1, Reward: 0.2412, Total Reward: 180.1095, Epsilon: 0.865\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=8.49, Min Distance=0.00\n",
      "Intersection detected: Velocity=8.49, Min Distance=0.00\n",
      "Moving: Velocity=8.49\n",
      "Step 150: Brake action applied! Velocity: 8.49\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0306\n",
      "Step 150: Action: 4, Reward: 1.3397, Total Reward: 181.4493, Epsilon: 0.864\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection detected: Velocity=8.78, Min Distance=0.00\n",
      "Moving: Velocity=8.78\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0877\n",
      "Step 151: Action: 0, Reward: 0.5512, Total Reward: 182.0005, Epsilon: 0.864\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=8.74, Min Distance=0.00\n",
      "Intersection detected: Velocity=8.74, Min Distance=0.00\n",
      "Moving: Velocity=8.74\n",
      "Step 152: Brake action applied! Velocity: 8.74\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0639\n",
      "Step 152: Action: 4, Reward: 1.3498, Total Reward: 183.3502, Epsilon: 0.863\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection detected: Velocity=8.71, Min Distance=0.00\n",
      "Moving: Velocity=8.71\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0562\n",
      "Step 153: Action: 1, Reward: 0.5483, Total Reward: 183.8985, Epsilon: 0.863\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection detected: Velocity=8.72, Min Distance=0.00\n",
      "Moving: Velocity=8.72\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1731\n",
      "Step 154: Action: 3, Reward: 0.2487, Total Reward: 184.1472, Epsilon: 0.862\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection detected: Velocity=8.71, Min Distance=0.00\n",
      "Moving: Velocity=8.71\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0713\n",
      "Step 155: Action: 2, Reward: 0.2484, Total Reward: 184.3956, Epsilon: 0.862\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection detected: Velocity=8.71, Min Distance=0.00\n",
      "Moving: Velocity=8.71\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0586\n",
      "Step 156: Action: 3, Reward: 0.2485, Total Reward: 184.6441, Epsilon: 0.861\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection detected: Velocity=8.74, Min Distance=0.00\n",
      "Moving: Velocity=8.74\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1748\n",
      "Step 157: Action: 3, Reward: 0.5497, Total Reward: 185.1938, Epsilon: 0.861\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection detected: Velocity=9.01, Min Distance=0.00\n",
      "Moving: Velocity=9.01\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0899\n",
      "Step 158: Action: 0, Reward: 0.2602, Total Reward: 185.4540, Epsilon: 0.860\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=8.97, Min Distance=0.00\n",
      "Intersection detected: Velocity=8.97, Min Distance=0.00\n",
      "Moving: Velocity=8.97\n",
      "Step 159: Brake action applied! Velocity: 8.97\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0678\n",
      "Step 159: Action: 4, Reward: 1.3588, Total Reward: 186.8128, Epsilon: 0.860\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection detected: Velocity=8.93, Min Distance=0.00\n",
      "Moving: Velocity=8.93\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2008\n",
      "Step 160: Action: 1, Reward: 0.5573, Total Reward: 187.3701, Epsilon: 0.859\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=8.90, Min Distance=0.00\n",
      "Intersection detected: Velocity=8.90, Min Distance=0.00\n",
      "Moving: Velocity=8.90\n",
      "Step 161: Brake action applied! Velocity: 8.90\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0700\n",
      "Step 161: Action: 4, Reward: 1.3559, Total Reward: 188.7260, Epsilon: 0.859\n",
      "Q-values: [1.2995305 1.325985  1.1875482 1.1507949 1.5657363]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=8.86, Min Distance=0.00\n",
      "Intersection detected: Velocity=8.86, Min Distance=0.00\n",
      "Moving: Velocity=8.86\n",
      "Step 162: Brake action applied! Velocity: 8.86\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0777\n",
      "Step 162: Action: 4, Reward: 1.3544, Total Reward: 190.0804, Epsilon: 0.858\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection detected: Velocity=8.87, Min Distance=0.00\n",
      "Moving: Velocity=8.87\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1958\n",
      "Step 163: Action: 2, Reward: 0.2548, Total Reward: 190.3352, Epsilon: 0.858\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection detected: Velocity=8.90, Min Distance=0.00\n",
      "Moving: Velocity=8.90\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1156\n",
      "Step 164: Action: 2, Reward: 0.5561, Total Reward: 190.8913, Epsilon: 0.857\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection detected: Velocity=9.16, Min Distance=0.00\n",
      "Moving: Velocity=9.16\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1942\n",
      "Step 165: Action: 0, Reward: 0.2665, Total Reward: 191.1578, Epsilon: 0.857\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=9.13, Min Distance=0.00\n",
      "Intersection detected: Velocity=9.13, Min Distance=0.00\n",
      "Moving: Velocity=9.13\n",
      "Step 166: Brake action applied! Velocity: 9.13\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1938\n",
      "Step 166: Action: 4, Reward: 1.3650, Total Reward: 192.5228, Epsilon: 0.856\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection detected: Velocity=9.13, Min Distance=0.00\n",
      "Moving: Velocity=9.13\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0677\n",
      "Step 167: Action: 3, Reward: 0.2653, Total Reward: 192.7881, Epsilon: 0.856\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection detected: Velocity=9.09, Min Distance=0.00\n",
      "Moving: Velocity=9.09\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1976\n",
      "Step 168: Action: 1, Reward: 0.2636, Total Reward: 193.0517, Epsilon: 0.855\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection detected: Velocity=9.05, Min Distance=0.00\n",
      "Off-road detected: Penalty applied\n",
      "Moving: Velocity=9.05\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2212\n",
      "Step 169: Action: 1, Reward: -2.0000, Total Reward: 191.0517, Epsilon: 0.855\n",
      "Episode 3 ended early: Terminated=True, Truncated=False\n",
      "Episode 3 completed. Total Reward: 191.0517\n",
      "Episode 4 started\n",
      "Initial observation shape: (259,)\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.03, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.03, Min Distance=0.00\n",
      "Step 1: Brake action applied! Velocity: 0.03\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1689\n",
      "Step 1: Action: 4, Reward: 1.5010, Total Reward: 1.5010, Epsilon: 0.854\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.04, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.04, Min Distance=0.00\n",
      "Step 2: Brake action applied! Velocity: 0.04\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0844\n",
      "Step 2: Action: 4, Reward: 1.5017, Total Reward: 3.0027, Epsilon: 0.854\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.32\n",
      "Intersection detected: Velocity=0.32, Min Distance=0.00\n",
      "Moving: Velocity=0.32\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2565\n",
      "Step 3: Action: 2, Reward: 0.9728, Total Reward: 3.9755, Epsilon: 0.853\n",
      "Q-values: [1.3705128 1.3325814 1.1894627 1.1413624 1.6267155]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.28, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.28, Min Distance=0.00\n",
      "Moving: Velocity=0.28\n",
      "Step 4: Brake action applied! Velocity: 0.28\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0865\n",
      "Step 4: Action: 4, Reward: 1.2112, Total Reward: 5.1867, Epsilon: 0.853\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.57\n",
      "Intersection detected: Velocity=0.57, Min Distance=0.00\n",
      "Moving: Velocity=0.57\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0838\n",
      "Step 5: Action: 0, Reward: 1.2826, Total Reward: 6.4693, Epsilon: 0.852\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.53, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.53, Min Distance=0.00\n",
      "Moving: Velocity=0.53\n",
      "Step 6: Brake action applied! Velocity: 0.53\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1995\n",
      "Step 6: Action: 4, Reward: 1.5212, Total Reward: 7.9905, Epsilon: 0.852\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.49\n",
      "Intersection detected: Velocity=0.49, Min Distance=0.00\n",
      "Moving: Velocity=0.49\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2397\n",
      "Step 7: Action: 1, Reward: 1.2797, Total Reward: 9.2702, Epsilon: 0.852\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.46\n",
      "Intersection detected: Velocity=0.46, Min Distance=0.00\n",
      "Moving: Velocity=0.46\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1719\n",
      "Step 8: Action: 1, Reward: 1.2783, Total Reward: 10.5485, Epsilon: 0.851\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.71\n",
      "Intersection detected: Velocity=0.71, Min Distance=0.00\n",
      "Moving: Velocity=0.71\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0973\n",
      "Step 9: Action: 3, Reward: 0.9886, Total Reward: 11.5371, Epsilon: 0.851\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.91\n",
      "Intersection detected: Velocity=0.91, Min Distance=0.00\n",
      "Moving: Velocity=0.91\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1183\n",
      "Step 10: Action: 2, Reward: 0.9964, Total Reward: 12.5334, Epsilon: 0.850\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.87, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.87, Min Distance=0.00\n",
      "Moving: Velocity=0.87\n",
      "Step 11: Brake action applied! Velocity: 0.87\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1941\n",
      "Step 11: Action: 4, Reward: 1.2346, Total Reward: 13.7681, Epsilon: 0.850\n",
      "Q-values: [1.3654709 1.159092  1.1527687 1.1472907 1.6271996]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.83, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.83, Min Distance=0.00\n",
      "Moving: Velocity=0.83\n",
      "Step 12: Brake action applied! Velocity: 0.83\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0745\n",
      "Step 12: Action: 4, Reward: 1.5332, Total Reward: 15.3012, Epsilon: 0.849\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.12\n",
      "Intersection detected: Velocity=1.12, Min Distance=0.00\n",
      "Moving: Velocity=1.12\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2173\n",
      "Step 13: Action: 0, Reward: 1.3046, Total Reward: 16.6059, Epsilon: 0.849\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.08, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.08, Min Distance=0.00\n",
      "Moving: Velocity=1.08\n",
      "Step 14: Brake action applied! Velocity: 1.08\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0848\n",
      "Step 14: Action: 4, Reward: 1.5432, Total Reward: 18.1490, Epsilon: 0.848\n",
      "Q-values: [1.35592   1.168019  1.1420813 1.1356149 1.6038722]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.04, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.04, Min Distance=0.00\n",
      "Moving: Velocity=1.04\n",
      "Step 15: Brake action applied! Velocity: 1.04\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0909\n",
      "Step 15: Action: 4, Reward: 1.5417, Total Reward: 19.6907, Epsilon: 0.848\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.01, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.01, Min Distance=0.00\n",
      "Moving: Velocity=1.01\n",
      "Step 16: Brake action applied! Velocity: 1.01\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0861\n",
      "Step 16: Action: 4, Reward: 1.5403, Total Reward: 21.2310, Epsilon: 0.847\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.24\n",
      "Intersection detected: Velocity=1.24, Min Distance=0.00\n",
      "Moving: Velocity=1.24\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0454\n",
      "Step 17: Action: 3, Reward: 1.0095, Total Reward: 22.2405, Epsilon: 0.847\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.18, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.18, Min Distance=0.00\n",
      "Moving: Velocity=1.18\n",
      "Step 18: Brake action applied! Velocity: 1.18\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1006\n",
      "Step 18: Action: 4, Reward: 1.2474, Total Reward: 23.4878, Epsilon: 0.846\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.15\n",
      "Intersection detected: Velocity=1.15, Min Distance=0.00\n",
      "Moving: Velocity=1.15\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0521\n",
      "Step 19: Action: 1, Reward: 1.3059, Total Reward: 24.7937, Epsilon: 0.846\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.11\n",
      "Intersection detected: Velocity=1.11, Min Distance=0.00\n",
      "Moving: Velocity=1.11\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3627\n",
      "Step 20: Action: 1, Reward: 1.3044, Total Reward: 26.0982, Epsilon: 0.845\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.07\n",
      "Intersection detected: Velocity=1.07, Min Distance=0.00\n",
      "Moving: Velocity=1.07\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1601\n",
      "Step 21: Action: 1, Reward: 1.3030, Total Reward: 27.4011, Epsilon: 0.845\n",
      "Q-values: [1.3630084 1.2934731 1.2051531 1.1828594 1.5976382]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.04, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.04, Min Distance=0.00\n",
      "Moving: Velocity=1.04\n",
      "Step 22: Brake action applied! Velocity: 1.04\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2108\n",
      "Step 22: Action: 4, Reward: 1.5415, Total Reward: 28.9426, Epsilon: 0.844\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.27\n",
      "Intersection detected: Velocity=1.27, Min Distance=0.00\n",
      "Moving: Velocity=1.27\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0606\n",
      "Step 23: Action: 3, Reward: 1.0106, Total Reward: 29.9533, Epsilon: 0.844\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.54\n",
      "Intersection detected: Velocity=1.54, Min Distance=0.00\n",
      "Moving: Velocity=1.54\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2046\n",
      "Step 24: Action: 0, Reward: 1.0215, Total Reward: 30.9747, Epsilon: 0.843\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.50\n",
      "Intersection detected: Velocity=1.50, Min Distance=0.00\n",
      "Moving: Velocity=1.50\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0982\n",
      "Step 25: Action: 1, Reward: 1.3200, Total Reward: 32.2947, Epsilon: 0.843\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.71\n",
      "Intersection detected: Velocity=1.71, Min Distance=0.00\n",
      "Moving: Velocity=1.71\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0705\n",
      "Step 26: Action: 3, Reward: 1.0283, Total Reward: 33.3230, Epsilon: 0.842\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.78\n",
      "Intersection detected: Velocity=1.78, Min Distance=0.00\n",
      "Moving: Velocity=1.78\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0903\n",
      "Step 27: Action: 2, Reward: 1.0313, Total Reward: 34.3543, Epsilon: 0.842\n",
      "Q-values: [1.3326877 1.3150517 1.2088773 1.2042146 1.5090746]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.74, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.74, Min Distance=0.00\n",
      "Moving: Velocity=1.74\n",
      "Step 28: Brake action applied! Velocity: 1.74\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1616\n",
      "Step 28: Action: 4, Reward: 1.2696, Total Reward: 35.6239, Epsilon: 0.841\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.94\n",
      "Intersection detected: Velocity=1.94, Min Distance=0.00\n",
      "Moving: Velocity=1.94\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1895\n",
      "Step 29: Action: 2, Reward: 1.0377, Total Reward: 36.6616, Epsilon: 0.841\n",
      "Q-values: [1.3407725 1.3355169 1.2223165 1.2192888 1.5219977]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.88, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.88, Min Distance=0.00\n",
      "Moving: Velocity=1.88\n",
      "Step 30: Brake action applied! Velocity: 1.88\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2638\n",
      "Step 30: Action: 4, Reward: 1.2753, Total Reward: 37.9369, Epsilon: 0.840\n",
      "Q-values: [1.3301871 1.3283279 1.2186062 1.2164129 1.5162665]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.84, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.84, Min Distance=0.00\n",
      "Moving: Velocity=1.84\n",
      "Step 31: Brake action applied! Velocity: 1.84\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2070\n",
      "Step 31: Action: 4, Reward: 1.5738, Total Reward: 39.5107, Epsilon: 0.840\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.81\n",
      "Intersection detected: Velocity=1.81, Min Distance=0.00\n",
      "Moving: Velocity=1.81\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3660\n",
      "Step 32: Action: 1, Reward: 1.3323, Total Reward: 40.8430, Epsilon: 0.839\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.99\n",
      "Intersection detected: Velocity=1.99, Min Distance=0.00\n",
      "Moving: Velocity=1.99\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0603\n",
      "Step 33: Action: 2, Reward: 1.0397, Total Reward: 41.8827, Epsilon: 0.839\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.94, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.94, Min Distance=0.00\n",
      "Moving: Velocity=1.94\n",
      "Step 34: Brake action applied! Velocity: 1.94\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0988\n",
      "Step 34: Action: 4, Reward: 1.2774, Total Reward: 43.1601, Epsilon: 0.838\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.22\n",
      "Intersection detected: Velocity=2.22, Min Distance=0.00\n",
      "Moving: Velocity=2.22\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0773\n",
      "Step 35: Action: 0, Reward: 1.3489, Total Reward: 44.5090, Epsilon: 0.838\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.19\n",
      "Intersection detected: Velocity=2.19, Min Distance=0.00\n",
      "Moving: Velocity=2.19\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3413\n",
      "Step 36: Action: 1, Reward: 1.3474, Total Reward: 45.8564, Epsilon: 0.837\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.35\n",
      "Intersection detected: Velocity=2.35, Min Distance=0.00\n",
      "Moving: Velocity=2.35\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1692\n",
      "Step 37: Action: 2, Reward: 1.0539, Total Reward: 46.9103, Epsilon: 0.837\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.37\n",
      "Intersection detected: Velocity=2.37, Min Distance=0.00\n",
      "Moving: Velocity=2.37\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3346\n",
      "Step 38: Action: 3, Reward: 1.0549, Total Reward: 47.9652, Epsilon: 0.836\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.55\n",
      "Intersection detected: Velocity=2.55, Min Distance=0.00\n",
      "Moving: Velocity=2.55\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1945\n",
      "Step 39: Action: 3, Reward: 1.3621, Total Reward: 49.3273, Epsilon: 0.836\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.81\n",
      "Intersection detected: Velocity=2.81, Min Distance=0.00\n",
      "Moving: Velocity=2.81\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0478\n",
      "Step 40: Action: 3, Reward: 1.3723, Total Reward: 50.6996, Epsilon: 0.835\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.73, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.73, Min Distance=0.00\n",
      "Moving: Velocity=2.73\n",
      "Step 41: Brake action applied! Velocity: 2.73\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1054\n",
      "Step 41: Action: 4, Reward: 1.3093, Total Reward: 52.0088, Epsilon: 0.835\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.69, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.69, Min Distance=0.00\n",
      "Moving: Velocity=2.69\n",
      "Step 42: Brake action applied! Velocity: 2.69\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2198\n",
      "Step 42: Action: 4, Reward: 1.6077, Total Reward: 53.6165, Epsilon: 0.834\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.83\n",
      "Intersection detected: Velocity=2.83, Min Distance=0.00\n",
      "Moving: Velocity=2.83\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2475\n",
      "Step 43: Action: 3, Reward: 1.0734, Total Reward: 54.6899, Epsilon: 0.834\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.77\n",
      "Intersection detected: Velocity=2.77, Min Distance=0.00\n",
      "Moving: Velocity=2.77\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1654\n",
      "Step 44: Action: 1, Reward: 1.0709, Total Reward: 55.7608, Epsilon: 0.833\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.94\n",
      "Intersection detected: Velocity=2.94, Min Distance=0.00\n",
      "Moving: Velocity=2.94\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0880\n",
      "Step 45: Action: 3, Reward: 1.0774, Total Reward: 56.8382, Epsilon: 0.833\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.94\n",
      "Intersection detected: Velocity=2.94, Min Distance=0.00\n",
      "Moving: Velocity=2.94\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3412\n",
      "Step 46: Action: 2, Reward: 1.0775, Total Reward: 57.9157, Epsilon: 0.832\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.90, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.90, Min Distance=0.00\n",
      "Moving: Velocity=2.90\n",
      "Step 47: Brake action applied! Velocity: 2.90\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0905\n",
      "Step 47: Action: 4, Reward: 1.3160, Total Reward: 59.2317, Epsilon: 0.832\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.02\n",
      "Intersection detected: Velocity=3.02, Min Distance=0.00\n",
      "Moving: Velocity=3.02\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1879\n",
      "Step 48: Action: 2, Reward: 1.0806, Total Reward: 60.3123, Epsilon: 0.831\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.95, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.95, Min Distance=0.00\n",
      "Moving: Velocity=2.95\n",
      "Step 49: Brake action applied! Velocity: 2.95\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2409\n",
      "Step 49: Action: 4, Reward: 1.3182, Total Reward: 61.6305, Epsilon: 0.831\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.11\n",
      "Intersection detected: Velocity=3.11, Min Distance=0.00\n",
      "Moving: Velocity=3.11\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2211\n",
      "Step 50: Action: 2, Reward: 1.0843, Total Reward: 62.7148, Epsilon: 0.830\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.35\n",
      "Intersection detected: Velocity=3.35, Min Distance=0.00\n",
      "Moving: Velocity=3.35\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0604\n",
      "Step 51: Action: 0, Reward: 1.0940, Total Reward: 63.8088, Epsilon: 0.830\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.64\n",
      "Intersection detected: Velocity=3.64, Min Distance=0.00\n",
      "Moving: Velocity=3.64\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1966\n",
      "Step 52: Action: 0, Reward: 1.4055, Total Reward: 65.2143, Epsilon: 0.829\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.60, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.60, Min Distance=0.00\n",
      "Moving: Velocity=3.60\n",
      "Step 53: Brake action applied! Velocity: 3.60\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0638\n",
      "Step 53: Action: 4, Reward: 1.6440, Total Reward: 66.8583, Epsilon: 0.829\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.56, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.56, Min Distance=0.00\n",
      "Moving: Velocity=3.56\n",
      "Step 54: Brake action applied! Velocity: 3.56\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2113\n",
      "Step 54: Action: 4, Reward: 1.6425, Total Reward: 68.5008, Epsilon: 0.828\n",
      "Q-values: [1.3829815 1.2412926 1.1637591 1.174554  1.6132153]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.53, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.53, Min Distance=0.00\n",
      "Moving: Velocity=3.53\n",
      "Step 55: Brake action applied! Velocity: 3.53\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2203\n",
      "Step 55: Action: 4, Reward: 1.6411, Total Reward: 70.1419, Epsilon: 0.828\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.61\n",
      "Intersection detected: Velocity=3.61, Min Distance=0.00\n",
      "Moving: Velocity=3.61\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0649\n",
      "Step 56: Action: 3, Reward: 1.1044, Total Reward: 71.2463, Epsilon: 0.827\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.61\n",
      "Intersection detected: Velocity=3.61, Min Distance=0.00\n",
      "Moving: Velocity=3.61\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0734\n",
      "Step 57: Action: 2, Reward: 1.1046, Total Reward: 72.3508, Epsilon: 0.827\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.90\n",
      "Intersection detected: Velocity=3.90, Min Distance=0.00\n",
      "Moving: Velocity=3.90\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1509\n",
      "Step 58: Action: 0, Reward: 1.1161, Total Reward: 73.4669, Epsilon: 0.826\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.97\n",
      "Intersection detected: Velocity=3.97, Min Distance=0.00\n",
      "Moving: Velocity=3.97\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0393\n",
      "Step 59: Action: 3, Reward: 1.1189, Total Reward: 74.5858, Epsilon: 0.826\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.24\n",
      "Intersection detected: Velocity=4.24, Min Distance=0.00\n",
      "Moving: Velocity=4.24\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1830\n",
      "Step 60: Action: 0, Reward: 1.1297, Total Reward: 75.7155, Epsilon: 0.825\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.29\n",
      "Intersection detected: Velocity=4.29, Min Distance=0.00\n",
      "Moving: Velocity=4.29\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0500\n",
      "Step 61: Action: 2, Reward: 1.1316, Total Reward: 76.8471, Epsilon: 0.825\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.25\n",
      "Intersection detected: Velocity=4.25, Min Distance=0.00\n",
      "Moving: Velocity=4.25\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0625\n",
      "Step 62: Action: 1, Reward: 1.1298, Total Reward: 77.9769, Epsilon: 0.824\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.21\n",
      "Intersection detected: Velocity=4.21, Min Distance=0.00\n",
      "Moving: Velocity=4.21\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1804\n",
      "Step 63: Action: 1, Reward: 1.4283, Total Reward: 79.4053, Epsilon: 0.824\n",
      "Q-values: [1.4456375 1.3446943 1.1515276 1.2685852 1.5816509]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.17, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.17, Min Distance=0.00\n",
      "Moving: Velocity=4.17\n",
      "Step 64: Brake action applied! Velocity: 4.17\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2596\n",
      "Step 64: Action: 4, Reward: 1.6669, Total Reward: 81.0722, Epsilon: 0.823\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.14, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.14, Min Distance=0.00\n",
      "Moving: Velocity=4.14\n",
      "Step 65: Brake action applied! Velocity: 4.14\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0763\n",
      "Step 65: Action: 4, Reward: 1.6654, Total Reward: 82.7376, Epsilon: 0.823\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.20\n",
      "Intersection detected: Velocity=4.20, Min Distance=0.00\n",
      "Moving: Velocity=4.20\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2137\n",
      "Step 66: Action: 3, Reward: 1.1279, Total Reward: 83.8656, Epsilon: 0.822\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.46\n",
      "Intersection detected: Velocity=4.46, Min Distance=0.00\n",
      "Moving: Velocity=4.46\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1722\n",
      "Step 67: Action: 0, Reward: 1.1386, Total Reward: 85.0041, Epsilon: 0.822\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.43\n",
      "Intersection detected: Velocity=4.43, Min Distance=0.00\n",
      "Moving: Velocity=4.43\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2133\n",
      "Step 68: Action: 1, Reward: 1.4371, Total Reward: 86.4412, Epsilon: 0.821\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.39, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.39, Min Distance=0.00\n",
      "Moving: Velocity=4.39\n",
      "Step 69: Brake action applied! Velocity: 4.39\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0691\n",
      "Step 69: Action: 4, Reward: 1.6757, Total Reward: 88.1169, Epsilon: 0.821\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.45\n",
      "Intersection detected: Velocity=4.45, Min Distance=0.00\n",
      "Moving: Velocity=4.45\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0823\n",
      "Step 70: Action: 2, Reward: 1.1379, Total Reward: 89.2548, Epsilon: 0.820\n",
      "Q-values: [1.321057  1.2485946 1.1484629 1.2037598 1.5296872]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.40, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.40, Min Distance=0.00\n",
      "Moving: Velocity=4.40\n",
      "Step 71: Brake action applied! Velocity: 4.40\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0616\n",
      "Step 71: Action: 4, Reward: 1.3758, Total Reward: 90.6306, Epsilon: 0.820\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.36, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.36, Min Distance=0.00\n",
      "Moving: Velocity=4.36\n",
      "Step 72: Brake action applied! Velocity: 4.36\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0804\n",
      "Step 72: Action: 4, Reward: 1.6743, Total Reward: 92.3049, Epsilon: 0.819\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.41\n",
      "Intersection detected: Velocity=4.41, Min Distance=0.00\n",
      "Moving: Velocity=4.41\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0433\n",
      "Step 73: Action: 3, Reward: 1.1365, Total Reward: 93.4414, Epsilon: 0.819\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.42\n",
      "Intersection detected: Velocity=4.42, Min Distance=0.00\n",
      "Moving: Velocity=4.42\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1995\n",
      "Step 74: Action: 2, Reward: 1.1367, Total Reward: 94.5781, Epsilon: 0.818\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.70\n",
      "Intersection detected: Velocity=4.70, Min Distance=0.00\n",
      "Moving: Velocity=4.70\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0625\n",
      "Step 75: Action: 0, Reward: 1.1482, Total Reward: 95.7263, Epsilon: 0.818\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.67, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.67, Min Distance=0.00\n",
      "Moving: Velocity=4.67\n",
      "Step 76: Brake action applied! Velocity: 4.67\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1929\n",
      "Step 76: Action: 4, Reward: 1.6867, Total Reward: 97.4130, Epsilon: 0.817\n",
      "Q-values: [1.403607  1.3660016 1.2585044 1.2124798 1.6768174]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.63, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.63, Min Distance=0.00\n",
      "Moving: Velocity=4.63\n",
      "Step 77: Brake action applied! Velocity: 4.63\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0424\n",
      "Step 77: Action: 4, Reward: 1.6853, Total Reward: 99.0983, Epsilon: 0.817\n",
      "Q-values: [1.3944083 1.3678447 1.2511206 1.1922256 1.6715281]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.60, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.60, Min Distance=0.00\n",
      "Moving: Velocity=4.60\n",
      "Step 78: Brake action applied! Velocity: 4.60\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0607\n",
      "Step 78: Action: 4, Reward: 1.6838, Total Reward: 100.7821, Epsilon: 0.816\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.56\n",
      "Intersection detected: Velocity=4.56, Min Distance=0.00\n",
      "Moving: Velocity=4.56\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0461\n",
      "Step 79: Action: 1, Reward: 1.4424, Total Reward: 102.2245, Epsilon: 0.816\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.61\n",
      "Intersection detected: Velocity=4.61, Min Distance=0.00\n",
      "Moving: Velocity=4.61\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0621\n",
      "Step 80: Action: 3, Reward: 1.1444, Total Reward: 103.3689, Epsilon: 0.815\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.62\n",
      "Intersection detected: Velocity=4.62, Min Distance=0.00\n",
      "Moving: Velocity=4.62\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1061\n",
      "Step 81: Action: 2, Reward: 1.1447, Total Reward: 104.5136, Epsilon: 0.815\n",
      "Q-values: [1.3733512 1.3680147 1.227607  1.1488144 1.6567852]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.58, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.58, Min Distance=0.00\n",
      "Moving: Velocity=4.58\n",
      "Step 82: Brake action applied! Velocity: 4.58\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0625\n",
      "Step 82: Action: 4, Reward: 1.3832, Total Reward: 105.8968, Epsilon: 0.814\n",
      "Q-values: [1.3705215 1.3669593 1.2207866 1.1437625 1.6564217]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.54, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.54, Min Distance=0.00\n",
      "Moving: Velocity=4.54\n",
      "Step 83: Brake action applied! Velocity: 4.54\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0434\n",
      "Step 83: Action: 4, Reward: 1.6817, Total Reward: 107.5785, Epsilon: 0.814\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.51\n",
      "Intersection detected: Velocity=4.51, Min Distance=0.00\n",
      "Moving: Velocity=4.51\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3410\n",
      "Step 84: Action: 1, Reward: 1.4403, Total Reward: 109.0188, Epsilon: 0.813\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.47\n",
      "Intersection detected: Velocity=4.47, Min Distance=0.00\n",
      "Moving: Velocity=4.47\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2322\n",
      "Step 85: Action: 1, Reward: 1.4388, Total Reward: 110.4576, Epsilon: 0.813\n",
      "Q-values: [1.3277109 1.3086406 1.1695318 1.111798  1.6036396]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.43, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.43, Min Distance=0.00\n",
      "Moving: Velocity=4.43\n",
      "Step 86: Brake action applied! Velocity: 4.43\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1605\n",
      "Step 86: Action: 4, Reward: 1.6774, Total Reward: 112.1350, Epsilon: 0.812\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.49\n",
      "Intersection detected: Velocity=4.49, Min Distance=0.00\n",
      "Moving: Velocity=4.49\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0326\n",
      "Step 87: Action: 2, Reward: 1.1396, Total Reward: 113.2746, Epsilon: 0.812\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.49\n",
      "Intersection detected: Velocity=4.49, Min Distance=0.00\n",
      "Moving: Velocity=4.49\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0720\n",
      "Step 88: Action: 3, Reward: 1.1398, Total Reward: 114.4143, Epsilon: 0.811\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.56\n",
      "Intersection detected: Velocity=4.56, Min Distance=0.00\n",
      "Moving: Velocity=4.56\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2443\n",
      "Step 89: Action: 3, Reward: 1.4422, Total Reward: 115.8566, Epsilon: 0.811\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.50\n",
      "Intersection detected: Velocity=4.50, Min Distance=0.00\n",
      "Moving: Velocity=4.50\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1703\n",
      "Step 90: Action: 1, Reward: 1.1401, Total Reward: 116.9967, Epsilon: 0.810\n",
      "Q-values: [1.3357242 1.2675567 1.1516395 1.0880835 1.5937427]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.47, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.47, Min Distance=0.00\n",
      "Moving: Velocity=4.47\n",
      "Step 91: Brake action applied! Velocity: 4.47\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3548\n",
      "Step 91: Action: 4, Reward: 1.6786, Total Reward: 118.6753, Epsilon: 0.810\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.52\n",
      "Intersection detected: Velocity=4.52, Min Distance=0.00\n",
      "Moving: Velocity=4.52\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1756\n",
      "Step 92: Action: 3, Reward: 1.1409, Total Reward: 119.8162, Epsilon: 0.809\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.79\n",
      "Intersection detected: Velocity=4.79, Min Distance=0.00\n",
      "Moving: Velocity=4.79\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0470\n",
      "Step 93: Action: 0, Reward: 1.1515, Total Reward: 120.9678, Epsilon: 0.809\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.83\n",
      "Intersection detected: Velocity=4.83, Min Distance=0.00\n",
      "Moving: Velocity=4.83\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0634\n",
      "Step 94: Action: 2, Reward: 1.1532, Total Reward: 122.1209, Epsilon: 0.808\n",
      "Q-values: [1.3824742 1.2745625 1.1953247 1.1546165 1.6276917]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.79, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.79, Min Distance=0.00\n",
      "Moving: Velocity=4.79\n",
      "Step 95: Brake action applied! Velocity: 4.79\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2286\n",
      "Step 95: Action: 4, Reward: 1.3915, Total Reward: 123.5124, Epsilon: 0.808\n",
      "Q-values: [1.4037614 1.2803258 1.2050601 1.1794652 1.6412636]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.75, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.75, Min Distance=0.00\n",
      "Moving: Velocity=4.75\n",
      "Step 96: Brake action applied! Velocity: 4.75\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3332\n",
      "Step 96: Action: 4, Reward: 1.6900, Total Reward: 125.2024, Epsilon: 0.807\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.71, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.71, Min Distance=0.00\n",
      "Moving: Velocity=4.71\n",
      "Step 97: Brake action applied! Velocity: 4.71\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1942\n",
      "Step 97: Action: 4, Reward: 1.6885, Total Reward: 126.8909, Epsilon: 0.807\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.76\n",
      "Intersection detected: Velocity=4.76, Min Distance=0.00\n",
      "Moving: Velocity=4.76\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1945\n",
      "Step 98: Action: 3, Reward: 1.1505, Total Reward: 128.0414, Epsilon: 0.806\n",
      "Q-values: [1.3798355 1.2299329 1.1885287 1.1758888 1.6214001]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.71, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.71, Min Distance=0.00\n",
      "Moving: Velocity=4.71\n",
      "Step 99: Brake action applied! Velocity: 4.71\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0530\n",
      "Step 99: Action: 4, Reward: 1.3885, Total Reward: 129.4299, Epsilon: 0.806\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.00\n",
      "Intersection detected: Velocity=5.00, Min Distance=0.00\n",
      "Moving: Velocity=5.00\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0698\n",
      "Step 100: Action: 0, Reward: 1.4600, Total Reward: 130.8899, Epsilon: 0.805\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.05\n",
      "Intersection detected: Velocity=5.05, Min Distance=0.00\n",
      "Moving: Velocity=5.05\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1782\n",
      "Step 101: Action: 3, Reward: 1.1621, Total Reward: 132.0520, Epsilon: 0.805\n",
      "Q-values: [1.3703617 1.2346803 1.1905441 1.1773593 1.6221774]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.01, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.01, Min Distance=0.00\n",
      "Moving: Velocity=5.01\n",
      "Step 102: Brake action applied! Velocity: 5.01\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0418\n",
      "Step 102: Action: 4, Reward: 1.4002, Total Reward: 133.4522, Epsilon: 0.804\n",
      "Q-values: [1.3766682 1.2513709 1.1971875 1.1837654 1.6326593]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.97, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.97, Min Distance=0.00\n",
      "Moving: Velocity=4.97\n",
      "Step 103: Brake action applied! Velocity: 4.97\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0434\n",
      "Step 103: Action: 4, Reward: 1.6988, Total Reward: 135.1510, Epsilon: 0.804\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.26\n",
      "Intersection detected: Velocity=5.26, Min Distance=0.00\n",
      "Moving: Velocity=5.26\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1706\n",
      "Step 104: Action: 0, Reward: 1.4703, Total Reward: 136.6212, Epsilon: 0.803\n",
      "Q-values: [1.4013709 1.2976648 1.223947  1.2056845 1.6698642]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.22, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.22, Min Distance=0.00\n",
      "Moving: Velocity=5.22\n",
      "Step 105: Brake action applied! Velocity: 5.22\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0511\n",
      "Step 105: Action: 4, Reward: 1.7088, Total Reward: 138.3300, Epsilon: 0.803\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.18, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.18, Min Distance=0.00\n",
      "Moving: Velocity=5.18\n",
      "Step 106: Brake action applied! Velocity: 5.18\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0572\n",
      "Step 106: Action: 4, Reward: 1.7073, Total Reward: 140.0374, Epsilon: 0.802\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.22\n",
      "Intersection detected: Velocity=5.22, Min Distance=0.00\n",
      "Moving: Velocity=5.22\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2093\n",
      "Step 107: Action: 2, Reward: 1.1689, Total Reward: 141.2063, Epsilon: 0.802\n",
      "Q-values: [1.3930371 1.3321037 1.2292163 1.2114258 1.6766629]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.18, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.18, Min Distance=0.00\n",
      "Moving: Velocity=5.18\n",
      "Step 108: Brake action applied! Velocity: 5.18\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1656\n",
      "Step 108: Action: 4, Reward: 1.4071, Total Reward: 142.6134, Epsilon: 0.802\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.14\n",
      "Intersection detected: Velocity=5.14, Min Distance=0.00\n",
      "Moving: Velocity=5.14\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0753\n",
      "Step 109: Action: 1, Reward: 1.4656, Total Reward: 144.0790, Epsilon: 0.801\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.10\n",
      "Intersection detected: Velocity=5.10, Min Distance=0.00\n",
      "Moving: Velocity=5.10\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0623\n",
      "Step 110: Action: 1, Reward: 1.4641, Total Reward: 145.5431, Epsilon: 0.801\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.07, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.07, Min Distance=0.00\n",
      "Moving: Velocity=5.07\n",
      "Step 111: Brake action applied! Velocity: 5.07\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1759\n",
      "Step 111: Action: 4, Reward: 1.7027, Total Reward: 147.2458, Epsilon: 0.800\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.03\n",
      "Intersection detected: Velocity=5.03, Min Distance=0.00\n",
      "Moving: Velocity=5.03\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0747\n",
      "Step 112: Action: 1, Reward: 1.4612, Total Reward: 148.7071, Epsilon: 0.800\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.99, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.99, Min Distance=0.00\n",
      "Moving: Velocity=4.99\n",
      "Step 113: Brake action applied! Velocity: 4.99\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0562\n",
      "Step 113: Action: 4, Reward: 1.6998, Total Reward: 150.4068, Epsilon: 0.799\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.04\n",
      "Intersection detected: Velocity=5.04, Min Distance=0.00\n",
      "Moving: Velocity=5.04\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1607\n",
      "Step 114: Action: 2, Reward: 1.1615, Total Reward: 151.5684, Epsilon: 0.799\n",
      "Q-values: [1.3213059 1.3454362 1.164058  1.1169473 1.6021032]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.99, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.99, Min Distance=0.00\n",
      "Moving: Velocity=4.99\n",
      "Step 115: Brake action applied! Velocity: 4.99\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0419\n",
      "Step 115: Action: 4, Reward: 1.3997, Total Reward: 152.9681, Epsilon: 0.798\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.05\n",
      "Intersection detected: Velocity=5.05, Min Distance=0.00\n",
      "Moving: Velocity=5.05\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1672\n",
      "Step 116: Action: 2, Reward: 1.1619, Total Reward: 154.1300, Epsilon: 0.798\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.00, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.00, Min Distance=0.00\n",
      "Moving: Velocity=5.00\n",
      "Step 117: Brake action applied! Velocity: 5.00\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3366\n",
      "Step 117: Action: 4, Reward: 1.3998, Total Reward: 155.5298, Epsilon: 0.797\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.28\n",
      "Intersection detected: Velocity=5.28, Min Distance=0.00\n",
      "Moving: Velocity=5.28\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1338\n",
      "Step 118: Action: 0, Reward: 1.4713, Total Reward: 157.0011, Epsilon: 0.797\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.57\n",
      "Intersection detected: Velocity=5.57, Min Distance=0.00\n",
      "Off-road detected: Penalty applied\n",
      "Moving: Velocity=5.57\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0359\n",
      "Step 119: Action: 0, Reward: -1.4172, Total Reward: 155.5839, Epsilon: 0.796\n",
      "Episode 4 ended early: Terminated=True, Truncated=False\n",
      "Episode 4 completed. Total Reward: 155.5839\n",
      "Episode 5 started\n",
      "Initial observation shape: (259,)\n",
      "Q-values: [1.3692578 1.3992444 1.2014172 1.1105384 1.6334958]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.03, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.03, Min Distance=0.00\n",
      "Step 1: Brake action applied! Velocity: 0.03\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0388\n",
      "Step 1: Action: 4, Reward: 1.5010, Total Reward: 1.5010, Epsilon: 0.796\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.04\n",
      "Intersection detected: Velocity=0.04, Min Distance=0.00\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1740\n",
      "Step 2: Action: 1, Reward: 1.2617, Total Reward: 2.7627, Epsilon: 0.795\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.02\n",
      "Intersection detected: Velocity=0.02, Min Distance=0.00\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0733\n",
      "Step 3: Action: 1, Reward: 1.2608, Total Reward: 4.0235, Epsilon: 0.795\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.31\n",
      "Intersection detected: Velocity=0.31, Min Distance=0.00\n",
      "Moving: Velocity=0.31\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0331\n",
      "Step 4: Action: 0, Reward: 1.2723, Total Reward: 5.2958, Epsilon: 0.794\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.57\n",
      "Intersection detected: Velocity=0.57, Min Distance=0.00\n",
      "Moving: Velocity=0.57\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0386\n",
      "Step 5: Action: 2, Reward: 0.9829, Total Reward: 6.2786, Epsilon: 0.794\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.53, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.53, Min Distance=0.00\n",
      "Moving: Velocity=0.53\n",
      "Step 6: Brake action applied! Velocity: 0.53\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1654\n",
      "Step 6: Action: 4, Reward: 1.2211, Total Reward: 7.4997, Epsilon: 0.793\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.79\n",
      "Intersection detected: Velocity=0.79, Min Distance=0.00\n",
      "Moving: Velocity=0.79\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0401\n",
      "Step 7: Action: 2, Reward: 0.9916, Total Reward: 8.4912, Epsilon: 0.793\n",
      "Q-values: [1.3853042 1.3920219 1.2068796 1.1676445 1.5939627]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.74, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.74, Min Distance=0.00\n",
      "Moving: Velocity=0.74\n",
      "Step 8: Brake action applied! Velocity: 0.74\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0791\n",
      "Step 8: Action: 4, Reward: 1.2297, Total Reward: 9.7209, Epsilon: 0.792\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.00\n",
      "Intersection detected: Velocity=1.00, Min Distance=0.00\n",
      "Moving: Velocity=1.00\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0635\n",
      "Step 9: Action: 2, Reward: 0.9998, Total Reward: 10.7207, Epsilon: 0.792\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.27\n",
      "Intersection detected: Velocity=1.27, Min Distance=0.00\n",
      "Moving: Velocity=1.27\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0658\n",
      "Step 10: Action: 0, Reward: 1.0108, Total Reward: 11.7315, Epsilon: 0.791\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.47\n",
      "Intersection detected: Velocity=1.47, Min Distance=0.00\n",
      "Moving: Velocity=1.47\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0487\n",
      "Step 11: Action: 3, Reward: 1.0188, Total Reward: 12.7503, Epsilon: 0.791\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.58\n",
      "Intersection detected: Velocity=1.58, Min Distance=0.00\n",
      "Moving: Velocity=1.58\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0519\n",
      "Step 12: Action: 2, Reward: 1.0231, Total Reward: 13.7734, Epsilon: 0.790\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.71\n",
      "Intersection detected: Velocity=1.71, Min Distance=0.00\n",
      "Moving: Velocity=1.71\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1530\n",
      "Step 13: Action: 3, Reward: 1.0286, Total Reward: 14.8020, Epsilon: 0.790\n",
      "Q-values: [1.4000989 1.3893849 1.2403423 1.250561  1.6282777]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.67, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.67, Min Distance=0.00\n",
      "Moving: Velocity=1.67\n",
      "Step 14: Brake action applied! Velocity: 1.67\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1876\n",
      "Step 14: Action: 4, Reward: 1.2666, Total Reward: 16.0686, Epsilon: 0.789\n",
      "Q-values: [1.3957043 1.3788476 1.2338158 1.2461176 1.6227673]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.63, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.63, Min Distance=0.00\n",
      "Moving: Velocity=1.63\n",
      "Step 15: Brake action applied! Velocity: 1.63\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1642\n",
      "Step 15: Action: 4, Reward: 1.5651, Total Reward: 17.6337, Epsilon: 0.789\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.59, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.59, Min Distance=0.00\n",
      "Moving: Velocity=1.59\n",
      "Step 16: Brake action applied! Velocity: 1.59\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0683\n",
      "Step 16: Action: 4, Reward: 1.5637, Total Reward: 19.1974, Epsilon: 0.788\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.88\n",
      "Intersection detected: Velocity=1.88, Min Distance=0.00\n",
      "Moving: Velocity=1.88\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3000\n",
      "Step 17: Action: 0, Reward: 1.3352, Total Reward: 20.5326, Epsilon: 0.788\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.84, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.84, Min Distance=0.00\n",
      "Moving: Velocity=1.84\n",
      "Step 18: Brake action applied! Velocity: 1.84\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1749\n",
      "Step 18: Action: 4, Reward: 1.5737, Total Reward: 22.1063, Epsilon: 0.787\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.13\n",
      "Intersection detected: Velocity=2.13, Min Distance=0.00\n",
      "Moving: Velocity=2.13\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2014\n",
      "Step 19: Action: 0, Reward: 1.3452, Total Reward: 23.4515, Epsilon: 0.787\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.29\n",
      "Intersection detected: Velocity=2.29, Min Distance=0.00\n",
      "Moving: Velocity=2.29\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0740\n",
      "Step 20: Action: 2, Reward: 1.0517, Total Reward: 24.5032, Epsilon: 0.786\n",
      "Q-values: [1.2758944 1.292266  1.1741282 1.1759691 1.546797 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.23, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.23, Min Distance=0.00\n",
      "Moving: Velocity=2.23\n",
      "Step 21: Brake action applied! Velocity: 2.23\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1869\n",
      "Step 21: Action: 4, Reward: 1.2894, Total Reward: 25.7926, Epsilon: 0.786\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.36\n",
      "Intersection detected: Velocity=2.36, Min Distance=0.00\n",
      "Moving: Velocity=2.36\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0558\n",
      "Step 22: Action: 3, Reward: 1.0544, Total Reward: 26.8470, Epsilon: 0.785\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.30\n",
      "Intersection detected: Velocity=2.30, Min Distance=0.00\n",
      "Moving: Velocity=2.30\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0668\n",
      "Step 23: Action: 1, Reward: 1.0522, Total Reward: 27.8992, Epsilon: 0.785\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.49\n",
      "Intersection detected: Velocity=2.49, Min Distance=0.00\n",
      "Moving: Velocity=2.49\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2054\n",
      "Step 24: Action: 3, Reward: 1.0596, Total Reward: 28.9588, Epsilon: 0.784\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.42, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.42, Min Distance=0.00\n",
      "Moving: Velocity=2.42\n",
      "Step 25: Brake action applied! Velocity: 2.42\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1753\n",
      "Step 25: Action: 4, Reward: 1.2970, Total Reward: 30.2558, Epsilon: 0.784\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.61\n",
      "Intersection detected: Velocity=2.61, Min Distance=0.00\n",
      "Moving: Velocity=2.61\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1880\n",
      "Step 26: Action: 3, Reward: 1.0643, Total Reward: 31.3200, Epsilon: 0.783\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.86\n",
      "Intersection detected: Velocity=2.86, Min Distance=0.00\n",
      "Moving: Velocity=2.86\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1793\n",
      "Step 27: Action: 0, Reward: 1.0743, Total Reward: 32.3944, Epsilon: 0.783\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.94\n",
      "Intersection detected: Velocity=2.94, Min Distance=0.00\n",
      "Moving: Velocity=2.94\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0334\n",
      "Step 28: Action: 2, Reward: 1.0776, Total Reward: 33.4720, Epsilon: 0.782\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.89\n",
      "Intersection detected: Velocity=2.89, Min Distance=0.00\n",
      "Moving: Velocity=2.89\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0395\n",
      "Step 29: Action: 1, Reward: 1.0756, Total Reward: 34.5476, Epsilon: 0.782\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.04\n",
      "Intersection detected: Velocity=3.04, Min Distance=0.00\n",
      "Moving: Velocity=3.04\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0545\n",
      "Step 30: Action: 2, Reward: 1.0815, Total Reward: 35.6291, Epsilon: 0.781\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.97\n",
      "Intersection detected: Velocity=2.97, Min Distance=0.00\n",
      "Moving: Velocity=2.97\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2076\n",
      "Step 31: Action: 1, Reward: 1.0789, Total Reward: 36.7080, Epsilon: 0.781\n",
      "Q-values: [1.3401961 1.3155763 1.170709  1.1547613 1.6214945]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.93, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.93, Min Distance=0.00\n",
      "Moving: Velocity=2.93\n",
      "Step 32: Brake action applied! Velocity: 2.93\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1374\n",
      "Step 32: Action: 4, Reward: 1.6174, Total Reward: 38.3253, Epsilon: 0.780\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.90\n",
      "Intersection detected: Velocity=2.90, Min Distance=0.00\n",
      "Moving: Velocity=2.90\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0385\n",
      "Step 33: Action: 1, Reward: 1.3759, Total Reward: 39.7013, Epsilon: 0.780\n",
      "Q-values: [1.3535823 1.3213779 1.1705608 1.1483393 1.6288528]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.86, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.86, Min Distance=0.00\n",
      "Moving: Velocity=2.86\n",
      "Step 34: Brake action applied! Velocity: 2.86\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0378\n",
      "Step 34: Action: 4, Reward: 1.6145, Total Reward: 41.3157, Epsilon: 0.779\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.98\n",
      "Intersection detected: Velocity=2.98, Min Distance=0.00\n",
      "Moving: Velocity=2.98\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0491\n",
      "Step 35: Action: 3, Reward: 1.0792, Total Reward: 42.3949, Epsilon: 0.779\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.23\n",
      "Intersection detected: Velocity=3.23, Min Distance=0.00\n",
      "Moving: Velocity=3.23\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0540\n",
      "Step 36: Action: 0, Reward: 1.0894, Total Reward: 43.4843, Epsilon: 0.778\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.52\n",
      "Intersection detected: Velocity=3.52, Min Distance=0.00\n",
      "Moving: Velocity=3.52\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0372\n",
      "Step 37: Action: 0, Reward: 1.4008, Total Reward: 44.8851, Epsilon: 0.778\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.81\n",
      "Intersection detected: Velocity=3.81, Min Distance=0.00\n",
      "Moving: Velocity=3.81\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0903\n",
      "Step 38: Action: 0, Reward: 1.4123, Total Reward: 46.2974, Epsilon: 0.777\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.09\n",
      "Intersection detected: Velocity=4.09, Min Distance=0.00\n",
      "Moving: Velocity=4.09\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0371\n",
      "Step 39: Action: 0, Reward: 1.4238, Total Reward: 47.7211, Epsilon: 0.777\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.06\n",
      "Intersection detected: Velocity=4.06, Min Distance=0.00\n",
      "Moving: Velocity=4.06\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0561\n",
      "Step 40: Action: 1, Reward: 1.4223, Total Reward: 49.1435, Epsilon: 0.776\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.34\n",
      "Intersection detected: Velocity=4.34, Min Distance=0.00\n",
      "Moving: Velocity=4.34\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0589\n",
      "Step 41: Action: 0, Reward: 1.4338, Total Reward: 50.5773, Epsilon: 0.776\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.40\n",
      "Intersection detected: Velocity=4.40, Min Distance=0.00\n",
      "Moving: Velocity=4.40\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2162\n",
      "Step 42: Action: 2, Reward: 1.1362, Total Reward: 51.7134, Epsilon: 0.775\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.36\n",
      "Intersection detected: Velocity=4.36, Min Distance=0.00\n",
      "Moving: Velocity=4.36\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0565\n",
      "Step 43: Action: 1, Reward: 1.1342, Total Reward: 52.8476, Epsilon: 0.775\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.64\n",
      "Intersection detected: Velocity=4.64, Min Distance=0.00\n",
      "Moving: Velocity=4.64\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1604\n",
      "Step 44: Action: 0, Reward: 1.4457, Total Reward: 54.2933, Epsilon: 0.774\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.61\n",
      "Intersection detected: Velocity=4.61, Min Distance=0.00\n",
      "Moving: Velocity=4.61\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3447\n",
      "Step 45: Action: 1, Reward: 1.4442, Total Reward: 55.7375, Epsilon: 0.774\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.66\n",
      "Intersection detected: Velocity=4.66, Min Distance=0.00\n",
      "Moving: Velocity=4.66\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1843\n",
      "Step 46: Action: 3, Reward: 1.1463, Total Reward: 56.8838, Epsilon: 0.773\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.66\n",
      "Intersection detected: Velocity=4.66, Min Distance=0.00\n",
      "Moving: Velocity=4.66\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0657\n",
      "Step 47: Action: 2, Reward: 1.1464, Total Reward: 58.0302, Epsilon: 0.773\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.70\n",
      "Intersection detected: Velocity=4.70, Min Distance=0.00\n",
      "Moving: Velocity=4.70\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0696\n",
      "Step 48: Action: 3, Reward: 1.1481, Total Reward: 59.1784, Epsilon: 0.772\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.66, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.66, Min Distance=0.00\n",
      "Moving: Velocity=4.66\n",
      "Step 49: Brake action applied! Velocity: 4.66\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1946\n",
      "Step 49: Action: 4, Reward: 1.3863, Total Reward: 60.5646, Epsilon: 0.772\n",
      "Q-values: [1.1950111 1.2531793 1.147925  1.1335106 1.5874649]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.62, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.62, Min Distance=0.00\n",
      "Moving: Velocity=4.62\n",
      "Step 50: Brake action applied! Velocity: 4.62\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0875\n",
      "Step 50: Action: 4, Reward: 1.6848, Total Reward: 62.2494, Epsilon: 0.771\n",
      "Q-values: [1.2265807 1.2829592 1.1735065 1.1633894 1.6198039]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.58, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.58, Min Distance=0.00\n",
      "Moving: Velocity=4.58\n",
      "Step 51: Brake action applied! Velocity: 4.58\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1667\n",
      "Step 51: Action: 4, Reward: 1.6833, Total Reward: 63.9328, Epsilon: 0.771\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.55\n",
      "Intersection detected: Velocity=4.55, Min Distance=0.00\n",
      "Moving: Velocity=4.55\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0530\n",
      "Step 52: Action: 1, Reward: 1.4419, Total Reward: 65.3746, Epsilon: 0.770\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.83\n",
      "Intersection detected: Velocity=4.83, Min Distance=0.00\n",
      "Moving: Velocity=4.83\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0672\n",
      "Step 53: Action: 0, Reward: 1.4534, Total Reward: 66.8280, Epsilon: 0.770\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.89\n",
      "Intersection detected: Velocity=4.89, Min Distance=0.00\n",
      "Moving: Velocity=4.89\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0517\n",
      "Step 54: Action: 3, Reward: 1.1555, Total Reward: 67.9835, Epsilon: 0.769\n",
      "Q-values: [1.3776641 1.3985747 1.2550254 1.2773991 1.708492 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.84, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.84, Min Distance=0.00\n",
      "Moving: Velocity=4.84\n",
      "Step 55: Brake action applied! Velocity: 4.84\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3322\n",
      "Step 55: Action: 4, Reward: 1.3937, Total Reward: 69.3772, Epsilon: 0.769\n",
      "Q-values: [1.3713135 1.3823377 1.2366056 1.2596393 1.6798556]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.80, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.80, Min Distance=0.00\n",
      "Moving: Velocity=4.80\n",
      "Step 56: Brake action applied! Velocity: 4.80\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3038\n",
      "Step 56: Action: 4, Reward: 1.6922, Total Reward: 71.0693, Epsilon: 0.768\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.77\n",
      "Intersection detected: Velocity=4.77, Min Distance=0.00\n",
      "Moving: Velocity=4.77\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0578\n",
      "Step 57: Action: 1, Reward: 1.4507, Total Reward: 72.5201, Epsilon: 0.768\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.73, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.73, Min Distance=0.00\n",
      "Moving: Velocity=4.73\n",
      "Step 58: Brake action applied! Velocity: 4.73\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2016\n",
      "Step 58: Action: 4, Reward: 1.6893, Total Reward: 74.2093, Epsilon: 0.767\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.70\n",
      "Intersection detected: Velocity=4.70, Min Distance=0.00\n",
      "Moving: Velocity=4.70\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1879\n",
      "Step 59: Action: 1, Reward: 1.4478, Total Reward: 75.6572, Epsilon: 0.767\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.66, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.66, Min Distance=0.00\n",
      "Moving: Velocity=4.66\n",
      "Step 60: Brake action applied! Velocity: 4.66\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0601\n",
      "Step 60: Action: 4, Reward: 1.6864, Total Reward: 77.3435, Epsilon: 0.766\n",
      "Q-values: [1.2689946 1.2287763 1.1106642 1.1012685 1.4888623]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.62, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.62, Min Distance=0.00\n",
      "Moving: Velocity=4.62\n",
      "Step 61: Brake action applied! Velocity: 4.62\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2800\n",
      "Step 61: Action: 4, Reward: 1.6849, Total Reward: 79.0285, Epsilon: 0.766\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.67\n",
      "Intersection detected: Velocity=4.67, Min Distance=0.00\n",
      "Moving: Velocity=4.67\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1651\n",
      "Step 62: Action: 3, Reward: 1.1470, Total Reward: 80.1754, Epsilon: 0.765\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.68\n",
      "Intersection detected: Velocity=4.68, Min Distance=0.00\n",
      "Moving: Velocity=4.68\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0536\n",
      "Step 63: Action: 2, Reward: 1.1471, Total Reward: 81.3225, Epsilon: 0.765\n",
      "Q-values: [1.2998189 1.24626   1.1236398 1.1122401 1.4928701]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.64, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.64, Min Distance=0.00\n",
      "Moving: Velocity=4.64\n",
      "Step 64: Brake action applied! Velocity: 4.64\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2068\n",
      "Step 64: Action: 4, Reward: 1.3856, Total Reward: 82.7082, Epsilon: 0.764\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.69\n",
      "Intersection detected: Velocity=4.69, Min Distance=0.00\n",
      "Moving: Velocity=4.69\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0737\n",
      "Step 65: Action: 2, Reward: 1.1477, Total Reward: 83.8559, Epsilon: 0.764\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.64\n",
      "Intersection detected: Velocity=4.64, Min Distance=0.00\n",
      "Moving: Velocity=4.64\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0326\n",
      "Step 66: Action: 1, Reward: 1.1457, Total Reward: 85.0015, Epsilon: 0.763\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.68\n",
      "Intersection detected: Velocity=4.68, Min Distance=0.00\n",
      "Moving: Velocity=4.68\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2941\n",
      "Step 67: Action: 3, Reward: 1.1471, Total Reward: 86.1486, Epsilon: 0.763\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.69\n",
      "Intersection detected: Velocity=4.69, Min Distance=0.00\n",
      "Moving: Velocity=4.69\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1663\n",
      "Step 68: Action: 2, Reward: 1.1474, Total Reward: 87.2960, Epsilon: 0.762\n",
      "Q-values: [1.4340777 1.3946056 1.2387471 1.2431531 1.6546733]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.65, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.65, Min Distance=0.00\n",
      "Moving: Velocity=4.65\n",
      "Step 69: Brake action applied! Velocity: 4.65\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0350\n",
      "Step 69: Action: 4, Reward: 1.3859, Total Reward: 88.6819, Epsilon: 0.762\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.61\n",
      "Intersection detected: Velocity=4.61, Min Distance=0.00\n",
      "Moving: Velocity=4.61\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2000\n",
      "Step 70: Action: 1, Reward: 1.4445, Total Reward: 90.1264, Epsilon: 0.761\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.58\n",
      "Intersection detected: Velocity=4.58, Min Distance=0.00\n",
      "Moving: Velocity=4.58\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1896\n",
      "Step 71: Action: 1, Reward: 1.4430, Total Reward: 91.5694, Epsilon: 0.761\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.63\n",
      "Intersection detected: Velocity=4.63, Min Distance=0.00\n",
      "Moving: Velocity=4.63\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1593\n",
      "Step 72: Action: 2, Reward: 1.1451, Total Reward: 92.7145, Epsilon: 0.760\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.76\n",
      "Intersection detected: Velocity=4.76, Min Distance=0.00\n",
      "Moving: Velocity=4.76\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0528\n",
      "Step 73: Action: 2, Reward: 1.4503, Total Reward: 94.1649, Epsilon: 0.760\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.98\n",
      "Intersection detected: Velocity=4.98, Min Distance=0.00\n",
      "Moving: Velocity=4.98\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0505\n",
      "Step 74: Action: 2, Reward: 1.4592, Total Reward: 95.6240, Epsilon: 0.759\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.91, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.91, Min Distance=0.00\n",
      "Moving: Velocity=4.91\n",
      "Step 75: Brake action applied! Velocity: 4.91\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0578\n",
      "Step 75: Action: 4, Reward: 1.3966, Total Reward: 97.0206, Epsilon: 0.759\n",
      "Q-values: [1.2358992 1.3171873 1.1370451 1.1045291 1.5392798]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.87, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.87, Min Distance=0.00\n",
      "Moving: Velocity=4.87\n",
      "Step 76: Brake action applied! Velocity: 4.87\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0690\n",
      "Step 76: Action: 4, Reward: 1.6948, Total Reward: 98.7154, Epsilon: 0.758\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.92\n",
      "Intersection detected: Velocity=4.92, Min Distance=0.00\n",
      "Moving: Velocity=4.92\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1581\n",
      "Step 77: Action: 2, Reward: 1.1569, Total Reward: 99.8723, Epsilon: 0.758\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.06\n",
      "Intersection detected: Velocity=5.06, Min Distance=0.00\n",
      "Moving: Velocity=5.06\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0501\n",
      "Step 78: Action: 2, Reward: 1.4623, Total Reward: 101.3347, Epsilon: 0.757\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.00, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.00, Min Distance=0.00\n",
      "Moving: Velocity=5.00\n",
      "Step 79: Brake action applied! Velocity: 5.00\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0600\n",
      "Step 79: Action: 4, Reward: 1.3998, Total Reward: 102.7345, Epsilon: 0.757\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.28\n",
      "Intersection detected: Velocity=5.28, Min Distance=0.00\n",
      "Moving: Velocity=5.28\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0723\n",
      "Step 80: Action: 0, Reward: 1.4712, Total Reward: 104.2057, Epsilon: 0.756\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.32\n",
      "Intersection detected: Velocity=5.32, Min Distance=0.00\n",
      "Moving: Velocity=5.32\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0646\n",
      "Step 81: Action: 3, Reward: 1.1727, Total Reward: 105.3784, Epsilon: 0.756\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.27\n",
      "Intersection detected: Velocity=5.27, Min Distance=0.00\n",
      "Moving: Velocity=5.27\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0682\n",
      "Step 82: Action: 1, Reward: 1.1709, Total Reward: 106.5493, Epsilon: 0.755\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.24, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.24, Min Distance=0.00\n",
      "Moving: Velocity=5.24\n",
      "Step 83: Brake action applied! Velocity: 5.24\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0631\n",
      "Step 83: Action: 4, Reward: 1.7095, Total Reward: 108.2588, Epsilon: 0.755\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.20, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.20, Min Distance=0.00\n",
      "Moving: Velocity=5.20\n",
      "Step 84: Brake action applied! Velocity: 5.20\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1417\n",
      "Step 84: Action: 4, Reward: 1.7080, Total Reward: 109.9668, Epsilon: 0.754\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.24\n",
      "Intersection detected: Velocity=5.24, Min Distance=0.00\n",
      "Moving: Velocity=5.24\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.4810\n",
      "Step 85: Action: 3, Reward: 1.1696, Total Reward: 111.1364, Epsilon: 0.754\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.19, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.19, Min Distance=0.00\n",
      "Moving: Velocity=5.19\n",
      "Step 86: Brake action applied! Velocity: 5.19\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0530\n",
      "Step 86: Action: 4, Reward: 1.4077, Total Reward: 112.5441, Epsilon: 0.753\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.16\n",
      "Intersection detected: Velocity=5.16, Min Distance=0.00\n",
      "Moving: Velocity=5.16\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2069\n",
      "Step 87: Action: 1, Reward: 1.4663, Total Reward: 114.0104, Epsilon: 0.753\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.19\n",
      "Intersection detected: Velocity=5.19, Min Distance=0.00\n",
      "Moving: Velocity=5.19\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0374\n",
      "Step 88: Action: 2, Reward: 1.1678, Total Reward: 115.1782, Epsilon: 0.752\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.47\n",
      "Intersection detected: Velocity=5.47, Min Distance=0.00\n",
      "Moving: Velocity=5.47\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0614\n",
      "Step 89: Action: 0, Reward: 1.1786, Total Reward: 116.3568, Epsilon: 0.752\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.75\n",
      "Intersection detected: Velocity=5.75, Min Distance=0.00\n",
      "Moving: Velocity=5.75\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0753\n",
      "Step 90: Action: 0, Reward: 1.4901, Total Reward: 117.8469, Epsilon: 0.752\n",
      "Q-values: [1.2520258 1.310633  1.188502  1.1118482 1.6153607]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.72, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.72, Min Distance=0.00\n",
      "Moving: Velocity=5.72\n",
      "Step 91: Brake action applied! Velocity: 5.72\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0414\n",
      "Step 91: Action: 4, Reward: 1.7287, Total Reward: 119.5756, Epsilon: 0.751\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.68\n",
      "Intersection detected: Velocity=5.68, Min Distance=0.00\n",
      "Moving: Velocity=5.68\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1647\n",
      "Step 92: Action: 1, Reward: 1.4872, Total Reward: 121.0628, Epsilon: 0.751\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.64\n",
      "Intersection detected: Velocity=5.64, Min Distance=0.00\n",
      "Moving: Velocity=5.64\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0752\n",
      "Step 93: Action: 1, Reward: 1.4857, Total Reward: 122.5485, Epsilon: 0.750\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.67\n",
      "Intersection detected: Velocity=5.67, Min Distance=0.00\n",
      "Moving: Velocity=5.67\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1811\n",
      "Step 94: Action: 3, Reward: 1.1870, Total Reward: 123.7355, Epsilon: 0.750\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.68\n",
      "Intersection detected: Velocity=5.68, Min Distance=0.00\n",
      "Moving: Velocity=5.68\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2037\n",
      "Step 95: Action: 2, Reward: 1.1870, Total Reward: 124.9225, Epsilon: 0.749\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.96\n",
      "Intersection detected: Velocity=5.96, Min Distance=0.00\n",
      "Moving: Velocity=5.96\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0394\n",
      "Step 96: Action: 0, Reward: 1.1985, Total Reward: 126.1210, Epsilon: 0.749\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.93\n",
      "Intersection detected: Velocity=5.93, Min Distance=0.00\n",
      "Moving: Velocity=5.93\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1656\n",
      "Step 97: Action: 1, Reward: 1.4971, Total Reward: 127.6181, Epsilon: 0.748\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.89, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.89, Min Distance=0.00\n",
      "Moving: Velocity=5.89\n",
      "Step 98: Brake action applied! Velocity: 5.89\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0445\n",
      "Step 98: Action: 4, Reward: 1.7356, Total Reward: 129.3537, Epsilon: 0.748\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.92\n",
      "Intersection detected: Velocity=5.92, Min Distance=0.00\n",
      "Moving: Velocity=5.92\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0604\n",
      "Step 99: Action: 2, Reward: 1.1967, Total Reward: 130.5504, Epsilon: 0.747\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.19\n",
      "Intersection detected: Velocity=6.19, Min Distance=0.00\n",
      "Moving: Velocity=6.19\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0781\n",
      "Step 100: Action: 0, Reward: 1.2076, Total Reward: 131.7581, Epsilon: 0.747\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.15\n",
      "Intersection detected: Velocity=6.15, Min Distance=0.00\n",
      "Moving: Velocity=6.15\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0516\n",
      "Step 101: Action: 1, Reward: 1.5062, Total Reward: 133.2643, Epsilon: 0.746\n",
      "Q-values: [1.3495482 1.2947644 1.1920214 1.1643946 1.5782247]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.12, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.12, Min Distance=0.00\n",
      "Moving: Velocity=6.12\n",
      "Step 102: Brake action applied! Velocity: 6.12\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1765\n",
      "Step 102: Action: 4, Reward: 1.7447, Total Reward: 135.0090, Epsilon: 0.746\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.08, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.08, Min Distance=0.00\n",
      "Moving: Velocity=6.08\n",
      "Step 103: Brake action applied! Velocity: 6.08\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0267\n",
      "Step 103: Action: 4, Reward: 1.7433, Total Reward: 136.7523, Epsilon: 0.745\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.37\n",
      "Intersection detected: Velocity=6.37, Min Distance=0.00\n",
      "Moving: Velocity=6.37\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0265\n",
      "Step 104: Action: 0, Reward: 1.5148, Total Reward: 138.2670, Epsilon: 0.745\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.33\n",
      "Intersection detected: Velocity=6.33, Min Distance=0.00\n",
      "Moving: Velocity=6.33\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0423\n",
      "Step 105: Action: 1, Reward: 1.5133, Total Reward: 139.7803, Epsilon: 0.744\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.30, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.30, Min Distance=0.00\n",
      "Moving: Velocity=6.30\n",
      "Step 106: Brake action applied! Velocity: 6.30\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0290\n",
      "Step 106: Action: 4, Reward: 1.7518, Total Reward: 141.5322, Epsilon: 0.744\n",
      "Q-values: [1.4981366 1.4207515 1.2385483 1.2237507 1.6695756]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.26, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.26, Min Distance=0.00\n",
      "Moving: Velocity=6.26\n",
      "Step 107: Brake action applied! Velocity: 6.26\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1718\n",
      "Step 107: Action: 4, Reward: 1.7504, Total Reward: 143.2826, Epsilon: 0.743\n",
      "Q-values: [1.5132315 1.4406079 1.2429276 1.2275491 1.6804568]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.22, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.22, Min Distance=0.00\n",
      "Moving: Velocity=6.22\n",
      "Step 108: Brake action applied! Velocity: 6.22\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2150\n",
      "Step 108: Action: 4, Reward: 1.7489, Total Reward: 145.0315, Epsilon: 0.743\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.25\n",
      "Intersection detected: Velocity=6.25, Min Distance=0.00\n",
      "Moving: Velocity=6.25\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0386\n",
      "Step 109: Action: 3, Reward: 1.2100, Total Reward: 146.2415, Epsilon: 0.742\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.21\n",
      "Intersection detected: Velocity=6.21, Min Distance=0.00\n",
      "Moving: Velocity=6.21\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0626\n",
      "Step 110: Action: 1, Reward: 1.2083, Total Reward: 147.4498, Epsilon: 0.742\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.24\n",
      "Intersection detected: Velocity=6.24, Min Distance=0.00\n",
      "Moving: Velocity=6.24\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0375\n",
      "Step 111: Action: 3, Reward: 1.2097, Total Reward: 148.6595, Epsilon: 0.741\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.20, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.20, Min Distance=0.00\n",
      "Moving: Velocity=6.20\n",
      "Step 112: Brake action applied! Velocity: 6.20\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1609\n",
      "Step 112: Action: 4, Reward: 1.4478, Total Reward: 150.1073, Epsilon: 0.741\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.23\n",
      "Intersection detected: Velocity=6.23, Min Distance=0.00\n",
      "Moving: Velocity=6.23\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2040\n",
      "Step 113: Action: 3, Reward: 1.2093, Total Reward: 151.3166, Epsilon: 0.740\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.19, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.19, Min Distance=0.00\n",
      "Moving: Velocity=6.19\n",
      "Step 114: Brake action applied! Velocity: 6.19\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3163\n",
      "Step 114: Action: 4, Reward: 1.4474, Total Reward: 152.7640, Epsilon: 0.740\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.15, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.15, Min Distance=0.00\n",
      "Moving: Velocity=6.15\n",
      "Step 115: Brake action applied! Velocity: 6.15\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3873\n",
      "Step 115: Action: 4, Reward: 1.7460, Total Reward: 154.5100, Epsilon: 0.739\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.18\n",
      "Intersection detected: Velocity=6.18, Min Distance=0.00\n",
      "Moving: Velocity=6.18\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0588\n",
      "Step 116: Action: 2, Reward: 1.2070, Total Reward: 155.7170, Epsilon: 0.739\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.13\n",
      "Intersection detected: Velocity=6.13, Min Distance=0.00\n",
      "Moving: Velocity=6.13\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0473\n",
      "Step 117: Action: 1, Reward: 1.2052, Total Reward: 156.9222, Epsilon: 0.738\n",
      "Q-values: [1.2967488 1.2732474 1.1082662 1.0661347 1.5314761]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.09, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.09, Min Distance=0.00\n",
      "Moving: Velocity=6.09\n",
      "Step 118: Brake action applied! Velocity: 6.09\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1652\n",
      "Step 118: Action: 4, Reward: 1.7438, Total Reward: 158.6660, Epsilon: 0.738\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.12\n",
      "Intersection detected: Velocity=6.12, Min Distance=0.00\n",
      "Moving: Velocity=6.12\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0545\n",
      "Step 119: Action: 2, Reward: 1.2050, Total Reward: 159.8710, Epsilon: 0.737\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.08, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.08, Min Distance=0.00\n",
      "Moving: Velocity=6.08\n",
      "Step 120: Brake action applied! Velocity: 6.08\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2185\n",
      "Step 120: Action: 4, Reward: 1.4432, Total Reward: 161.3141, Epsilon: 0.737\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.37\n",
      "Intersection detected: Velocity=6.37, Min Distance=0.00\n",
      "Moving: Velocity=6.37\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1674\n",
      "Step 121: Action: 0, Reward: 1.5147, Total Reward: 162.8288, Epsilon: 0.736\n",
      "Q-values: [1.3141501 1.336528  1.1938885 1.1303949 1.6118815]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.33, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.33, Min Distance=0.00\n",
      "Moving: Velocity=6.33\n",
      "Step 122: Brake action applied! Velocity: 6.33\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1942\n",
      "Step 122: Action: 4, Reward: 1.7532, Total Reward: 164.5820, Epsilon: 0.736\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.29, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.29, Min Distance=0.00\n",
      "Moving: Velocity=6.29\n",
      "Step 123: Brake action applied! Velocity: 6.29\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0473\n",
      "Step 123: Action: 4, Reward: 1.7517, Total Reward: 166.3337, Epsilon: 0.735\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.32\n",
      "Intersection detected: Velocity=6.32, Min Distance=0.00\n",
      "Moving: Velocity=6.32\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0452\n",
      "Step 124: Action: 3, Reward: 1.2128, Total Reward: 167.5465, Epsilon: 0.735\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.32\n",
      "Intersection detected: Velocity=6.32, Min Distance=0.00\n",
      "Moving: Velocity=6.32\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0635\n",
      "Step 125: Action: 2, Reward: 1.2126, Total Reward: 168.7591, Epsilon: 0.734\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.28, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.28, Min Distance=0.00\n",
      "Moving: Velocity=6.28\n",
      "Step 126: Brake action applied! Velocity: 6.28\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2974\n",
      "Step 126: Action: 4, Reward: 1.4511, Total Reward: 170.2103, Epsilon: 0.734\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.24, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.24, Min Distance=0.00\n",
      "Moving: Velocity=6.24\n",
      "Step 127: Brake action applied! Velocity: 6.24\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0572\n",
      "Step 127: Action: 4, Reward: 1.7497, Total Reward: 171.9600, Epsilon: 0.733\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.27\n",
      "Intersection detected: Velocity=6.27, Min Distance=0.00\n",
      "Moving: Velocity=6.27\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1588\n",
      "Step 128: Action: 2, Reward: 1.2108, Total Reward: 173.1708, Epsilon: 0.733\n",
      "Q-values: [1.1664119 1.2954205 1.1780403 1.0665659 1.5777376]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.23, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.23, Min Distance=0.00\n",
      "Off-road detected: Penalty applied\n",
      "Moving: Velocity=6.23\n",
      "Step 129: Brake action applied! Velocity: 6.23\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0456\n",
      "Step 129: Action: 4, Reward: -1.4509, Total Reward: 171.7198, Epsilon: 0.732\n",
      "Episode 5 ended early: Terminated=True, Truncated=False\n",
      "Episode 5 completed. Total Reward: 171.7198\n",
      "Episode 6 started\n",
      "Initial observation shape: (259,)\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.28\n",
      "Intersection detected: Velocity=0.28, Min Distance=0.00\n",
      "Moving: Velocity=0.28\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0513\n",
      "Step 1: Action: 3, Reward: 0.9712, Total Reward: 0.9712, Epsilon: 0.732\n",
      "Q-values: [1.2437333 1.3803558 1.2404397 1.1368876 1.6667693]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.24, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.24, Min Distance=0.00\n",
      "Moving: Velocity=0.24\n",
      "Step 2: Brake action applied! Velocity: 0.24\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0356\n",
      "Step 2: Action: 4, Reward: 1.2097, Total Reward: 2.1809, Epsilon: 0.731\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.52\n",
      "Intersection detected: Velocity=0.52, Min Distance=0.00\n",
      "Moving: Velocity=0.52\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0500\n",
      "Step 3: Action: 3, Reward: 0.9806, Total Reward: 3.1615, Epsilon: 0.731\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.73\n",
      "Intersection detected: Velocity=0.73, Min Distance=0.00\n",
      "Moving: Velocity=0.73\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1488\n",
      "Step 4: Action: 2, Reward: 0.9893, Total Reward: 4.1508, Epsilon: 0.730\n",
      "Q-values: [1.3135403 1.4397651 1.2722712 1.1792893 1.7229086]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.69, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.69, Min Distance=0.00\n",
      "Moving: Velocity=0.69\n",
      "Step 5: Brake action applied! Velocity: 0.69\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0545\n",
      "Step 5: Action: 4, Reward: 1.2275, Total Reward: 5.3783, Epsilon: 0.730\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.65, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.65, Min Distance=0.00\n",
      "Moving: Velocity=0.65\n",
      "Step 6: Brake action applied! Velocity: 0.65\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3265\n",
      "Step 6: Action: 4, Reward: 1.5260, Total Reward: 6.9044, Epsilon: 0.729\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.94\n",
      "Intersection detected: Velocity=0.94, Min Distance=0.00\n",
      "Moving: Velocity=0.94\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0601\n",
      "Step 7: Action: 0, Reward: 1.2975, Total Reward: 8.2019, Epsilon: 0.729\n",
      "Q-values: [1.3459033 1.4300072 1.2418878 1.1698161 1.7021048]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.90, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.90, Min Distance=0.00\n",
      "Moving: Velocity=0.90\n",
      "Step 8: Brake action applied! Velocity: 0.90\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0494\n",
      "Step 8: Action: 4, Reward: 1.5361, Total Reward: 9.7380, Epsilon: 0.728\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.19\n",
      "Intersection detected: Velocity=1.19, Min Distance=0.00\n",
      "Moving: Velocity=1.19\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0583\n",
      "Step 9: Action: 0, Reward: 1.3075, Total Reward: 11.0455, Epsilon: 0.728\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.15\n",
      "Intersection detected: Velocity=1.15, Min Distance=0.00\n",
      "Moving: Velocity=1.15\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2055\n",
      "Step 10: Action: 1, Reward: 1.3061, Total Reward: 12.3516, Epsilon: 0.727\n",
      "Q-values: [1.3613832 1.399575  1.1948174 1.1458013 1.6623701]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.12, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.12, Min Distance=0.00\n",
      "Moving: Velocity=1.12\n",
      "Step 11: Brake action applied! Velocity: 1.12\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0433\n",
      "Step 11: Action: 4, Reward: 1.5446, Total Reward: 13.8962, Epsilon: 0.727\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.34\n",
      "Intersection detected: Velocity=1.34, Min Distance=0.00\n",
      "Moving: Velocity=1.34\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1433\n",
      "Step 12: Action: 2, Reward: 1.0136, Total Reward: 14.9099, Epsilon: 0.726\n",
      "Q-values: [1.3773358 1.3898374 1.1862055 1.1422211 1.6617782]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.29, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.29, Min Distance=0.00\n",
      "Moving: Velocity=1.29\n",
      "Step 13: Brake action applied! Velocity: 1.29\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2959\n",
      "Step 13: Action: 4, Reward: 1.2515, Total Reward: 16.1613, Epsilon: 0.726\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.57\n",
      "Intersection detected: Velocity=1.57, Min Distance=0.00\n",
      "Moving: Velocity=1.57\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2043\n",
      "Step 14: Action: 0, Reward: 1.3229, Total Reward: 17.4843, Epsilon: 0.725\n",
      "Q-values: [1.3412812 1.3433244 1.1568793 1.1139905 1.6198162]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.54, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.54, Min Distance=0.00\n",
      "Moving: Velocity=1.54\n",
      "Step 15: Brake action applied! Velocity: 1.54\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1737\n",
      "Step 15: Action: 4, Reward: 1.5615, Total Reward: 19.0458, Epsilon: 0.725\n",
      "Q-values: [1.3334619 1.3292941 1.1494055 1.1077238 1.6039491]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.50, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.50, Min Distance=0.00\n",
      "Moving: Velocity=1.50\n",
      "Step 16: Brake action applied! Velocity: 1.50\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1968\n",
      "Step 16: Action: 4, Reward: 1.5600, Total Reward: 20.6058, Epsilon: 0.724\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.46\n",
      "Intersection detected: Velocity=1.46, Min Distance=0.00\n",
      "Moving: Velocity=1.46\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1980\n",
      "Step 17: Action: 1, Reward: 1.3186, Total Reward: 21.9244, Epsilon: 0.724\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.67\n",
      "Intersection detected: Velocity=1.67, Min Distance=0.00\n",
      "Moving: Velocity=1.67\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0543\n",
      "Step 18: Action: 3, Reward: 1.0268, Total Reward: 22.9512, Epsilon: 0.723\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.74\n",
      "Intersection detected: Velocity=1.74, Min Distance=0.00\n",
      "Moving: Velocity=1.74\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0571\n",
      "Step 19: Action: 2, Reward: 1.0298, Total Reward: 23.9809, Epsilon: 0.723\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.98\n",
      "Intersection detected: Velocity=1.98, Min Distance=0.00\n",
      "Moving: Velocity=1.98\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0492\n",
      "Step 20: Action: 2, Reward: 1.3390, Total Reward: 25.3200, Epsilon: 0.722\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.24\n",
      "Intersection detected: Velocity=2.24, Min Distance=0.00\n",
      "Moving: Velocity=2.24\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2983\n",
      "Step 21: Action: 2, Reward: 1.3497, Total Reward: 26.6697, Epsilon: 0.722\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.17\n",
      "Intersection detected: Velocity=2.17, Min Distance=0.00\n",
      "Moving: Velocity=2.17\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0505\n",
      "Step 22: Action: 1, Reward: 1.0468, Total Reward: 27.7165, Epsilon: 0.721\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.29\n",
      "Intersection detected: Velocity=2.29, Min Distance=0.00\n",
      "Moving: Velocity=2.29\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0473\n",
      "Step 23: Action: 3, Reward: 1.0516, Total Reward: 28.7681, Epsilon: 0.721\n",
      "Q-values: [1.4543846 1.367236  1.247506  1.2652739 1.6661358]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.23, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.23, Min Distance=0.00\n",
      "Moving: Velocity=2.23\n",
      "Step 24: Brake action applied! Velocity: 2.23\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0212\n",
      "Step 24: Action: 4, Reward: 1.2893, Total Reward: 30.0574, Epsilon: 0.720\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.42\n",
      "Intersection detected: Velocity=2.42, Min Distance=0.00\n",
      "Moving: Velocity=2.42\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0461\n",
      "Step 25: Action: 3, Reward: 1.0569, Total Reward: 31.1143, Epsilon: 0.720\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.44\n",
      "Intersection detected: Velocity=2.44, Min Distance=0.00\n",
      "Moving: Velocity=2.44\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0578\n",
      "Step 26: Action: 2, Reward: 1.0575, Total Reward: 32.1718, Epsilon: 0.719\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.57\n",
      "Intersection detected: Velocity=2.57, Min Distance=0.00\n",
      "Moving: Velocity=2.57\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3219\n",
      "Step 27: Action: 3, Reward: 1.0629, Total Reward: 33.2348, Epsilon: 0.719\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.52\n",
      "Intersection detected: Velocity=2.52, Min Distance=0.00\n",
      "Moving: Velocity=2.52\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1515\n",
      "Step 28: Action: 1, Reward: 1.0607, Total Reward: 34.2954, Epsilon: 0.718\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.80\n",
      "Intersection detected: Velocity=2.80, Min Distance=0.00\n",
      "Moving: Velocity=2.80\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1667\n",
      "Step 29: Action: 0, Reward: 1.3721, Total Reward: 35.6675, Epsilon: 0.718\n",
      "Q-values: [1.337579  1.2517585 1.1690079 1.1895802 1.5196635]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.77, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.77, Min Distance=0.00\n",
      "Moving: Velocity=2.77\n",
      "Step 30: Brake action applied! Velocity: 2.77\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1792\n",
      "Step 30: Action: 4, Reward: 1.6107, Total Reward: 37.2782, Epsilon: 0.717\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.89\n",
      "Intersection detected: Velocity=2.89, Min Distance=0.00\n",
      "Moving: Velocity=2.89\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0597\n",
      "Step 31: Action: 2, Reward: 1.0756, Total Reward: 38.3538, Epsilon: 0.717\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.15\n",
      "Intersection detected: Velocity=3.15, Min Distance=0.00\n",
      "Moving: Velocity=3.15\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2950\n",
      "Step 32: Action: 0, Reward: 1.0858, Total Reward: 39.4396, Epsilon: 0.716\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.28\n",
      "Intersection detected: Velocity=3.28, Min Distance=0.00\n",
      "Moving: Velocity=3.28\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0504\n",
      "Step 33: Action: 2, Reward: 1.0912, Total Reward: 40.5309, Epsilon: 0.716\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.22, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.22, Min Distance=0.00\n",
      "Moving: Velocity=3.22\n",
      "Step 34: Brake action applied! Velocity: 3.22\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1488\n",
      "Step 34: Action: 4, Reward: 1.3287, Total Reward: 41.8596, Epsilon: 0.715\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.18\n",
      "Intersection detected: Velocity=3.18, Min Distance=0.00\n",
      "Moving: Velocity=3.18\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0534\n",
      "Step 35: Action: 1, Reward: 1.3872, Total Reward: 43.2468, Epsilon: 0.715\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.14\n",
      "Intersection detected: Velocity=3.14, Min Distance=0.00\n",
      "Moving: Velocity=3.14\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0496\n",
      "Step 36: Action: 1, Reward: 1.3858, Total Reward: 44.6326, Epsilon: 0.714\n",
      "Q-values: [1.4300436 1.3876097 1.2738307 1.2681897 1.6630965]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.11, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.11, Min Distance=0.00\n",
      "Moving: Velocity=3.11\n",
      "Step 37: Brake action applied! Velocity: 3.11\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0424\n",
      "Step 37: Action: 4, Reward: 1.6243, Total Reward: 46.2569, Epsilon: 0.714\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.40\n",
      "Intersection detected: Velocity=3.40, Min Distance=0.00\n",
      "Moving: Velocity=3.40\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0423\n",
      "Step 38: Action: 0, Reward: 1.3958, Total Reward: 47.6527, Epsilon: 0.713\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.68\n",
      "Intersection detected: Velocity=3.68, Min Distance=0.00\n",
      "Moving: Velocity=3.68\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0452\n",
      "Step 39: Action: 0, Reward: 1.4073, Total Reward: 49.0600, Epsilon: 0.713\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.76\n",
      "Intersection detected: Velocity=3.76, Min Distance=0.00\n",
      "Moving: Velocity=3.76\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0313\n",
      "Step 40: Action: 2, Reward: 1.1104, Total Reward: 50.1705, Epsilon: 0.712\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.94\n",
      "Intersection detected: Velocity=3.94, Min Distance=0.00\n",
      "Moving: Velocity=3.94\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0386\n",
      "Step 41: Action: 2, Reward: 1.4177, Total Reward: 51.5881, Epsilon: 0.712\n",
      "Q-values: [1.411692  1.3978498 1.2701607 1.2353289 1.6811805]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.87, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.87, Min Distance=0.00\n",
      "Moving: Velocity=3.87\n",
      "Step 42: Brake action applied! Velocity: 3.87\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1835\n",
      "Step 42: Action: 4, Reward: 1.3548, Total Reward: 52.9429, Epsilon: 0.711\n",
      "Q-values: [1.3701375 1.364847  1.2416307 1.1946813 1.645846 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.83, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.83, Min Distance=0.00\n",
      "Moving: Velocity=3.83\n",
      "Step 43: Brake action applied! Velocity: 3.83\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1727\n",
      "Step 43: Action: 4, Reward: 1.6532, Total Reward: 54.5961, Epsilon: 0.711\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.79\n",
      "Intersection detected: Velocity=3.79, Min Distance=0.00\n",
      "Moving: Velocity=3.79\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1701\n",
      "Step 44: Action: 1, Reward: 1.4118, Total Reward: 56.0079, Epsilon: 0.710\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.76\n",
      "Intersection detected: Velocity=3.76, Min Distance=0.00\n",
      "Moving: Velocity=3.76\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1807\n",
      "Step 45: Action: 1, Reward: 1.4103, Total Reward: 57.4182, Epsilon: 0.710\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.83\n",
      "Intersection detected: Velocity=3.83, Min Distance=0.00\n",
      "Moving: Velocity=3.83\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1682\n",
      "Step 46: Action: 3, Reward: 1.1133, Total Reward: 58.5315, Epsilon: 0.709\n",
      "Q-values: [1.2062362 1.2436209 1.1391425 1.0599533 1.4780253]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.78, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.78, Min Distance=0.00\n",
      "Moving: Velocity=3.78\n",
      "Step 47: Brake action applied! Velocity: 3.78\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3082\n",
      "Step 47: Action: 4, Reward: 1.3512, Total Reward: 59.8827, Epsilon: 0.709\n",
      "Q-values: [1.1980731 1.2506841 1.1393926 1.0584399 1.4698935]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.74, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.74, Min Distance=0.00\n",
      "Moving: Velocity=3.74\n",
      "Step 48: Brake action applied! Velocity: 3.74\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0659\n",
      "Step 48: Action: 4, Reward: 1.6497, Total Reward: 61.5324, Epsilon: 0.708\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.81\n",
      "Intersection detected: Velocity=3.81, Min Distance=0.00\n",
      "Moving: Velocity=3.81\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0756\n",
      "Step 49: Action: 2, Reward: 1.1125, Total Reward: 62.6448, Epsilon: 0.708\n",
      "Q-values: [1.2669232 1.3420805 1.2085769 1.1276338 1.546166 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.76, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.76, Min Distance=0.00\n",
      "Moving: Velocity=3.76\n",
      "Step 50: Brake action applied! Velocity: 3.76\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1398\n",
      "Step 50: Action: 4, Reward: 1.3503, Total Reward: 63.9951, Epsilon: 0.707\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.86\n",
      "Intersection detected: Velocity=3.86, Min Distance=0.00\n",
      "Moving: Velocity=3.86\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0675\n",
      "Step 51: Action: 2, Reward: 1.1143, Total Reward: 65.1094, Epsilon: 0.707\n",
      "Q-values: [1.3760463 1.4611522 1.2931128 1.2169402 1.6573793]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.80, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.80, Min Distance=0.00\n",
      "Moving: Velocity=3.80\n",
      "Step 52: Brake action applied! Velocity: 3.80\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1751\n",
      "Step 52: Action: 4, Reward: 1.3519, Total Reward: 66.4613, Epsilon: 0.706\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.08\n",
      "Intersection detected: Velocity=4.08, Min Distance=0.00\n",
      "Moving: Velocity=4.08\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3319\n",
      "Step 53: Action: 0, Reward: 1.4233, Total Reward: 67.8846, Epsilon: 0.706\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.37\n",
      "Intersection detected: Velocity=4.37, Min Distance=0.00\n",
      "Moving: Velocity=4.37\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0593\n",
      "Step 54: Action: 0, Reward: 1.4348, Total Reward: 69.3195, Epsilon: 0.705\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.66\n",
      "Intersection detected: Velocity=4.66, Min Distance=0.00\n",
      "Moving: Velocity=4.66\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0709\n",
      "Step 55: Action: 0, Reward: 1.4463, Total Reward: 70.7658, Epsilon: 0.705\n",
      "Q-values: [1.3735571 1.4446573 1.2458048 1.2063663 1.5973397]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.62, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.62, Min Distance=0.00\n",
      "Moving: Velocity=4.62\n",
      "Step 56: Brake action applied! Velocity: 4.62\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0341\n",
      "Step 56: Action: 4, Reward: 1.6848, Total Reward: 72.4506, Epsilon: 0.704\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.58, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.58, Min Distance=0.00\n",
      "Moving: Velocity=4.58\n",
      "Step 57: Brake action applied! Velocity: 4.58\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0478\n",
      "Step 57: Action: 4, Reward: 1.6834, Total Reward: 74.1340, Epsilon: 0.704\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.63\n",
      "Intersection detected: Velocity=4.63, Min Distance=0.00\n",
      "Moving: Velocity=4.63\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0703\n",
      "Step 58: Action: 3, Reward: 1.1453, Total Reward: 75.2793, Epsilon: 0.703\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.63\n",
      "Intersection detected: Velocity=4.63, Min Distance=0.00\n",
      "Moving: Velocity=4.63\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0581\n",
      "Step 59: Action: 2, Reward: 1.1452, Total Reward: 76.4244, Epsilon: 0.703\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.59\n",
      "Intersection detected: Velocity=4.59, Min Distance=0.00\n",
      "Moving: Velocity=4.59\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1799\n",
      "Step 60: Action: 1, Reward: 1.1437, Total Reward: 77.5681, Epsilon: 0.703\n",
      "Q-values: [1.4214189 1.4264431 1.2154086 1.2108929 1.5975006]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.56, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.56, Min Distance=0.00\n",
      "Moving: Velocity=4.56\n",
      "Step 61: Brake action applied! Velocity: 4.56\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0335\n",
      "Step 61: Action: 4, Reward: 1.6822, Total Reward: 79.2504, Epsilon: 0.702\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.84\n",
      "Intersection detected: Velocity=4.84, Min Distance=0.00\n",
      "Moving: Velocity=4.84\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0486\n",
      "Step 62: Action: 0, Reward: 1.4537, Total Reward: 80.7041, Epsilon: 0.702\n",
      "Q-values: [1.4106946 1.3961304 1.1992129 1.1879067 1.5911767]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.81, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.81, Min Distance=0.00\n",
      "Moving: Velocity=4.81\n",
      "Step 63: Brake action applied! Velocity: 4.81\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2964\n",
      "Step 63: Action: 4, Reward: 1.6923, Total Reward: 82.3963, Epsilon: 0.701\n",
      "Q-values: [1.4168767 1.3954233 1.2039095 1.1890273 1.6014748]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.77, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.77, Min Distance=0.00\n",
      "Moving: Velocity=4.77\n",
      "Step 64: Brake action applied! Velocity: 4.77\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0316\n",
      "Step 64: Action: 4, Reward: 1.6908, Total Reward: 84.0871, Epsilon: 0.701\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.82\n",
      "Intersection detected: Velocity=4.82, Min Distance=0.00\n",
      "Moving: Velocity=4.82\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1621\n",
      "Step 65: Action: 3, Reward: 1.1527, Total Reward: 85.2398, Epsilon: 0.700\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.94\n",
      "Intersection detected: Velocity=4.94, Min Distance=0.00\n",
      "Moving: Velocity=4.94\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0387\n",
      "Step 66: Action: 3, Reward: 1.4576, Total Reward: 86.6974, Epsilon: 0.700\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.15\n",
      "Intersection detected: Velocity=5.15, Min Distance=0.00\n",
      "Moving: Velocity=5.15\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0446\n",
      "Step 67: Action: 3, Reward: 1.4662, Total Reward: 88.1636, Epsilon: 0.699\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.09\n",
      "Intersection detected: Velocity=5.09, Min Distance=0.00\n",
      "Moving: Velocity=5.09\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0360\n",
      "Step 68: Action: 1, Reward: 1.1636, Total Reward: 89.3272, Epsilon: 0.699\n",
      "Q-values: [1.3836738 1.3856044 1.2220143 1.2050421 1.6394348]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.05, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.05, Min Distance=0.00\n",
      "Moving: Velocity=5.05\n",
      "Step 69: Brake action applied! Velocity: 5.05\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1910\n",
      "Step 69: Action: 4, Reward: 1.7019, Total Reward: 91.0290, Epsilon: 0.698\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.01\n",
      "Intersection detected: Velocity=5.01, Min Distance=0.00\n",
      "Moving: Velocity=5.01\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1754\n",
      "Step 70: Action: 1, Reward: 1.4604, Total Reward: 92.4895, Epsilon: 0.698\n",
      "Q-values: [1.3766316 1.3877368 1.2272645 1.2113407 1.6512554]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.97, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.97, Min Distance=0.00\n",
      "Moving: Velocity=4.97\n",
      "Step 71: Brake action applied! Velocity: 4.97\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1723\n",
      "Step 71: Action: 4, Reward: 1.6990, Total Reward: 94.1884, Epsilon: 0.697\n",
      "Q-values: [1.3423852 1.3570477 1.2117182 1.1935598 1.6297234]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.94, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.94, Min Distance=0.00\n",
      "Moving: Velocity=4.94\n",
      "Step 72: Brake action applied! Velocity: 4.94\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1624\n",
      "Step 72: Action: 4, Reward: 1.6975, Total Reward: 95.8859, Epsilon: 0.697\n",
      "Q-values: [1.3015068 1.32505   1.195078  1.1730868 1.6071467]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.90, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.90, Min Distance=0.00\n",
      "Moving: Velocity=4.90\n",
      "Step 73: Brake action applied! Velocity: 4.90\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1875\n",
      "Step 73: Action: 4, Reward: 1.6960, Total Reward: 97.5820, Epsilon: 0.696\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.86\n",
      "Intersection detected: Velocity=4.86, Min Distance=0.00\n",
      "Moving: Velocity=4.86\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1745\n",
      "Step 74: Action: 1, Reward: 1.4546, Total Reward: 99.0365, Epsilon: 0.696\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.15\n",
      "Intersection detected: Velocity=5.15, Min Distance=0.00\n",
      "Moving: Velocity=5.15\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1857\n",
      "Step 75: Action: 0, Reward: 1.4661, Total Reward: 100.5026, Epsilon: 0.695\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.20\n",
      "Intersection detected: Velocity=5.20, Min Distance=0.00\n",
      "Moving: Velocity=5.20\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0631\n",
      "Step 76: Action: 3, Reward: 1.1680, Total Reward: 101.6706, Epsilon: 0.695\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.16\n",
      "Intersection detected: Velocity=5.16, Min Distance=0.00\n",
      "Moving: Velocity=5.16\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0477\n",
      "Step 77: Action: 1, Reward: 1.1662, Total Reward: 102.8368, Epsilon: 0.694\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.44\n",
      "Intersection detected: Velocity=5.44, Min Distance=0.00\n",
      "Moving: Velocity=5.44\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0492\n",
      "Step 78: Action: 0, Reward: 1.4777, Total Reward: 104.3145, Epsilon: 0.694\n",
      "Q-values: [1.3466849 1.3625683 1.2619407 1.2510583 1.6915553]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.41, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.41, Min Distance=0.00\n",
      "Moving: Velocity=5.41\n",
      "Step 79: Brake action applied! Velocity: 5.41\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0467\n",
      "Step 79: Action: 4, Reward: 1.7162, Total Reward: 106.0307, Epsilon: 0.693\n",
      "Q-values: [1.3952408 1.4081897 1.2938738 1.2906554 1.7409079]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.37, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.37, Min Distance=0.00\n",
      "Moving: Velocity=5.37\n",
      "Step 80: Brake action applied! Velocity: 5.37\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2965\n",
      "Step 80: Action: 4, Reward: 1.7148, Total Reward: 107.7455, Epsilon: 0.693\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.33\n",
      "Intersection detected: Velocity=5.33, Min Distance=0.00\n",
      "Moving: Velocity=5.33\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1720\n",
      "Step 81: Action: 1, Reward: 1.4733, Total Reward: 109.2188, Epsilon: 0.692\n",
      "Q-values: [1.3835478 1.3978608 1.2781637 1.2735729 1.72206  ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.30, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.30, Min Distance=0.00\n",
      "Moving: Velocity=5.30\n",
      "Step 82: Brake action applied! Velocity: 5.30\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0314\n",
      "Step 82: Action: 4, Reward: 1.7119, Total Reward: 110.9306, Epsilon: 0.692\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.26, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.26, Min Distance=0.00\n",
      "Moving: Velocity=5.26\n",
      "Step 83: Brake action applied! Velocity: 5.26\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0449\n",
      "Step 83: Action: 4, Reward: 1.7104, Total Reward: 112.6410, Epsilon: 0.691\n",
      "Q-values: [1.3714554 1.3860948 1.2602942 1.2568758 1.7002982]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.22, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.22, Min Distance=0.00\n",
      "Moving: Velocity=5.22\n",
      "Step 84: Brake action applied! Velocity: 5.22\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0439\n",
      "Step 84: Action: 4, Reward: 1.7089, Total Reward: 114.3500, Epsilon: 0.691\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.26\n",
      "Intersection detected: Velocity=5.26, Min Distance=0.00\n",
      "Moving: Velocity=5.26\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0286\n",
      "Step 85: Action: 2, Reward: 1.1706, Total Reward: 115.5205, Epsilon: 0.690\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.22, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.22, Min Distance=0.00\n",
      "Moving: Velocity=5.22\n",
      "Step 86: Brake action applied! Velocity: 5.22\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0330\n",
      "Step 86: Action: 4, Reward: 1.4087, Total Reward: 116.9293, Epsilon: 0.690\n",
      "Q-values: [1.3704939 1.3745704 1.2295623 1.2351207 1.6711264]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.18, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.18, Min Distance=0.00\n",
      "Moving: Velocity=5.18\n",
      "Step 87: Brake action applied! Velocity: 5.18\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1675\n",
      "Step 87: Action: 4, Reward: 1.7073, Total Reward: 118.6365, Epsilon: 0.689\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.47\n",
      "Intersection detected: Velocity=5.47, Min Distance=0.00\n",
      "Moving: Velocity=5.47\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2962\n",
      "Step 88: Action: 0, Reward: 1.4787, Total Reward: 120.1153, Epsilon: 0.689\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.51\n",
      "Intersection detected: Velocity=5.51, Min Distance=0.00\n",
      "Moving: Velocity=5.51\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1719\n",
      "Step 89: Action: 2, Reward: 1.1805, Total Reward: 121.2958, Epsilon: 0.688\n",
      "Q-values: [1.3327744 1.3113173 1.1718049 1.1847436 1.5922284]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.47, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.47, Min Distance=0.00\n",
      "Moving: Velocity=5.47\n",
      "Step 90: Brake action applied! Velocity: 5.47\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0439\n",
      "Step 90: Action: 4, Reward: 1.4187, Total Reward: 122.7145, Epsilon: 0.688\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.43\n",
      "Intersection detected: Velocity=5.43, Min Distance=0.00\n",
      "Moving: Velocity=5.43\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2844\n",
      "Step 91: Action: 1, Reward: 1.4773, Total Reward: 124.1918, Epsilon: 0.687\n",
      "Q-values: [1.3563777 1.3279835 1.167624  1.1975298 1.585434 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.40, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.40, Min Distance=0.00\n",
      "Moving: Velocity=5.40\n",
      "Step 92: Brake action applied! Velocity: 5.40\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1693\n",
      "Step 92: Action: 4, Reward: 1.7158, Total Reward: 125.9076, Epsilon: 0.687\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.43\n",
      "Intersection detected: Velocity=5.43, Min Distance=0.00\n",
      "Moving: Velocity=5.43\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1698\n",
      "Step 93: Action: 3, Reward: 1.1773, Total Reward: 127.0849, Epsilon: 0.686\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.39, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.39, Min Distance=0.00\n",
      "Moving: Velocity=5.39\n",
      "Step 94: Brake action applied! Velocity: 5.39\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1678\n",
      "Step 94: Action: 4, Reward: 1.4155, Total Reward: 128.5004, Epsilon: 0.686\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.67\n",
      "Intersection detected: Velocity=5.67, Min Distance=0.00\n",
      "Moving: Velocity=5.67\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0471\n",
      "Step 95: Action: 0, Reward: 1.4869, Total Reward: 129.9873, Epsilon: 0.685\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.64\n",
      "Intersection detected: Velocity=5.64, Min Distance=0.00\n",
      "Moving: Velocity=5.64\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0379\n",
      "Step 96: Action: 1, Reward: 1.4855, Total Reward: 131.4728, Epsilon: 0.685\n",
      "Q-values: [1.4380656 1.4272475 1.2330768 1.2849606 1.664776 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.60, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.60, Min Distance=0.00\n",
      "Moving: Velocity=5.60\n",
      "Step 97: Brake action applied! Velocity: 5.60\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0219\n",
      "Step 97: Action: 4, Reward: 1.7240, Total Reward: 133.1968, Epsilon: 0.684\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.56, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.56, Min Distance=0.00\n",
      "Moving: Velocity=5.56\n",
      "Step 98: Brake action applied! Velocity: 5.56\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0389\n",
      "Step 98: Action: 4, Reward: 1.7226, Total Reward: 134.9194, Epsilon: 0.684\n",
      "Q-values: [1.5067289 1.5019339 1.291801  1.3396356 1.7487355]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.53, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.53, Min Distance=0.00\n",
      "Moving: Velocity=5.53\n",
      "Step 99: Brake action applied! Velocity: 5.53\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1567\n",
      "Step 99: Action: 4, Reward: 1.7211, Total Reward: 136.6405, Epsilon: 0.683\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.56\n",
      "Intersection detected: Velocity=5.56, Min Distance=0.00\n",
      "Moving: Velocity=5.56\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0498\n",
      "Step 100: Action: 2, Reward: 1.1826, Total Reward: 137.8231, Epsilon: 0.683\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.57\n",
      "Intersection detected: Velocity=5.57, Min Distance=0.00\n",
      "Moving: Velocity=5.57\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0382\n",
      "Step 101: Action: 3, Reward: 1.1827, Total Reward: 139.0058, Epsilon: 0.682\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.53, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.53, Min Distance=0.00\n",
      "Moving: Velocity=5.53\n",
      "Step 102: Brake action applied! Velocity: 5.53\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1817\n",
      "Step 102: Action: 4, Reward: 1.4212, Total Reward: 140.4269, Epsilon: 0.682\n",
      "Q-values: [1.3947158 1.3852384 1.1999562 1.2111974 1.6440067]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.49, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.49, Min Distance=0.00\n",
      "Moving: Velocity=5.49\n",
      "Step 103: Brake action applied! Velocity: 5.49\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0426\n",
      "Step 103: Action: 4, Reward: 1.7197, Total Reward: 142.1467, Epsilon: 0.681\n",
      "Q-values: [1.3605964 1.350172  1.1725221 1.1750998 1.607845 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.46, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.46, Min Distance=0.00\n",
      "Moving: Velocity=5.46\n",
      "Step 104: Brake action applied! Velocity: 5.46\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0550\n",
      "Step 104: Action: 4, Reward: 1.7183, Total Reward: 143.8650, Epsilon: 0.681\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.42\n",
      "Intersection detected: Velocity=5.42, Min Distance=0.00\n",
      "Moving: Velocity=5.42\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1491\n",
      "Step 105: Action: 1, Reward: 1.4768, Total Reward: 145.3418, Epsilon: 0.680\n",
      "Q-values: [1.3793176 1.361242  1.1819196 1.1734391 1.6217748]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.38, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.38, Min Distance=0.00\n",
      "Moving: Velocity=5.38\n",
      "Step 106: Brake action applied! Velocity: 5.38\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0515\n",
      "Step 106: Action: 4, Reward: 1.7154, Total Reward: 147.0571, Epsilon: 0.680\n",
      "Q-values: [1.4250349 1.4017855 1.2127753 1.2016566 1.6645758]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.35, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.35, Min Distance=0.00\n",
      "Moving: Velocity=5.35\n",
      "Step 107: Brake action applied! Velocity: 5.35\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0485\n",
      "Step 107: Action: 4, Reward: 1.7139, Total Reward: 148.7711, Epsilon: 0.679\n",
      "Q-values: [1.4753664 1.4435123 1.243445  1.2317978 1.7076133]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.31, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.31, Min Distance=0.00\n",
      "Moving: Velocity=5.31\n",
      "Step 108: Brake action applied! Velocity: 5.31\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0572\n",
      "Step 108: Action: 4, Reward: 1.7125, Total Reward: 150.4835, Epsilon: 0.679\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.60\n",
      "Intersection detected: Velocity=5.60, Min Distance=0.00\n",
      "Moving: Velocity=5.60\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0407\n",
      "Step 109: Action: 0, Reward: 1.4839, Total Reward: 151.9675, Epsilon: 0.678\n",
      "Q-values: [1.5071278 1.4690384 1.264162  1.2493548 1.7327514]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.56, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.56, Min Distance=0.00\n",
      "Moving: Velocity=5.56\n",
      "Step 110: Brake action applied! Velocity: 5.56\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1335\n",
      "Step 110: Action: 4, Reward: 1.7225, Total Reward: 153.6899, Epsilon: 0.678\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.53, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.53, Min Distance=0.00\n",
      "Moving: Velocity=5.53\n",
      "Step 111: Brake action applied! Velocity: 5.53\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0396\n",
      "Step 111: Action: 4, Reward: 1.7210, Total Reward: 155.4110, Epsilon: 0.677\n",
      "Q-values: [1.5040731 1.459681  1.2616072 1.2324011 1.7264279]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.49, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.49, Min Distance=0.00\n",
      "Moving: Velocity=5.49\n",
      "Step 112: Brake action applied! Velocity: 5.49\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0291\n",
      "Step 112: Action: 4, Reward: 1.7196, Total Reward: 157.1306, Epsilon: 0.677\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.45\n",
      "Intersection detected: Velocity=5.45, Min Distance=0.00\n",
      "Moving: Velocity=5.45\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0315\n",
      "Step 113: Action: 1, Reward: 1.4781, Total Reward: 158.6087, Epsilon: 0.676\n",
      "Q-values: [1.447618  1.3980426 1.2231184 1.1837435 1.6723344]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.42, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.42, Min Distance=0.00\n",
      "Moving: Velocity=5.42\n",
      "Step 114: Brake action applied! Velocity: 5.42\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0625\n",
      "Step 114: Action: 4, Reward: 1.7167, Total Reward: 160.3253, Epsilon: 0.676\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.45\n",
      "Intersection detected: Velocity=5.45, Min Distance=0.00\n",
      "Moving: Velocity=5.45\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0500\n",
      "Step 115: Action: 2, Reward: 1.1782, Total Reward: 161.5035, Epsilon: 0.675\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.55\n",
      "Intersection detected: Velocity=5.55, Min Distance=0.00\n",
      "Moving: Velocity=5.55\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0461\n",
      "Step 116: Action: 2, Reward: 1.4818, Total Reward: 162.9854, Epsilon: 0.675\n",
      "Q-values: [1.2596172 1.2209322 1.0977552 1.0408074 1.5017325]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.49, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.49, Min Distance=0.00\n",
      "Moving: Velocity=5.49\n",
      "Step 117: Brake action applied! Velocity: 5.49\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1604\n",
      "Step 117: Action: 4, Reward: 1.4196, Total Reward: 164.4049, Epsilon: 0.674\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.50\n",
      "Intersection detected: Velocity=5.50, Min Distance=0.00\n",
      "Moving: Velocity=5.50\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2752\n",
      "Step 118: Action: 3, Reward: 1.1800, Total Reward: 165.5850, Epsilon: 0.674\n",
      "Q-values: [1.2813308 1.2469997 1.1239718 1.068822  1.5191272]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.46, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.46, Min Distance=0.00\n",
      "Moving: Velocity=5.46\n",
      "Step 119: Brake action applied! Velocity: 5.46\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0327\n",
      "Step 119: Action: 4, Reward: 1.4184, Total Reward: 167.0033, Epsilon: 0.673\n",
      "Q-values: [1.3421403 1.3043233 1.1728283 1.119229  1.5760422]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.42, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.42, Min Distance=0.00\n",
      "Moving: Velocity=5.42\n",
      "Step 120: Brake action applied! Velocity: 5.42\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0436\n",
      "Step 120: Action: 4, Reward: 1.7169, Total Reward: 168.7202, Epsilon: 0.673\n",
      "Q-values: [1.3876191 1.3493491 1.2144114 1.1633927 1.6213763]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.39, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.39, Min Distance=0.00\n",
      "Moving: Velocity=5.39\n",
      "Step 121: Brake action applied! Velocity: 5.39\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0379\n",
      "Step 121: Action: 4, Reward: 1.7155, Total Reward: 170.4357, Epsilon: 0.672\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.42\n",
      "Intersection detected: Velocity=5.42, Min Distance=0.00\n",
      "Moving: Velocity=5.42\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0235\n",
      "Step 122: Action: 3, Reward: 1.1770, Total Reward: 171.6127, Epsilon: 0.672\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.70\n",
      "Intersection detected: Velocity=5.70, Min Distance=0.00\n",
      "Moving: Velocity=5.70\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0515\n",
      "Step 123: Action: 0, Reward: 1.1879, Total Reward: 172.8006, Epsilon: 0.671\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.73\n",
      "Intersection detected: Velocity=5.73, Min Distance=0.00\n",
      "Moving: Velocity=5.73\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0428\n",
      "Step 124: Action: 2, Reward: 1.1892, Total Reward: 173.9898, Epsilon: 0.671\n",
      "Q-values: [1.3929797 1.3415012 1.2350603 1.1908762 1.6240423]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.69, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.69, Min Distance=0.00\n",
      "Moving: Velocity=5.69\n",
      "Step 125: Brake action applied! Velocity: 5.69\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0787\n",
      "Step 125: Action: 4, Reward: 1.4275, Total Reward: 175.4173, Epsilon: 0.670\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.73\n",
      "Intersection detected: Velocity=5.73, Min Distance=0.00\n",
      "Moving: Velocity=5.73\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3122\n",
      "Step 126: Action: 2, Reward: 1.1890, Total Reward: 176.6063, Epsilon: 0.670\n",
      "Q-values: [1.2687746 1.2173545 1.1456228 1.1101637 1.5054497]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.68, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.68, Min Distance=0.00\n",
      "Moving: Velocity=5.68\n",
      "Step 127: Brake action applied! Velocity: 5.68\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1437\n",
      "Step 127: Action: 4, Reward: 1.4271, Total Reward: 178.0334, Epsilon: 0.669\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.72\n",
      "Intersection detected: Velocity=5.72, Min Distance=0.00\n",
      "Moving: Velocity=5.72\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0447\n",
      "Step 128: Action: 2, Reward: 1.1888, Total Reward: 179.2222, Epsilon: 0.669\n",
      "Q-values: [1.1795808 1.1371648 1.0869234 1.049264  1.4279039]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.67, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.67, Min Distance=0.00\n",
      "Moving: Velocity=5.67\n",
      "Step 129: Brake action applied! Velocity: 5.67\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0489\n",
      "Step 129: Action: 4, Reward: 1.4269, Total Reward: 180.6491, Epsilon: 0.668\n",
      "Q-values: [1.2093644 1.1680524 1.1136839 1.0797472 1.46341  ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.64, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.64, Min Distance=0.00\n",
      "Moving: Velocity=5.64\n",
      "Step 130: Brake action applied! Velocity: 5.64\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0442\n",
      "Step 130: Action: 4, Reward: 1.7254, Total Reward: 182.3746, Epsilon: 0.668\n",
      "Q-values: [1.2693493 1.2255396 1.1622765 1.134404  1.5281353]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.60, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.60, Min Distance=0.00\n",
      "Moving: Velocity=5.60\n",
      "Step 131: Brake action applied! Velocity: 5.60\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2846\n",
      "Step 131: Action: 4, Reward: 1.7240, Total Reward: 184.0986, Epsilon: 0.667\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.56\n",
      "Intersection detected: Velocity=5.56, Min Distance=0.00\n",
      "Moving: Velocity=5.56\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1723\n",
      "Step 132: Action: 1, Reward: 1.4825, Total Reward: 185.5811, Epsilon: 0.667\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.60\n",
      "Intersection detected: Velocity=5.60, Min Distance=0.00\n",
      "Moving: Velocity=5.60\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0276\n",
      "Step 133: Action: 2, Reward: 1.1840, Total Reward: 186.7651, Epsilon: 0.666\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.55\n",
      "Intersection detected: Velocity=5.55, Min Distance=0.00\n",
      "Moving: Velocity=5.55\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0458\n",
      "Step 134: Action: 1, Reward: 1.1822, Total Reward: 187.9472, Epsilon: 0.666\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.84\n",
      "Intersection detected: Velocity=5.84, Min Distance=0.00\n",
      "Moving: Velocity=5.84\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0202\n",
      "Step 135: Action: 0, Reward: 1.4936, Total Reward: 189.4409, Epsilon: 0.665\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.88\n",
      "Intersection detected: Velocity=5.88, Min Distance=0.00\n",
      "Moving: Velocity=5.88\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0468\n",
      "Step 136: Action: 2, Reward: 1.1953, Total Reward: 190.6361, Epsilon: 0.665\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.89\n",
      "Intersection detected: Velocity=5.89, Min Distance=0.00\n",
      "Moving: Velocity=5.89\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1860\n",
      "Step 137: Action: 3, Reward: 1.1955, Total Reward: 191.8316, Epsilon: 0.664\n",
      "Q-values: [1.2717242 1.2487589 1.159346  1.1446061 1.5311352]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.85, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.85, Min Distance=0.00\n",
      "Moving: Velocity=5.85\n",
      "Step 138: Brake action applied! Velocity: 5.85\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0476\n",
      "Step 138: Action: 4, Reward: 1.4340, Total Reward: 193.2656, Epsilon: 0.664\n",
      "Q-values: [1.2698605 1.2494295 1.1546328 1.140788  1.5308713]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.81, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.81, Min Distance=0.00\n",
      "Moving: Velocity=5.81\n",
      "Step 139: Brake action applied! Velocity: 5.81\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0327\n",
      "Step 139: Action: 4, Reward: 1.7325, Total Reward: 194.9981, Epsilon: 0.663\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.84\n",
      "Intersection detected: Velocity=5.84, Min Distance=0.00\n",
      "Moving: Velocity=5.84\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0261\n",
      "Step 140: Action: 3, Reward: 1.1938, Total Reward: 196.1919, Epsilon: 0.663\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.80, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.80, Min Distance=0.00\n",
      "Moving: Velocity=5.80\n",
      "Step 141: Brake action applied! Velocity: 5.80\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0571\n",
      "Step 141: Action: 4, Reward: 1.4320, Total Reward: 197.6239, Epsilon: 0.662\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.09\n",
      "Intersection detected: Velocity=6.09, Min Distance=0.00\n",
      "Moving: Velocity=6.09\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1552\n",
      "Step 142: Action: 0, Reward: 1.5035, Total Reward: 199.1273, Epsilon: 0.662\n",
      "Q-values: [1.2486302 1.2475967 1.1360734 1.1228068 1.5349848]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.05, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.05, Min Distance=0.00\n",
      "Moving: Velocity=6.05\n",
      "Step 143: Brake action applied! Velocity: 6.05\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0434\n",
      "Step 143: Action: 4, Reward: 1.7420, Total Reward: 200.8694, Epsilon: 0.661\n",
      "Q-values: [1.280082  1.2841328 1.1604106 1.1454405 1.5758021]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.01, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.01, Min Distance=0.00\n",
      "Off-road detected: Penalty applied\n",
      "Moving: Velocity=6.01\n",
      "Step 144: Brake action applied! Velocity: 6.01\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1804\n",
      "Step 144: Action: 4, Reward: -1.1595, Total Reward: 199.7099, Epsilon: 0.661\n",
      "Episode 6 ended early: Terminated=True, Truncated=False\n",
      "Episode 6 completed. Total Reward: 199.7099\n",
      "Target network updated\n",
      "Episode 7 started\n",
      "Initial observation shape: (259,)\n",
      "Q-values: [1.4366348 1.4464842 1.2824328 1.2775195 1.7384028]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.03, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.03, Min Distance=0.00\n",
      "Step 1: Brake action applied! Velocity: 0.03\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 2.3973\n",
      "Step 1: Action: 4, Reward: 1.5010, Total Reward: 1.5010, Epsilon: 0.660\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.31\n",
      "Intersection detected: Velocity=0.31, Min Distance=0.00\n",
      "Moving: Velocity=0.31\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 1.5371\n",
      "Step 2: Action: 3, Reward: 0.9723, Total Reward: 2.4733, Epsilon: 0.660\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.27\n",
      "Intersection detected: Velocity=0.27, Min Distance=0.00\n",
      "Moving: Velocity=0.27\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6552\n",
      "Step 3: Action: 1, Reward: 0.9707, Total Reward: 3.4440, Epsilon: 0.659\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.53\n",
      "Intersection detected: Velocity=0.53, Min Distance=0.00\n",
      "Moving: Velocity=0.53\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1628\n",
      "Step 4: Action: 2, Reward: 0.9812, Total Reward: 4.4252, Epsilon: 0.659\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.75\n",
      "Intersection detected: Velocity=0.75, Min Distance=0.00\n",
      "Moving: Velocity=0.75\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2238\n",
      "Step 5: Action: 3, Reward: 0.9899, Total Reward: 5.4151, Epsilon: 0.658\n",
      "Q-values: [3.7003086 3.7033634 3.274042  3.1723888 4.3581986]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.70, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.70, Min Distance=0.00\n",
      "Moving: Velocity=0.70\n",
      "Step 6: Brake action applied! Velocity: 0.70\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 1.5885\n",
      "Step 6: Action: 4, Reward: 1.2281, Total Reward: 6.6432, Epsilon: 0.658\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.99\n",
      "Intersection detected: Velocity=0.99, Min Distance=0.00\n",
      "Moving: Velocity=0.99\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 1.3229\n",
      "Step 7: Action: 0, Reward: 1.2996, Total Reward: 7.9428, Epsilon: 0.657\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.95, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.95, Min Distance=0.00\n",
      "Moving: Velocity=0.95\n",
      "Step 8: Brake action applied! Velocity: 0.95\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.8969\n",
      "Step 8: Action: 4, Reward: 1.5381, Total Reward: 9.4809, Epsilon: 0.657\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.19\n",
      "Intersection detected: Velocity=1.19, Min Distance=0.00\n",
      "Moving: Velocity=1.19\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1636\n",
      "Step 9: Action: 2, Reward: 1.0074, Total Reward: 10.4883, Epsilon: 0.656\n",
      "Q-values: [2.9529364 3.0701106 2.614388  2.6663864 3.0967824]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.13, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.13, Min Distance=0.00\n",
      "Moving: Velocity=1.13\n",
      "Step 10: Brake action applied! Velocity: 1.13\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0533\n",
      "Step 10: Action: 4, Reward: 1.2454, Total Reward: 11.7337, Epsilon: 0.656\n",
      "Q-values: [2.6997538 2.8362677 2.3960626 2.4802592 2.750756 ]\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.10\n",
      "Intersection detected: Velocity=1.10, Min Distance=0.00\n",
      "Moving: Velocity=1.10\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1781\n",
      "Step 11: Action: 1, Reward: 1.3039, Total Reward: 13.0376, Epsilon: 0.655\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.32\n",
      "Intersection detected: Velocity=1.32, Min Distance=0.00\n",
      "Moving: Velocity=1.32\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3440\n",
      "Step 12: Action: 3, Reward: 1.0128, Total Reward: 14.0504, Epsilon: 0.655\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.27\n",
      "Intersection detected: Velocity=1.27, Min Distance=0.00\n",
      "Moving: Velocity=1.27\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6458\n",
      "Step 13: Action: 1, Reward: 1.0106, Total Reward: 15.0610, Epsilon: 0.654\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.23, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.23, Min Distance=0.00\n",
      "Moving: Velocity=1.23\n",
      "Step 14: Brake action applied! Velocity: 1.23\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6261\n",
      "Step 14: Action: 4, Reward: 1.5491, Total Reward: 16.6102, Epsilon: 0.654\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.19\n",
      "Intersection detected: Velocity=1.19, Min Distance=0.00\n",
      "Moving: Velocity=1.19\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.4795\n",
      "Step 15: Action: 1, Reward: 1.3077, Total Reward: 17.9179, Epsilon: 0.653\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.16, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.16, Min Distance=0.00\n",
      "Moving: Velocity=1.16\n",
      "Step 16: Brake action applied! Velocity: 1.16\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.4187\n",
      "Step 16: Action: 4, Reward: 1.5462, Total Reward: 19.4641, Epsilon: 0.653\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.38\n",
      "Intersection detected: Velocity=1.38, Min Distance=0.00\n",
      "Moving: Velocity=1.38\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3228\n",
      "Step 17: Action: 2, Reward: 1.0151, Total Reward: 20.4792, Epsilon: 0.653\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.32, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.32, Min Distance=0.00\n",
      "Moving: Velocity=1.32\n",
      "Step 18: Brake action applied! Velocity: 1.32\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0774\n",
      "Step 18: Action: 4, Reward: 1.2530, Total Reward: 21.7322, Epsilon: 0.652\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.29, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.29, Min Distance=0.00\n",
      "Moving: Velocity=1.29\n",
      "Step 19: Brake action applied! Velocity: 1.29\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3810\n",
      "Step 19: Action: 4, Reward: 1.5515, Total Reward: 23.2837, Epsilon: 0.652\n",
      "Q-values: [3.2085056 3.2095494 3.0352106 3.1480997 3.3051796]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.25, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.25, Min Distance=0.00\n",
      "Moving: Velocity=1.25\n",
      "Step 20: Brake action applied! Velocity: 1.25\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0778\n",
      "Step 20: Action: 4, Reward: 1.5500, Total Reward: 24.8337, Epsilon: 0.651\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.47\n",
      "Intersection detected: Velocity=1.47, Min Distance=0.00\n",
      "Moving: Velocity=1.47\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6036\n",
      "Step 21: Action: 2, Reward: 1.0187, Total Reward: 25.8524, Epsilon: 0.651\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.41, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.41, Min Distance=0.00\n",
      "Moving: Velocity=1.41\n",
      "Step 22: Brake action applied! Velocity: 1.41\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1256\n",
      "Step 22: Action: 4, Reward: 1.2565, Total Reward: 27.1089, Epsilon: 0.650\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.70\n",
      "Intersection detected: Velocity=1.70, Min Distance=0.00\n",
      "Moving: Velocity=1.70\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.5175\n",
      "Step 23: Action: 0, Reward: 1.3280, Total Reward: 28.4369, Epsilon: 0.650\n",
      "Q-values: [3.0690897 3.01769   2.974554  2.9526403 3.204937 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.66, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.66, Min Distance=0.00\n",
      "Moving: Velocity=1.66\n",
      "Step 24: Brake action applied! Velocity: 1.66\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0837\n",
      "Step 24: Action: 4, Reward: 1.5665, Total Reward: 30.0034, Epsilon: 0.649\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.86\n",
      "Intersection detected: Velocity=1.86, Min Distance=0.00\n",
      "Moving: Velocity=1.86\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0652\n",
      "Step 25: Action: 3, Reward: 1.0343, Total Reward: 31.0377, Epsilon: 0.649\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.80\n",
      "Intersection detected: Velocity=1.80, Min Distance=0.00\n",
      "Moving: Velocity=1.80\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0842\n",
      "Step 26: Action: 1, Reward: 1.0320, Total Reward: 32.0697, Epsilon: 0.648\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.76\n",
      "Intersection detected: Velocity=1.76, Min Distance=0.00\n",
      "Moving: Velocity=1.76\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1151\n",
      "Step 27: Action: 1, Reward: 1.3305, Total Reward: 33.4002, Epsilon: 0.648\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.05\n",
      "Intersection detected: Velocity=2.05, Min Distance=0.00\n",
      "Moving: Velocity=2.05\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1144\n",
      "Step 28: Action: 0, Reward: 1.3420, Total Reward: 34.7422, Epsilon: 0.647\n",
      "Q-values: [2.7037258 2.6144576 2.6604013 2.554949  2.9238095]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.01, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.01, Min Distance=0.00\n",
      "Moving: Velocity=2.01\n",
      "Step 29: Brake action applied! Velocity: 2.01\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3582\n",
      "Step 29: Action: 4, Reward: 1.5805, Total Reward: 36.3227, Epsilon: 0.647\n",
      "Q-values: [2.7377067 2.6496074 2.6812642 2.5721486 2.970826 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.98, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.98, Min Distance=0.00\n",
      "Moving: Velocity=1.98\n",
      "Step 30: Brake action applied! Velocity: 1.98\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.4071\n",
      "Step 30: Action: 4, Reward: 1.5791, Total Reward: 37.9018, Epsilon: 0.646\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.26\n",
      "Intersection detected: Velocity=2.26, Min Distance=0.00\n",
      "Moving: Velocity=2.26\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1114\n",
      "Step 31: Action: 0, Reward: 1.3506, Total Reward: 39.2523, Epsilon: 0.646\n",
      "Q-values: [2.8157375 2.7219946 2.732079  2.6283333 3.0914018]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.23, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.23, Min Distance=0.00\n",
      "Moving: Velocity=2.23\n",
      "Step 32: Brake action applied! Velocity: 2.23\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3328\n",
      "Step 32: Action: 4, Reward: 1.5891, Total Reward: 40.8414, Epsilon: 0.645\n",
      "Q-values: [2.894421  2.804465  2.78855   2.6900733 3.1833632]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.19, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.19, Min Distance=0.00\n",
      "Moving: Velocity=2.19\n",
      "Step 33: Brake action applied! Velocity: 2.19\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3428\n",
      "Step 33: Action: 4, Reward: 1.5876, Total Reward: 42.4291, Epsilon: 0.645\n",
      "Q-values: [2.948239  2.8724625 2.8238575 2.735866  3.2472136]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.15, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.15, Min Distance=0.00\n",
      "Moving: Velocity=2.15\n",
      "Step 34: Brake action applied! Velocity: 2.15\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0707\n",
      "Step 34: Action: 4, Reward: 1.5862, Total Reward: 44.0153, Epsilon: 0.644\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.44\n",
      "Intersection detected: Velocity=2.44, Min Distance=0.00\n",
      "Moving: Velocity=2.44\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0244\n",
      "Step 35: Action: 0, Reward: 1.3577, Total Reward: 45.3729, Epsilon: 0.644\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.41, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.41, Min Distance=0.00\n",
      "Moving: Velocity=2.41\n",
      "Step 36: Brake action applied! Velocity: 2.41\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3924\n",
      "Step 36: Action: 4, Reward: 1.5962, Total Reward: 46.9692, Epsilon: 0.643\n",
      "Q-values: [3.052633  3.0097518 2.8564053 2.826378  3.3583531]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.37, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.37, Min Distance=0.00\n",
      "Moving: Velocity=2.37\n",
      "Step 37: Brake action applied! Velocity: 2.37\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3689\n",
      "Step 37: Action: 4, Reward: 1.5948, Total Reward: 48.5639, Epsilon: 0.643\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.52\n",
      "Intersection detected: Velocity=2.52, Min Distance=0.00\n",
      "Moving: Velocity=2.52\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3762\n",
      "Step 38: Action: 3, Reward: 1.0608, Total Reward: 49.6247, Epsilon: 0.642\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.46\n",
      "Intersection detected: Velocity=2.46, Min Distance=0.00\n",
      "Moving: Velocity=2.46\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0828\n",
      "Step 39: Action: 1, Reward: 1.0584, Total Reward: 50.6831, Epsilon: 0.642\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.42\n",
      "Intersection detected: Velocity=2.42, Min Distance=0.00\n",
      "Moving: Velocity=2.42\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3660\n",
      "Step 40: Action: 1, Reward: 1.3569, Total Reward: 52.0400, Epsilon: 0.641\n",
      "Q-values: [2.914749  2.9416177 2.664922  2.6919413 3.1551087]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.39, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.39, Min Distance=0.00\n",
      "Moving: Velocity=2.39\n",
      "Step 41: Brake action applied! Velocity: 2.39\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0292\n",
      "Step 41: Action: 4, Reward: 1.5954, Total Reward: 53.6354, Epsilon: 0.641\n",
      "Q-values: [2.8885477 2.9249406 2.6288188 2.6657016 3.1115496]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.35, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.35, Min Distance=0.00\n",
      "Moving: Velocity=2.35\n",
      "Step 42: Brake action applied! Velocity: 2.35\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3732\n",
      "Step 42: Action: 4, Reward: 1.5940, Total Reward: 55.2294, Epsilon: 0.640\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.31\n",
      "Intersection detected: Velocity=2.31, Min Distance=0.00\n",
      "Moving: Velocity=2.31\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0537\n",
      "Step 43: Action: 1, Reward: 1.3525, Total Reward: 56.5819, Epsilon: 0.640\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.47\n",
      "Intersection detected: Velocity=2.47, Min Distance=0.00\n",
      "Moving: Velocity=2.47\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0734\n",
      "Step 44: Action: 2, Reward: 1.0587, Total Reward: 57.6406, Epsilon: 0.639\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.41\n",
      "Intersection detected: Velocity=2.41, Min Distance=0.00\n",
      "Moving: Velocity=2.41\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0597\n",
      "Step 45: Action: 1, Reward: 1.0563, Total Reward: 58.6969, Epsilon: 0.639\n",
      "Q-values: [2.929711  2.9671576 2.6475272 2.7091334 3.1189506]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.37, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.37, Min Distance=0.00\n",
      "Moving: Velocity=2.37\n",
      "Step 46: Brake action applied! Velocity: 2.37\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3136\n",
      "Step 46: Action: 4, Reward: 1.5948, Total Reward: 60.2916, Epsilon: 0.638\n",
      "Q-values: [2.9849808 3.0151627 2.6997964 2.7615805 3.1706662]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.33, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.33, Min Distance=0.00\n",
      "Moving: Velocity=2.33\n",
      "Step 47: Brake action applied! Velocity: 2.33\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0577\n",
      "Step 47: Action: 4, Reward: 1.5933, Total Reward: 61.8849, Epsilon: 0.638\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.30, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.30, Min Distance=0.00\n",
      "Moving: Velocity=2.30\n",
      "Step 48: Brake action applied! Velocity: 2.30\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0870\n",
      "Step 48: Action: 4, Reward: 1.5918, Total Reward: 63.4768, Epsilon: 0.637\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.26\n",
      "Intersection detected: Velocity=2.26, Min Distance=0.00\n",
      "Moving: Velocity=2.26\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3076\n",
      "Step 49: Action: 1, Reward: 1.3504, Total Reward: 64.8272, Epsilon: 0.637\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.42\n",
      "Intersection detected: Velocity=2.42, Min Distance=0.00\n",
      "Moving: Velocity=2.42\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0950\n",
      "Step 50: Action: 2, Reward: 1.0567, Total Reward: 65.8838, Epsilon: 0.636\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.44\n",
      "Intersection detected: Velocity=2.44, Min Distance=0.00\n",
      "Moving: Velocity=2.44\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3652\n",
      "Step 51: Action: 3, Reward: 1.0576, Total Reward: 66.9415, Epsilon: 0.636\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.40\n",
      "Intersection detected: Velocity=2.40, Min Distance=0.00\n",
      "Moving: Velocity=2.40\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0519\n",
      "Step 52: Action: 1, Reward: 1.0561, Total Reward: 67.9976, Epsilon: 0.635\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.37, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.37, Min Distance=0.00\n",
      "Moving: Velocity=2.37\n",
      "Step 53: Brake action applied! Velocity: 2.37\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0689\n",
      "Step 53: Action: 4, Reward: 1.5947, Total Reward: 69.5923, Epsilon: 0.635\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.65\n",
      "Intersection detected: Velocity=2.65, Min Distance=0.00\n",
      "Moving: Velocity=2.65\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0269\n",
      "Step 54: Action: 0, Reward: 1.3662, Total Reward: 70.9584, Epsilon: 0.634\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.94\n",
      "Intersection detected: Velocity=2.94, Min Distance=0.00\n",
      "Moving: Velocity=2.94\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6498\n",
      "Step 55: Action: 0, Reward: 1.3776, Total Reward: 72.3361, Epsilon: 0.634\n",
      "Q-values: [2.9460747 2.9033465 2.7209604 2.736008  3.1298363]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.90, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.90, Min Distance=0.00\n",
      "Moving: Velocity=2.90\n",
      "Step 56: Brake action applied! Velocity: 2.90\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0672\n",
      "Step 56: Action: 4, Reward: 1.6162, Total Reward: 73.9523, Epsilon: 0.633\n",
      "Q-values: [2.9377162 2.9037354 2.7263885 2.7302787 3.128779 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.87, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.87, Min Distance=0.00\n",
      "Moving: Velocity=2.87\n",
      "Step 57: Brake action applied! Velocity: 2.87\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0243\n",
      "Step 57: Action: 4, Reward: 1.6147, Total Reward: 75.5670, Epsilon: 0.633\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.83\n",
      "Intersection detected: Velocity=2.83, Min Distance=0.00\n",
      "Moving: Velocity=2.83\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0517\n",
      "Step 58: Action: 1, Reward: 1.3733, Total Reward: 76.9403, Epsilon: 0.632\n",
      "Q-values: [2.919333  2.900511  2.7414758 2.7196136 3.1338966]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.80, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.80, Min Distance=0.00\n",
      "Moving: Velocity=2.80\n",
      "Step 59: Brake action applied! Velocity: 2.80\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0595\n",
      "Step 59: Action: 4, Reward: 1.6118, Total Reward: 78.5521, Epsilon: 0.632\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.92\n",
      "Intersection detected: Velocity=2.92, Min Distance=0.00\n",
      "Moving: Velocity=2.92\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0496\n",
      "Step 60: Action: 2, Reward: 1.0766, Total Reward: 79.6287, Epsilon: 0.631\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.93\n",
      "Intersection detected: Velocity=2.93, Min Distance=0.00\n",
      "Moving: Velocity=2.93\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0571\n",
      "Step 61: Action: 3, Reward: 1.0771, Total Reward: 80.7058, Epsilon: 0.631\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.04\n",
      "Intersection detected: Velocity=3.04, Min Distance=0.00\n",
      "Moving: Velocity=3.04\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3668\n",
      "Step 62: Action: 2, Reward: 1.0814, Total Reward: 81.7873, Epsilon: 0.630\n",
      "Q-values: [2.9163249 2.9184656 2.800704  2.7300274 3.2127178]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.98, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.98, Min Distance=0.00\n",
      "Moving: Velocity=2.98\n",
      "Step 63: Brake action applied! Velocity: 2.98\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6601\n",
      "Step 63: Action: 4, Reward: 1.3192, Total Reward: 83.1065, Epsilon: 0.630\n",
      "Q-values: [2.8986845 2.8996816 2.8115423 2.7355387 3.2322993]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.94, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.94, Min Distance=0.00\n",
      "Moving: Velocity=2.94\n",
      "Step 64: Brake action applied! Velocity: 2.94\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0493\n",
      "Step 64: Action: 4, Reward: 1.6177, Total Reward: 84.7242, Epsilon: 0.629\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.91, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.91, Min Distance=0.00\n",
      "Moving: Velocity=2.91\n",
      "Step 65: Brake action applied! Velocity: 2.91\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3343\n",
      "Step 65: Action: 4, Reward: 1.6162, Total Reward: 86.3404, Epsilon: 0.629\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.02\n",
      "Intersection detected: Velocity=3.02, Min Distance=0.00\n",
      "Moving: Velocity=3.02\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0552\n",
      "Step 66: Action: 3, Reward: 1.0808, Total Reward: 87.4212, Epsilon: 0.628\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.25\n",
      "Intersection detected: Velocity=3.25, Min Distance=0.00\n",
      "Moving: Velocity=3.25\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.9373\n",
      "Step 67: Action: 3, Reward: 1.3902, Total Reward: 88.8114, Epsilon: 0.628\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.52\n",
      "Intersection detected: Velocity=3.52, Min Distance=0.00\n",
      "Moving: Velocity=3.52\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0875\n",
      "Step 68: Action: 3, Reward: 1.4007, Total Reward: 90.2122, Epsilon: 0.627\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.44, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.44, Min Distance=0.00\n",
      "Moving: Velocity=3.44\n",
      "Step 69: Brake action applied! Velocity: 3.44\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0483\n",
      "Step 69: Action: 4, Reward: 1.3377, Total Reward: 91.5499, Epsilon: 0.627\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.73\n",
      "Intersection detected: Velocity=3.73, Min Distance=0.00\n",
      "Moving: Velocity=3.73\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0716\n",
      "Step 70: Action: 0, Reward: 1.4091, Total Reward: 92.9590, Epsilon: 0.626\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.79\n",
      "Intersection detected: Velocity=3.79, Min Distance=0.00\n",
      "Moving: Velocity=3.79\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3357\n",
      "Step 71: Action: 2, Reward: 1.1118, Total Reward: 94.0707, Epsilon: 0.626\n",
      "Q-values: [2.7632384 2.8010142 2.735424  2.656251  3.181177 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.74, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.74, Min Distance=0.00\n",
      "Moving: Velocity=3.74\n",
      "Step 72: Brake action applied! Velocity: 3.74\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0540\n",
      "Step 72: Action: 4, Reward: 1.3497, Total Reward: 95.4204, Epsilon: 0.625\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.84\n",
      "Intersection detected: Velocity=3.84, Min Distance=0.00\n",
      "Moving: Velocity=3.84\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0398\n",
      "Step 73: Action: 2, Reward: 1.1136, Total Reward: 96.5340, Epsilon: 0.625\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.09\n",
      "Intersection detected: Velocity=4.09, Min Distance=0.00\n",
      "Moving: Velocity=4.09\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3568\n",
      "Step 74: Action: 0, Reward: 1.1236, Total Reward: 97.6576, Epsilon: 0.624\n",
      "Q-values: [2.8303938 2.850849  2.7374706 2.6785839 3.1861343]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.05, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.05, Min Distance=0.00\n",
      "Moving: Velocity=4.05\n",
      "Step 75: Brake action applied! Velocity: 4.05\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0510\n",
      "Step 75: Action: 4, Reward: 1.6621, Total Reward: 99.3197, Epsilon: 0.624\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.02\n",
      "Intersection detected: Velocity=4.02, Min Distance=0.00\n",
      "Moving: Velocity=4.02\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3177\n",
      "Step 76: Action: 1, Reward: 1.4206, Total Reward: 100.7403, Epsilon: 0.623\n",
      "Q-values: [2.9375355 2.9306579 2.783288  2.752042  3.241817 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.98, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.98, Min Distance=0.00\n",
      "Moving: Velocity=3.98\n",
      "Step 77: Brake action applied! Velocity: 3.98\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0544\n",
      "Step 77: Action: 4, Reward: 1.6592, Total Reward: 102.3995, Epsilon: 0.623\n",
      "Q-values: [2.9702165 2.9514427 2.7900329 2.7699528 3.2488945]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.94, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.94, Min Distance=0.00\n",
      "Moving: Velocity=3.94\n",
      "Step 78: Brake action applied! Velocity: 3.94\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0344\n",
      "Step 78: Action: 4, Reward: 1.6577, Total Reward: 104.0572, Epsilon: 0.622\n",
      "Q-values: [3.0023537 2.9730887 2.7988377 2.786349  3.2581477]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.91, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.91, Min Distance=0.00\n",
      "Moving: Velocity=3.91\n",
      "Step 79: Brake action applied! Velocity: 3.91\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0473\n",
      "Step 79: Action: 4, Reward: 1.6563, Total Reward: 105.7135, Epsilon: 0.622\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.19\n",
      "Intersection detected: Velocity=4.19, Min Distance=0.00\n",
      "Moving: Velocity=4.19\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3802\n",
      "Step 80: Action: 0, Reward: 1.4277, Total Reward: 107.1412, Epsilon: 0.621\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.16\n",
      "Intersection detected: Velocity=4.16, Min Distance=0.00\n",
      "Moving: Velocity=4.16\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3673\n",
      "Step 81: Action: 1, Reward: 1.4263, Total Reward: 108.5675, Epsilon: 0.621\n",
      "Q-values: [3.0184119 2.9743435 2.7543077 2.7652948 3.1985846]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.12, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.12, Min Distance=0.00\n",
      "Moving: Velocity=4.12\n",
      "Step 82: Brake action applied! Velocity: 4.12\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2996\n",
      "Step 82: Action: 4, Reward: 1.6648, Total Reward: 110.2323, Epsilon: 0.620\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.18\n",
      "Intersection detected: Velocity=4.18, Min Distance=0.00\n",
      "Moving: Velocity=4.18\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0302\n",
      "Step 83: Action: 2, Reward: 1.1273, Total Reward: 111.3596, Epsilon: 0.620\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.45\n",
      "Intersection detected: Velocity=4.45, Min Distance=0.00\n",
      "Moving: Velocity=4.45\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0347\n",
      "Step 84: Action: 0, Reward: 1.1379, Total Reward: 112.4975, Epsilon: 0.619\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.41\n",
      "Intersection detected: Velocity=4.41, Min Distance=0.00\n",
      "Moving: Velocity=4.41\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2987\n",
      "Step 85: Action: 1, Reward: 1.4364, Total Reward: 113.9339, Epsilon: 0.619\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.37, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.37, Min Distance=0.00\n",
      "Moving: Velocity=4.37\n",
      "Step 86: Brake action applied! Velocity: 4.37\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3527\n",
      "Step 86: Action: 4, Reward: 1.6750, Total Reward: 115.6089, Epsilon: 0.618\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.34\n",
      "Intersection detected: Velocity=4.34, Min Distance=0.00\n",
      "Moving: Velocity=4.34\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3729\n",
      "Step 87: Action: 1, Reward: 1.4335, Total Reward: 117.0424, Epsilon: 0.618\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.30, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.30, Min Distance=0.00\n",
      "Moving: Velocity=4.30\n",
      "Step 88: Brake action applied! Velocity: 4.30\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0402\n",
      "Step 88: Action: 4, Reward: 1.6721, Total Reward: 118.7145, Epsilon: 0.617\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.26, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.26, Min Distance=0.00\n",
      "Moving: Velocity=4.26\n",
      "Step 89: Brake action applied! Velocity: 4.26\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3582\n",
      "Step 89: Action: 4, Reward: 1.6706, Total Reward: 120.3851, Epsilon: 0.617\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.32\n",
      "Intersection detected: Velocity=4.32, Min Distance=0.00\n",
      "Moving: Velocity=4.32\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0449\n",
      "Step 90: Action: 2, Reward: 1.1330, Total Reward: 121.5180, Epsilon: 0.616\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.33\n",
      "Intersection detected: Velocity=4.33, Min Distance=0.00\n",
      "Moving: Velocity=4.33\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0352\n",
      "Step 91: Action: 3, Reward: 1.1332, Total Reward: 122.6512, Epsilon: 0.616\n",
      "Q-values: [2.887065  2.9461036 2.7497237 2.6846437 3.1582034]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.29, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.29, Min Distance=0.00\n",
      "Moving: Velocity=4.29\n",
      "Step 92: Brake action applied! Velocity: 4.29\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3385\n",
      "Step 92: Action: 4, Reward: 1.3717, Total Reward: 124.0229, Epsilon: 0.615\n",
      "Q-values: [2.9220583 2.9933114 2.8137333 2.7356033 3.2243848]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.26, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.26, Min Distance=0.00\n",
      "Moving: Velocity=4.26\n",
      "Step 93: Brake action applied! Velocity: 4.26\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0228\n",
      "Step 93: Action: 4, Reward: 1.6703, Total Reward: 125.6932, Epsilon: 0.615\n",
      "Q-values: [2.9301147 3.0110767 2.8486507 2.7617497 3.2577064]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.22, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.22, Min Distance=0.00\n",
      "Moving: Velocity=4.22\n",
      "Step 94: Brake action applied! Velocity: 4.22\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0565\n",
      "Step 94: Action: 4, Reward: 1.6688, Total Reward: 127.3620, Epsilon: 0.614\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.28\n",
      "Intersection detected: Velocity=4.28, Min Distance=0.00\n",
      "Moving: Velocity=4.28\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3539\n",
      "Step 95: Action: 2, Reward: 1.1312, Total Reward: 128.4932, Epsilon: 0.614\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.43\n",
      "Intersection detected: Velocity=4.43, Min Distance=0.00\n",
      "Moving: Velocity=4.43\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6566\n",
      "Step 96: Action: 2, Reward: 1.4373, Total Reward: 129.9305, Epsilon: 0.613\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.67\n",
      "Intersection detected: Velocity=4.67, Min Distance=0.00\n",
      "Moving: Velocity=4.67\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3448\n",
      "Step 97: Action: 2, Reward: 1.4468, Total Reward: 131.3773, Epsilon: 0.613\n",
      "Q-values: [2.777794  2.8513906 2.7682164 2.7057755 3.1485684]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.60, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.60, Min Distance=0.00\n",
      "Moving: Velocity=4.60\n",
      "Step 98: Brake action applied! Velocity: 4.60\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0354\n",
      "Step 98: Action: 4, Reward: 1.3841, Total Reward: 132.7614, Epsilon: 0.612\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.56\n",
      "Intersection detected: Velocity=4.56, Min Distance=0.00\n",
      "Moving: Velocity=4.56\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0580\n",
      "Step 99: Action: 1, Reward: 1.4424, Total Reward: 134.2037, Epsilon: 0.612\n",
      "Q-values: [2.7747018 2.830896  2.7634568 2.724747  3.1402311]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.52, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.52, Min Distance=0.00\n",
      "Moving: Velocity=4.52\n",
      "Step 100: Brake action applied! Velocity: 4.52\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6467\n",
      "Step 100: Action: 4, Reward: 1.6809, Total Reward: 135.8846, Epsilon: 0.611\n",
      "Q-values: [2.7742023 2.8063319 2.7560349 2.7177913 3.1319084]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.49, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.49, Min Distance=0.00\n",
      "Moving: Velocity=4.49\n",
      "Step 101: Brake action applied! Velocity: 4.49\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3132\n",
      "Step 101: Action: 4, Reward: 1.6794, Total Reward: 137.5641, Epsilon: 0.611\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.54\n",
      "Intersection detected: Velocity=4.54, Min Distance=0.00\n",
      "Moving: Velocity=4.54\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0467\n",
      "Step 102: Action: 3, Reward: 1.1416, Total Reward: 138.7057, Epsilon: 0.610\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.81\n",
      "Intersection detected: Velocity=4.81, Min Distance=0.00\n",
      "Moving: Velocity=4.81\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0525\n",
      "Step 103: Action: 0, Reward: 1.1523, Total Reward: 139.8580, Epsilon: 0.610\n",
      "Q-values: [2.8170729 2.7788014 2.7616441 2.7057369 3.1455588]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.77, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.77, Min Distance=0.00\n",
      "Moving: Velocity=4.77\n",
      "Step 104: Brake action applied! Velocity: 4.77\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3217\n",
      "Step 104: Action: 4, Reward: 1.6908, Total Reward: 141.5489, Epsilon: 0.609\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.06\n",
      "Intersection detected: Velocity=5.06, Min Distance=0.00\n",
      "Moving: Velocity=5.06\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3780\n",
      "Step 105: Action: 0, Reward: 1.4623, Total Reward: 143.0112, Epsilon: 0.609\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.11\n",
      "Intersection detected: Velocity=5.11, Min Distance=0.00\n",
      "Moving: Velocity=5.11\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0737\n",
      "Step 106: Action: 3, Reward: 1.1642, Total Reward: 144.1754, Epsilon: 0.608\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.06, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.06, Min Distance=0.00\n",
      "Moving: Velocity=5.06\n",
      "Step 107: Brake action applied! Velocity: 5.06\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3298\n",
      "Step 107: Action: 4, Reward: 1.4024, Total Reward: 145.5779, Epsilon: 0.608\n",
      "Q-values: [2.8886821 2.8596642 2.8214173 2.7389667 3.218947 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.02, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.02, Min Distance=0.00\n",
      "Moving: Velocity=5.02\n",
      "Step 108: Brake action applied! Velocity: 5.02\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0733\n",
      "Step 108: Action: 4, Reward: 1.7010, Total Reward: 147.2788, Epsilon: 0.607\n",
      "Q-values: [2.8961794 2.8739614 2.8291333 2.7387116 3.2289424]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.99, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.99, Min Distance=0.00\n",
      "Moving: Velocity=4.99\n",
      "Step 109: Brake action applied! Velocity: 4.99\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3152\n",
      "Step 109: Action: 4, Reward: 1.6995, Total Reward: 148.9784, Epsilon: 0.607\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.27\n",
      "Intersection detected: Velocity=5.27, Min Distance=0.00\n",
      "Moving: Velocity=5.27\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6358\n",
      "Step 110: Action: 0, Reward: 1.4710, Total Reward: 150.4494, Epsilon: 0.606\n",
      "Q-values: [2.8545983 2.8543441 2.774998  2.683421  3.157311 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.24, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.24, Min Distance=0.00\n",
      "Moving: Velocity=5.24\n",
      "Step 111: Brake action applied! Velocity: 5.24\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0581\n",
      "Step 111: Action: 4, Reward: 1.7095, Total Reward: 152.1589, Epsilon: 0.606\n",
      "Q-values: [2.8620431 2.8752167 2.7694356 2.677735  3.1454856]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.20, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.20, Min Distance=0.00\n",
      "Moving: Velocity=5.20\n",
      "Step 112: Brake action applied! Velocity: 5.20\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0654\n",
      "Step 112: Action: 4, Reward: 1.7081, Total Reward: 153.8670, Epsilon: 0.605\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.24\n",
      "Intersection detected: Velocity=5.24, Min Distance=0.00\n",
      "Moving: Velocity=5.24\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0780\n",
      "Step 113: Action: 3, Reward: 1.1696, Total Reward: 155.0366, Epsilon: 0.605\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.19\n",
      "Intersection detected: Velocity=5.19, Min Distance=0.00\n",
      "Moving: Velocity=5.19\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0525\n",
      "Step 114: Action: 1, Reward: 1.1678, Total Reward: 156.2044, Epsilon: 0.604\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.16\n",
      "Intersection detected: Velocity=5.16, Min Distance=0.00\n",
      "Moving: Velocity=5.16\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3305\n",
      "Step 115: Action: 1, Reward: 1.4663, Total Reward: 157.6707, Epsilon: 0.604\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.12\n",
      "Intersection detected: Velocity=5.12, Min Distance=0.00\n",
      "Moving: Velocity=5.12\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0701\n",
      "Step 116: Action: 1, Reward: 1.4648, Total Reward: 159.1355, Epsilon: 0.604\n",
      "Q-values: [2.902137  2.9542296 2.746374  2.6776743 3.1180122]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.08, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.08, Min Distance=0.00\n",
      "Moving: Velocity=5.08\n",
      "Step 117: Brake action applied! Velocity: 5.08\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2958\n",
      "Step 117: Action: 4, Reward: 1.7034, Total Reward: 160.8389, Epsilon: 0.603\n",
      "Q-values: [2.9240253 2.9809067 2.7524853 2.692746  3.127631 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.05, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.05, Min Distance=0.00\n",
      "Moving: Velocity=5.05\n",
      "Step 118: Brake action applied! Velocity: 5.05\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6564\n",
      "Step 118: Action: 4, Reward: 1.7019, Total Reward: 162.5408, Epsilon: 0.603\n",
      "Q-values: [2.9207115 2.9904075 2.7428107 2.694371  3.118947 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.01, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.01, Min Distance=0.00\n",
      "Moving: Velocity=5.01\n",
      "Step 119: Brake action applied! Velocity: 5.01\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0415\n",
      "Step 119: Action: 4, Reward: 1.7005, Total Reward: 164.2413, Epsilon: 0.602\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.98\n",
      "Intersection detected: Velocity=4.98, Min Distance=0.00\n",
      "Moving: Velocity=4.98\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0313\n",
      "Step 120: Action: 1, Reward: 1.4590, Total Reward: 165.7003, Epsilon: 0.602\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.26\n",
      "Intersection detected: Velocity=5.26, Min Distance=0.00\n",
      "Moving: Velocity=5.26\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3881\n",
      "Step 121: Action: 0, Reward: 1.4705, Total Reward: 167.1708, Epsilon: 0.601\n",
      "Q-values: [2.9201736 3.0036108 2.7346895 2.7134933 3.127083 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.23, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.23, Min Distance=0.00\n",
      "Moving: Velocity=5.23\n",
      "Step 122: Brake action applied! Velocity: 5.23\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0545\n",
      "Step 122: Action: 4, Reward: 1.7090, Total Reward: 168.8798, Epsilon: 0.601\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.19, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.19, Min Distance=0.00\n",
      "Moving: Velocity=5.19\n",
      "Step 123: Brake action applied! Velocity: 5.19\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0428\n",
      "Step 123: Action: 4, Reward: 1.7076, Total Reward: 170.5874, Epsilon: 0.600\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.23\n",
      "Intersection detected: Velocity=5.23, Min Distance=0.00\n",
      "Moving: Velocity=5.23\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3580\n",
      "Step 124: Action: 2, Reward: 1.1691, Total Reward: 171.7566, Epsilon: 0.600\n",
      "Q-values: [2.9161773 2.9614632 2.7293675 2.7359314 3.1436143]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.18, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.18, Min Distance=0.00\n",
      "Moving: Velocity=5.18\n",
      "Step 125: Brake action applied! Velocity: 5.18\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3128\n",
      "Step 125: Action: 4, Reward: 1.4072, Total Reward: 173.1638, Epsilon: 0.599\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.14, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.14, Min Distance=0.00\n",
      "Moving: Velocity=5.14\n",
      "Step 126: Brake action applied! Velocity: 5.14\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0510\n",
      "Step 126: Action: 4, Reward: 1.7058, Total Reward: 174.8696, Epsilon: 0.599\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.19\n",
      "Intersection detected: Velocity=5.19, Min Distance=0.00\n",
      "Moving: Velocity=5.19\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0618\n",
      "Step 127: Action: 2, Reward: 1.1675, Total Reward: 176.0371, Epsilon: 0.598\n",
      "Q-values: [2.891009  2.906896  2.7089818 2.7081044 3.1479352]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.14, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.14, Min Distance=0.00\n",
      "Off-road detected: Penalty applied\n",
      "Moving: Velocity=5.14\n",
      "Step 128: Brake action applied! Velocity: 5.14\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0335\n",
      "Step 128: Action: 4, Reward: -1.4944, Total Reward: 174.5427, Epsilon: 0.598\n",
      "Episode 7 ended early: Terminated=True, Truncated=False\n",
      "Episode 7 completed. Total Reward: 174.5427\n",
      "Episode 8 started\n",
      "Initial observation shape: (259,)\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.03, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.03, Min Distance=0.00\n",
      "Step 1: Brake action applied! Velocity: 0.03\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0381\n",
      "Step 1: Action: 4, Reward: 1.5010, Total Reward: 1.5010, Epsilon: 0.597\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.04\n",
      "Intersection detected: Velocity=0.04, Min Distance=0.00\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3615\n",
      "Step 2: Action: 1, Reward: 1.2617, Total Reward: 2.7627, Epsilon: 0.597\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.02\n",
      "Intersection detected: Velocity=0.02, Min Distance=0.00\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0408\n",
      "Step 3: Action: 1, Reward: 1.2608, Total Reward: 4.0235, Epsilon: 0.596\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.31\n",
      "Intersection detected: Velocity=0.31, Min Distance=0.00\n",
      "Moving: Velocity=0.31\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0591\n",
      "Step 4: Action: 0, Reward: 1.2723, Total Reward: 5.2958, Epsilon: 0.596\n",
      "Q-values: [2.9412324 2.885372  2.7877715 2.7375042 3.2696114]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.27, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.27, Min Distance=0.00\n",
      "Moving: Velocity=0.27\n",
      "Step 5: Brake action applied! Velocity: 0.27\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3896\n",
      "Step 5: Action: 4, Reward: 1.5108, Total Reward: 6.8066, Epsilon: 0.595\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.23\n",
      "Intersection detected: Velocity=0.23, Min Distance=0.00\n",
      "Moving: Velocity=0.23\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3215\n",
      "Step 6: Action: 1, Reward: 1.2694, Total Reward: 8.0759, Epsilon: 0.595\n",
      "Q-values: [2.9217753 2.865296  2.7845855 2.723438  3.2599223]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.20, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.20, Min Distance=0.00\n",
      "Moving: Velocity=0.20\n",
      "Step 7: Brake action applied! Velocity: 0.20\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.7279\n",
      "Step 7: Action: 4, Reward: 1.5079, Total Reward: 9.5838, Epsilon: 0.594\n",
      "Q-values: [2.8777876 2.8313415 2.7543569 2.6917543 3.2128775]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.16, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.16, Min Distance=0.00\n",
      "Moving: Velocity=0.16\n",
      "Step 8: Brake action applied! Velocity: 0.16\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3429\n",
      "Step 8: Action: 4, Reward: 1.5064, Total Reward: 11.0903, Epsilon: 0.594\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.43\n",
      "Intersection detected: Velocity=0.43, Min Distance=0.00\n",
      "Moving: Velocity=0.43\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3713\n",
      "Step 9: Action: 3, Reward: 0.9773, Total Reward: 12.0676, Epsilon: 0.593\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.39\n",
      "Intersection detected: Velocity=0.39, Min Distance=0.00\n",
      "Moving: Velocity=0.39\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6399\n",
      "Step 10: Action: 1, Reward: 0.9756, Total Reward: 13.0432, Epsilon: 0.593\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.66\n",
      "Intersection detected: Velocity=0.66, Min Distance=0.00\n",
      "Moving: Velocity=0.66\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0746\n",
      "Step 11: Action: 3, Reward: 0.9863, Total Reward: 14.0296, Epsilon: 0.592\n",
      "Q-values: [2.7540324 2.7322876 2.6767924 2.6215184 3.087927 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.61, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.61, Min Distance=0.00\n",
      "Moving: Velocity=0.61\n",
      "Step 12: Brake action applied! Velocity: 0.61\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0744\n",
      "Step 12: Action: 4, Reward: 1.2245, Total Reward: 15.2540, Epsilon: 0.592\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.85\n",
      "Intersection detected: Velocity=0.85, Min Distance=0.00\n",
      "Moving: Velocity=0.85\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3537\n",
      "Step 13: Action: 2, Reward: 0.9941, Total Reward: 16.2481, Epsilon: 0.591\n",
      "Q-values: [2.8105264 2.7871554 2.7439485 2.6950326 3.158214 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.81, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.81, Min Distance=0.00\n",
      "Moving: Velocity=0.81\n",
      "Step 14: Brake action applied! Velocity: 0.81\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0547\n",
      "Step 14: Action: 4, Reward: 1.2323, Total Reward: 17.4804, Epsilon: 0.591\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.09\n",
      "Intersection detected: Velocity=1.09, Min Distance=0.00\n",
      "Moving: Velocity=1.09\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3170\n",
      "Step 15: Action: 0, Reward: 1.3037, Total Reward: 18.7841, Epsilon: 0.590\n",
      "Q-values: [2.8934598 2.855257  2.8209436 2.7704716 3.2436163]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.06, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.06, Min Distance=0.00\n",
      "Moving: Velocity=1.06\n",
      "Step 16: Brake action applied! Velocity: 1.06\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0521\n",
      "Step 16: Action: 4, Reward: 1.5422, Total Reward: 20.3264, Epsilon: 0.590\n",
      "Q-values: [2.9449618 2.9027114 2.866553  2.8073637 3.2943616]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.02, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.02, Min Distance=0.00\n",
      "Moving: Velocity=1.02\n",
      "Step 17: Brake action applied! Velocity: 1.02\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0352\n",
      "Step 17: Action: 4, Reward: 1.5408, Total Reward: 21.8671, Epsilon: 0.589\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.31\n",
      "Intersection detected: Velocity=1.31, Min Distance=0.00\n",
      "Moving: Velocity=1.31\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0295\n",
      "Step 18: Action: 0, Reward: 1.3123, Total Reward: 23.1794, Epsilon: 0.589\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.52\n",
      "Intersection detected: Velocity=1.52, Min Distance=0.00\n",
      "Moving: Velocity=1.52\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0380\n",
      "Step 19: Action: 3, Reward: 1.0208, Total Reward: 24.2002, Epsilon: 0.588\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.61\n",
      "Intersection detected: Velocity=1.61, Min Distance=0.00\n",
      "Moving: Velocity=1.61\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0775\n",
      "Step 20: Action: 2, Reward: 1.0245, Total Reward: 25.2248, Epsilon: 0.588\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.57, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.57, Min Distance=0.00\n",
      "Moving: Velocity=1.57\n",
      "Step 21: Brake action applied! Velocity: 1.57\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0524\n",
      "Step 21: Action: 4, Reward: 1.2628, Total Reward: 26.4876, Epsilon: 0.587\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.76\n",
      "Intersection detected: Velocity=1.76, Min Distance=0.00\n",
      "Moving: Velocity=1.76\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0422\n",
      "Step 22: Action: 3, Reward: 1.0303, Total Reward: 27.5180, Epsilon: 0.587\n",
      "Q-values: [2.9371846 2.916973  2.8066823 2.737216  3.23132  ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.70, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.70, Min Distance=0.00\n",
      "Moving: Velocity=1.70\n",
      "Step 23: Brake action applied! Velocity: 1.70\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2977\n",
      "Step 23: Action: 4, Reward: 1.2682, Total Reward: 28.7861, Epsilon: 0.586\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.67, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.67, Min Distance=0.00\n",
      "Moving: Velocity=1.67\n",
      "Step 24: Brake action applied! Velocity: 1.67\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3640\n",
      "Step 24: Action: 4, Reward: 1.5667, Total Reward: 30.3528, Epsilon: 0.586\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.86\n",
      "Intersection detected: Velocity=1.86, Min Distance=0.00\n",
      "Moving: Velocity=1.86\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3412\n",
      "Step 25: Action: 2, Reward: 1.0343, Total Reward: 31.3870, Epsilon: 0.585\n",
      "Q-values: [2.8751185 2.8688607 2.7208767 2.6269643 3.1274436]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.80, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.80, Min Distance=0.00\n",
      "Moving: Velocity=1.80\n",
      "Step 26: Brake action applied! Velocity: 1.80\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3428\n",
      "Step 26: Action: 4, Reward: 1.2719, Total Reward: 32.6589, Epsilon: 0.585\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.01\n",
      "Intersection detected: Velocity=2.01, Min Distance=0.00\n",
      "Moving: Velocity=2.01\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3428\n",
      "Step 27: Action: 2, Reward: 1.0403, Total Reward: 33.6993, Epsilon: 0.584\n",
      "Q-values: [2.8191633 2.839796  2.6736407 2.570149  3.0629945]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.95, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.95, Min Distance=0.00\n",
      "Moving: Velocity=1.95\n",
      "Step 28: Brake action applied! Velocity: 1.95\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0708\n",
      "Step 28: Action: 4, Reward: 1.2779, Total Reward: 34.9772, Epsilon: 0.584\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.15\n",
      "Intersection detected: Velocity=2.15, Min Distance=0.00\n",
      "Moving: Velocity=2.15\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0695\n",
      "Step 29: Action: 2, Reward: 1.0461, Total Reward: 36.0233, Epsilon: 0.583\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.41\n",
      "Intersection detected: Velocity=2.41, Min Distance=0.00\n",
      "Moving: Velocity=2.41\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3864\n",
      "Step 30: Action: 2, Reward: 1.3565, Total Reward: 37.3798, Epsilon: 0.583\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.68\n",
      "Intersection detected: Velocity=2.68, Min Distance=0.00\n",
      "Moving: Velocity=2.68\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.5898\n",
      "Step 31: Action: 2, Reward: 1.3674, Total Reward: 38.7472, Epsilon: 0.582\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.68\n",
      "Intersection detected: Velocity=2.68, Min Distance=0.00\n",
      "Moving: Velocity=2.68\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0574\n",
      "Step 32: Action: 3, Reward: 1.0672, Total Reward: 39.8143, Epsilon: 0.582\n",
      "Q-values: [2.8690922 2.933802  2.7169602 2.619162  3.0944772]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.64, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.64, Min Distance=0.00\n",
      "Moving: Velocity=2.64\n",
      "Step 33: Brake action applied! Velocity: 2.64\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0509\n",
      "Step 33: Action: 4, Reward: 1.3057, Total Reward: 41.1200, Epsilon: 0.581\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.78\n",
      "Intersection detected: Velocity=2.78, Min Distance=0.00\n",
      "Moving: Velocity=2.78\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0293\n",
      "Step 34: Action: 2, Reward: 1.0713, Total Reward: 42.1913, Epsilon: 0.581\n",
      "Q-values: [2.948613  3.0238514 2.7852893 2.692968  3.1741602]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.72, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.72, Min Distance=0.00\n",
      "Moving: Velocity=2.72\n",
      "Step 35: Brake action applied! Velocity: 2.72\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0453\n",
      "Step 35: Action: 4, Reward: 1.3089, Total Reward: 43.5003, Epsilon: 0.580\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.69, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.69, Min Distance=0.00\n",
      "Moving: Velocity=2.69\n",
      "Step 36: Brake action applied! Velocity: 2.69\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0383\n",
      "Step 36: Action: 4, Reward: 1.6074, Total Reward: 45.1077, Epsilon: 0.580\n",
      "Q-values: [3.0237036 3.1072264 2.854091  2.7701335 3.2590227]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.65, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.65, Min Distance=0.00\n",
      "Moving: Velocity=2.65\n",
      "Step 37: Brake action applied! Velocity: 2.65\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0362\n",
      "Step 37: Action: 4, Reward: 1.6060, Total Reward: 46.7137, Epsilon: 0.579\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.78\n",
      "Intersection detected: Velocity=2.78, Min Distance=0.00\n",
      "Moving: Velocity=2.78\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0457\n",
      "Step 38: Action: 2, Reward: 1.0712, Total Reward: 47.7849, Epsilon: 0.579\n",
      "Q-values: [3.0050807 3.0968702 2.8329785 2.7665308 3.242961 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.72, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.72, Min Distance=0.00\n",
      "Moving: Velocity=2.72\n",
      "Step 39: Brake action applied! Velocity: 2.72\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3404\n",
      "Step 39: Action: 4, Reward: 1.3088, Total Reward: 49.0938, Epsilon: 0.578\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.68\n",
      "Intersection detected: Velocity=2.68, Min Distance=0.00\n",
      "Moving: Velocity=2.68\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0346\n",
      "Step 40: Action: 1, Reward: 1.3673, Total Reward: 50.4611, Epsilon: 0.578\n",
      "Q-values: [3.001836  3.094246  2.80828   2.7703857 3.2204945]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.65, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.65, Min Distance=0.00\n",
      "Moving: Velocity=2.65\n",
      "Step 41: Brake action applied! Velocity: 2.65\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0496\n",
      "Step 41: Action: 4, Reward: 1.6059, Total Reward: 52.0670, Epsilon: 0.577\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.93\n",
      "Intersection detected: Velocity=2.93, Min Distance=0.00\n",
      "Moving: Velocity=2.93\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0472\n",
      "Step 42: Action: 0, Reward: 1.3774, Total Reward: 53.4443, Epsilon: 0.577\n",
      "Q-values: [2.938904  3.0201697 2.7402282 2.7261891 3.1498556]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.90, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.90, Min Distance=0.00\n",
      "Moving: Velocity=2.90\n",
      "Step 43: Brake action applied! Velocity: 2.90\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0449\n",
      "Step 43: Action: 4, Reward: 1.6159, Total Reward: 55.0602, Epsilon: 0.576\n",
      "Q-values: [2.9531708 3.024199  2.7451289 2.7373567 3.1609468]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.86, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.86, Min Distance=0.00\n",
      "Moving: Velocity=2.86\n",
      "Step 44: Brake action applied! Velocity: 2.86\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0307\n",
      "Step 44: Action: 4, Reward: 1.6144, Total Reward: 56.6746, Epsilon: 0.576\n",
      "Q-values: [2.9542453 3.01717   2.743318  2.739324  3.1646874]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.82, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.82, Min Distance=0.00\n",
      "Moving: Velocity=2.82\n",
      "Step 45: Brake action applied! Velocity: 2.82\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3703\n",
      "Step 45: Action: 4, Reward: 1.6130, Total Reward: 58.2876, Epsilon: 0.575\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.95\n",
      "Intersection detected: Velocity=2.95, Min Distance=0.00\n",
      "Moving: Velocity=2.95\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3466\n",
      "Step 46: Action: 2, Reward: 1.0778, Total Reward: 59.3655, Epsilon: 0.575\n",
      "Q-values: [2.917894  2.9720793 2.7093492 2.7173066 3.1363733]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.89, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.89, Min Distance=0.00\n",
      "Moving: Velocity=2.89\n",
      "Step 47: Brake action applied! Velocity: 2.89\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3228\n",
      "Step 47: Action: 4, Reward: 1.3154, Total Reward: 60.6809, Epsilon: 0.574\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.85, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.85, Min Distance=0.00\n",
      "Moving: Velocity=2.85\n",
      "Step 48: Brake action applied! Velocity: 2.85\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0547\n",
      "Step 48: Action: 4, Reward: 1.6139, Total Reward: 62.2948, Epsilon: 0.574\n",
      "Q-values: [2.9345162 2.9801588 2.729257  2.740363  3.165405 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.81, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.81, Min Distance=0.00\n",
      "Moving: Velocity=2.81\n",
      "Step 49: Brake action applied! Velocity: 2.81\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3614\n",
      "Step 49: Action: 4, Reward: 1.6124, Total Reward: 63.9072, Epsilon: 0.573\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.10\n",
      "Intersection detected: Velocity=3.10, Min Distance=0.00\n",
      "Moving: Velocity=3.10\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3792\n",
      "Step 50: Action: 0, Reward: 1.3839, Total Reward: 65.2912, Epsilon: 0.573\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.06\n",
      "Intersection detected: Velocity=3.06, Min Distance=0.00\n",
      "Moving: Velocity=3.06\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3587\n",
      "Step 51: Action: 1, Reward: 1.3825, Total Reward: 66.6736, Epsilon: 0.572\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.35\n",
      "Intersection detected: Velocity=3.35, Min Distance=0.00\n",
      "Moving: Velocity=3.35\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3191\n",
      "Step 52: Action: 0, Reward: 1.3940, Total Reward: 68.0676, Epsilon: 0.572\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.44\n",
      "Intersection detected: Velocity=3.44, Min Distance=0.00\n",
      "Moving: Velocity=3.44\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0438\n",
      "Step 53: Action: 2, Reward: 1.0975, Total Reward: 69.1651, Epsilon: 0.571\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.45\n",
      "Intersection detected: Velocity=3.45, Min Distance=0.00\n",
      "Moving: Velocity=3.45\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3668\n",
      "Step 54: Action: 3, Reward: 1.0981, Total Reward: 70.2632, Epsilon: 0.571\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.52\n",
      "Intersection detected: Velocity=3.52, Min Distance=0.00\n",
      "Moving: Velocity=3.52\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3771\n",
      "Step 55: Action: 2, Reward: 1.1009, Total Reward: 71.3641, Epsilon: 0.570\n",
      "Q-values: [2.7638707 2.8724902 2.7209878 2.7078571 3.150366 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.47, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.47, Min Distance=0.00\n",
      "Moving: Velocity=3.47\n",
      "Step 56: Brake action applied! Velocity: 3.47\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3138\n",
      "Step 56: Action: 4, Reward: 1.3389, Total Reward: 72.7030, Epsilon: 0.570\n",
      "Q-values: [2.7523758 2.8709323 2.728456  2.7052116 3.1512265]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.44, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.44, Min Distance=0.00\n",
      "Moving: Velocity=3.44\n",
      "Step 57: Brake action applied! Velocity: 3.44\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6266\n",
      "Step 57: Action: 4, Reward: 1.6374, Total Reward: 74.3404, Epsilon: 0.569\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.40\n",
      "Intersection detected: Velocity=3.40, Min Distance=0.00\n",
      "Moving: Velocity=3.40\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0657\n",
      "Step 58: Action: 1, Reward: 1.3960, Total Reward: 75.7364, Epsilon: 0.569\n",
      "Q-values: [2.7550929 2.883479  2.7520933 2.7092254 3.150179 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.36, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.36, Min Distance=0.00\n",
      "Moving: Velocity=3.36\n",
      "Step 59: Brake action applied! Velocity: 3.36\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6315\n",
      "Step 59: Action: 4, Reward: 1.6345, Total Reward: 77.3709, Epsilon: 0.568\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.45\n",
      "Intersection detected: Velocity=3.45, Min Distance=0.00\n",
      "Moving: Velocity=3.45\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0484\n",
      "Step 60: Action: 2, Reward: 1.0980, Total Reward: 78.4689, Epsilon: 0.568\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.71\n",
      "Intersection detected: Velocity=3.71, Min Distance=0.00\n",
      "Moving: Velocity=3.71\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3232\n",
      "Step 61: Action: 0, Reward: 1.1085, Total Reward: 79.5774, Epsilon: 0.567\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.77\n",
      "Intersection detected: Velocity=3.77, Min Distance=0.00\n",
      "Moving: Velocity=3.77\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0412\n",
      "Step 62: Action: 3, Reward: 1.1108, Total Reward: 80.6882, Epsilon: 0.567\n",
      "Q-values: [2.7877097 2.9209304 2.8061812 2.7112467 3.1733246]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.72, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.72, Min Distance=0.00\n",
      "Moving: Velocity=3.72\n",
      "Step 63: Brake action applied! Velocity: 3.72\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3469\n",
      "Step 63: Action: 4, Reward: 1.3489, Total Reward: 82.0371, Epsilon: 0.566\n",
      "Q-values: [2.8291357 2.9568675 2.8420193 2.7292557 3.2113035]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.69, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.69, Min Distance=0.00\n",
      "Moving: Velocity=3.69\n",
      "Step 64: Brake action applied! Velocity: 3.69\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0230\n",
      "Step 64: Action: 4, Reward: 1.6474, Total Reward: 83.6845, Epsilon: 0.566\n",
      "Q-values: [2.8696258 2.9907267 2.8765779 2.747432  3.2501776]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.65, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.65, Min Distance=0.00\n",
      "Moving: Velocity=3.65\n",
      "Step 65: Brake action applied! Velocity: 3.65\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0454\n",
      "Step 65: Action: 4, Reward: 1.6460, Total Reward: 85.3305, Epsilon: 0.565\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.94\n",
      "Intersection detected: Velocity=3.94, Min Distance=0.00\n",
      "Moving: Velocity=3.94\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0448\n",
      "Step 66: Action: 0, Reward: 1.4175, Total Reward: 86.7480, Epsilon: 0.565\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.01\n",
      "Intersection detected: Velocity=4.01, Min Distance=0.00\n",
      "Moving: Velocity=4.01\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0414\n",
      "Step 67: Action: 2, Reward: 1.1203, Total Reward: 87.8683, Epsilon: 0.564\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.96\n",
      "Intersection detected: Velocity=3.96, Min Distance=0.00\n",
      "Moving: Velocity=3.96\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0265\n",
      "Step 68: Action: 1, Reward: 1.1184, Total Reward: 88.9867, Epsilon: 0.564\n",
      "Q-values: [2.909216  2.9806676 2.8662374 2.7277827 3.2445903]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.92, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.92, Min Distance=0.00\n",
      "Moving: Velocity=3.92\n",
      "Step 69: Brake action applied! Velocity: 3.92\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0599\n",
      "Step 69: Action: 4, Reward: 1.6569, Total Reward: 90.6435, Epsilon: 0.563\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.99\n",
      "Intersection detected: Velocity=3.99, Min Distance=0.00\n",
      "Moving: Velocity=3.99\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0485\n",
      "Step 70: Action: 2, Reward: 1.1197, Total Reward: 91.7632, Epsilon: 0.563\n",
      "Q-values: [2.895121  2.9364471 2.811903  2.699418  3.201868 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.94, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.94, Min Distance=0.00\n",
      "Off-road detected: Penalty applied\n",
      "Moving: Velocity=3.94\n",
      "Step 71: Brake action applied! Velocity: 3.94\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3812\n",
      "Step 71: Action: 4, Reward: -1.5425, Total Reward: 90.2208, Epsilon: 0.562\n",
      "Episode 8 ended early: Terminated=True, Truncated=False\n",
      "Episode 8 completed. Total Reward: 90.2208\n",
      "Episode 9 started\n",
      "Initial observation shape: (259,)\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.28\n",
      "Intersection detected: Velocity=0.28, Min Distance=0.00\n",
      "Moving: Velocity=0.28\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.4068\n",
      "Step 1: Action: 3, Reward: 0.9712, Total Reward: 0.9712, Epsilon: 0.562\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.24\n",
      "Intersection detected: Velocity=0.24, Min Distance=0.00\n",
      "Moving: Velocity=0.24\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3409\n",
      "Step 2: Action: 1, Reward: 0.9697, Total Reward: 1.9409, Epsilon: 0.561\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.20, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.20, Min Distance=0.00\n",
      "Moving: Velocity=0.20\n",
      "Step 3: Brake action applied! Velocity: 0.20\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3236\n",
      "Step 3: Action: 4, Reward: 1.5082, Total Reward: 3.4491, Epsilon: 0.561\n",
      "Q-values: [2.792429  2.8329287 2.6762612 2.6175904 3.0754967]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.17, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.17, Min Distance=0.00\n",
      "Moving: Velocity=0.17\n",
      "Step 4: Brake action applied! Velocity: 0.17\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0850\n",
      "Step 4: Action: 4, Reward: 1.5067, Total Reward: 4.9558, Epsilon: 0.560\n",
      "Q-values: [2.7889056 2.8320158 2.6719997 2.6262527 3.0802155]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.13, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.13, Min Distance=0.00\n",
      "Moving: Velocity=0.13\n",
      "Step 5: Brake action applied! Velocity: 0.13\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3779\n",
      "Step 5: Action: 4, Reward: 1.5053, Total Reward: 6.4611, Epsilon: 0.560\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.41\n",
      "Intersection detected: Velocity=0.41, Min Distance=0.00\n",
      "Moving: Velocity=0.41\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3222\n",
      "Step 6: Action: 3, Reward: 0.9762, Total Reward: 7.4373, Epsilon: 0.559\n",
      "Q-values: [2.7943606 2.8397663 2.6759448 2.6490562 3.090338 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.36, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.36, Min Distance=0.00\n",
      "Moving: Velocity=0.36\n",
      "Step 7: Brake action applied! Velocity: 0.36\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3304\n",
      "Step 7: Action: 4, Reward: 1.2145, Total Reward: 8.6519, Epsilon: 0.559\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.33, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.33, Min Distance=0.00\n",
      "Moving: Velocity=0.33\n",
      "Step 8: Brake action applied! Velocity: 0.33\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3214\n",
      "Step 8: Action: 4, Reward: 1.5130, Total Reward: 10.1649, Epsilon: 0.558\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.61\n",
      "Intersection detected: Velocity=0.61, Min Distance=0.00\n",
      "Moving: Velocity=0.61\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0409\n",
      "Step 9: Action: 0, Reward: 1.2845, Total Reward: 11.4494, Epsilon: 0.558\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.86\n",
      "Intersection detected: Velocity=0.86, Min Distance=0.00\n",
      "Moving: Velocity=0.86\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0467\n",
      "Step 10: Action: 2, Reward: 0.9945, Total Reward: 12.4439, Epsilon: 0.557\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.14\n",
      "Intersection detected: Velocity=1.14, Min Distance=0.00\n",
      "Moving: Velocity=1.14\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3183\n",
      "Step 11: Action: 0, Reward: 1.0055, Total Reward: 13.4495, Epsilon: 0.557\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.35\n",
      "Intersection detected: Velocity=1.35, Min Distance=0.00\n",
      "Moving: Velocity=1.35\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3337\n",
      "Step 12: Action: 3, Reward: 1.0140, Total Reward: 14.4635, Epsilon: 0.556\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.30\n",
      "Intersection detected: Velocity=1.30, Min Distance=0.00\n",
      "Moving: Velocity=1.30\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3663\n",
      "Step 13: Action: 1, Reward: 1.0119, Total Reward: 15.4754, Epsilon: 0.556\n",
      "Q-values: [2.950153  3.0361774 2.835608  2.7943738 3.2706285]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.26, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.26, Min Distance=0.00\n",
      "Moving: Velocity=1.26\n",
      "Step 14: Brake action applied! Velocity: 1.26\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0345\n",
      "Step 14: Action: 4, Reward: 1.5504, Total Reward: 17.0258, Epsilon: 0.555\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.22, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.22, Min Distance=0.00\n",
      "Moving: Velocity=1.22\n",
      "Step 15: Brake action applied! Velocity: 1.22\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3679\n",
      "Step 15: Action: 4, Reward: 1.5490, Total Reward: 18.5748, Epsilon: 0.555\n",
      "Q-values: [2.919977  2.9881034 2.8093393 2.7677433 3.2319438]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.19, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.19, Min Distance=0.00\n",
      "Moving: Velocity=1.19\n",
      "Step 16: Brake action applied! Velocity: 1.19\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0321\n",
      "Step 16: Action: 4, Reward: 1.5475, Total Reward: 20.1223, Epsilon: 0.554\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.47\n",
      "Intersection detected: Velocity=1.47, Min Distance=0.00\n",
      "Moving: Velocity=1.47\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0467\n",
      "Step 17: Action: 0, Reward: 1.3190, Total Reward: 21.4413, Epsilon: 0.554\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.76\n",
      "Intersection detected: Velocity=1.76, Min Distance=0.00\n",
      "Moving: Velocity=1.76\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3823\n",
      "Step 18: Action: 0, Reward: 1.3305, Total Reward: 22.7718, Epsilon: 0.554\n",
      "Q-values: [2.8347287 2.865469  2.7250402 2.6919503 3.1259723]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.73, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.73, Min Distance=0.00\n",
      "Moving: Velocity=1.73\n",
      "Step 19: Brake action applied! Velocity: 1.73\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3105\n",
      "Step 19: Action: 4, Reward: 1.5690, Total Reward: 24.3408, Epsilon: 0.553\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.69\n",
      "Intersection detected: Velocity=1.69, Min Distance=0.00\n",
      "Moving: Velocity=1.69\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0389\n",
      "Step 20: Action: 1, Reward: 1.3276, Total Reward: 25.6684, Epsilon: 0.553\n",
      "Q-values: [2.8474927 2.8632293 2.737213  2.7052808 3.134652 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.65, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.65, Min Distance=0.00\n",
      "Moving: Velocity=1.65\n",
      "Step 21: Brake action applied! Velocity: 1.65\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3175\n",
      "Step 21: Action: 4, Reward: 1.5661, Total Reward: 27.2345, Epsilon: 0.552\n",
      "Q-values: [2.8552113 2.8644576 2.7470965 2.7111223 3.1393304]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.62, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.62, Min Distance=0.00\n",
      "Moving: Velocity=1.62\n",
      "Step 22: Brake action applied! Velocity: 1.62\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3353\n",
      "Step 22: Action: 4, Reward: 1.5647, Total Reward: 28.7992, Epsilon: 0.552\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.81\n",
      "Intersection detected: Velocity=1.81, Min Distance=0.00\n",
      "Moving: Velocity=1.81\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3826\n",
      "Step 23: Action: 3, Reward: 1.0325, Total Reward: 29.8317, Epsilon: 0.551\n",
      "Q-values: [2.8492138 2.842181  2.737792  2.703339  3.111036 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.76, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.76, Min Distance=0.00\n",
      "Moving: Velocity=1.76\n",
      "Step 24: Brake action applied! Velocity: 1.76\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0527\n",
      "Step 24: Action: 4, Reward: 1.2702, Total Reward: 31.1019, Epsilon: 0.551\n",
      "Q-values: [2.8980207 2.8835542 2.775074  2.7365088 3.1459696]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.72, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.72, Min Distance=0.00\n",
      "Moving: Velocity=1.72\n",
      "Step 25: Brake action applied! Velocity: 1.72\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0297\n",
      "Step 25: Action: 4, Reward: 1.5687, Total Reward: 32.6707, Epsilon: 0.550\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.91\n",
      "Intersection detected: Velocity=1.91, Min Distance=0.00\n",
      "Moving: Velocity=1.91\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3100\n",
      "Step 26: Action: 3, Reward: 1.0366, Total Reward: 33.7072, Epsilon: 0.550\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.86, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.86, Min Distance=0.00\n",
      "Moving: Velocity=1.86\n",
      "Step 27: Brake action applied! Velocity: 1.86\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3230\n",
      "Step 27: Action: 4, Reward: 1.2743, Total Reward: 34.9815, Epsilon: 0.549\n",
      "Q-values: [2.9801044 2.9697487 2.8465245 2.7792768 3.2244687]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.82, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.82, Min Distance=0.00\n",
      "Moving: Velocity=1.82\n",
      "Step 28: Brake action applied! Velocity: 1.82\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0273\n",
      "Step 28: Action: 4, Reward: 1.5728, Total Reward: 36.5543, Epsilon: 0.549\n",
      "Q-values: [2.999412  3.0005865 2.8685303 2.7906423 3.2518835]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.78, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.78, Min Distance=0.00\n",
      "Moving: Velocity=1.78\n",
      "Step 29: Brake action applied! Velocity: 1.78\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3165\n",
      "Step 29: Action: 4, Reward: 1.5713, Total Reward: 38.1257, Epsilon: 0.548\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.97\n",
      "Intersection detected: Velocity=1.97, Min Distance=0.00\n",
      "Moving: Velocity=1.97\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0834\n",
      "Step 30: Action: 2, Reward: 1.0389, Total Reward: 39.1645, Epsilon: 0.548\n",
      "Q-values: [2.9485734 2.9608781 2.8215675 2.718097  3.2066483]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.91, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.91, Min Distance=0.00\n",
      "Moving: Velocity=1.91\n",
      "Step 31: Brake action applied! Velocity: 1.91\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0648\n",
      "Step 31: Action: 4, Reward: 1.2765, Total Reward: 40.4410, Epsilon: 0.547\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.87\n",
      "Intersection detected: Velocity=1.87, Min Distance=0.00\n",
      "Moving: Velocity=1.87\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6991\n",
      "Step 32: Action: 1, Reward: 1.3350, Total Reward: 41.7760, Epsilon: 0.547\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.84\n",
      "Intersection detected: Velocity=1.84, Min Distance=0.00\n",
      "Moving: Velocity=1.84\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0295\n",
      "Step 33: Action: 1, Reward: 1.3335, Total Reward: 43.1096, Epsilon: 0.546\n",
      "Q-values: [2.8957036 2.905381  2.7522628 2.6326308 3.1228535]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.80, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.80, Min Distance=0.00\n",
      "Moving: Velocity=1.80\n",
      "Step 34: Brake action applied! Velocity: 1.80\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3595\n",
      "Step 34: Action: 4, Reward: 1.5721, Total Reward: 44.6816, Epsilon: 0.546\n",
      "Q-values: [2.8658268 2.8828485 2.7287865 2.6074367 3.0938556]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.77, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.77, Min Distance=0.00\n",
      "Moving: Velocity=1.77\n",
      "Step 35: Brake action applied! Velocity: 1.77\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3338\n",
      "Step 35: Action: 4, Reward: 1.5706, Total Reward: 46.2523, Epsilon: 0.545\n",
      "Q-values: [2.851423  2.871369  2.7202733 2.5877416 3.0842535]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.73, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.73, Min Distance=0.00\n",
      "Moving: Velocity=1.73\n",
      "Step 36: Brake action applied! Velocity: 1.73\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3790\n",
      "Step 36: Action: 4, Reward: 1.5692, Total Reward: 47.8214, Epsilon: 0.545\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.02\n",
      "Intersection detected: Velocity=2.02, Min Distance=0.00\n",
      "Moving: Velocity=2.02\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3089\n",
      "Step 37: Action: 0, Reward: 1.3407, Total Reward: 49.1621, Epsilon: 0.544\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.19\n",
      "Intersection detected: Velocity=2.19, Min Distance=0.00\n",
      "Moving: Velocity=2.19\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0554\n",
      "Step 38: Action: 3, Reward: 1.0474, Total Reward: 50.2095, Epsilon: 0.544\n",
      "Q-values: [2.8549786 2.8825035 2.727792  2.5907564 3.0927296]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.13, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.13, Min Distance=0.00\n",
      "Moving: Velocity=2.13\n",
      "Step 39: Brake action applied! Velocity: 2.13\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0735\n",
      "Step 39: Action: 4, Reward: 1.2851, Total Reward: 51.4946, Epsilon: 0.543\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.26\n",
      "Intersection detected: Velocity=2.26, Min Distance=0.00\n",
      "Moving: Velocity=2.26\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3205\n",
      "Step 40: Action: 2, Reward: 1.0505, Total Reward: 52.5451, Epsilon: 0.543\n",
      "Q-values: [2.9431243 2.9602113 2.7993152 2.6660397 3.184376 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.21, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.21, Min Distance=0.00\n",
      "Moving: Velocity=2.21\n",
      "Step 41: Brake action applied! Velocity: 2.21\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0407\n",
      "Step 41: Action: 4, Reward: 1.2882, Total Reward: 53.8334, Epsilon: 0.542\n",
      "Q-values: [2.9940677 2.9998403 2.836542  2.7040708 3.2328053]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.17, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.17, Min Distance=0.00\n",
      "Moving: Velocity=2.17\n",
      "Step 42: Brake action applied! Velocity: 2.17\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0822\n",
      "Step 42: Action: 4, Reward: 1.5867, Total Reward: 55.4201, Epsilon: 0.542\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.46\n",
      "Intersection detected: Velocity=2.46, Min Distance=0.00\n",
      "Moving: Velocity=2.46\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0546\n",
      "Step 43: Action: 0, Reward: 1.3582, Total Reward: 56.7783, Epsilon: 0.541\n",
      "Q-values: [3.0004904 2.9889953 2.8391387 2.7114224 3.247614 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.42, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.42, Min Distance=0.00\n",
      "Moving: Velocity=2.42\n",
      "Step 44: Brake action applied! Velocity: 2.42\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3949\n",
      "Step 44: Action: 4, Reward: 1.5968, Total Reward: 58.3751, Epsilon: 0.541\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.56\n",
      "Intersection detected: Velocity=2.56, Min Distance=0.00\n",
      "Moving: Velocity=2.56\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0635\n",
      "Step 45: Action: 2, Reward: 1.0626, Total Reward: 59.4377, Epsilon: 0.540\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.50\n",
      "Intersection detected: Velocity=2.50, Min Distance=0.00\n",
      "Moving: Velocity=2.50\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3562\n",
      "Step 46: Action: 1, Reward: 1.0602, Total Reward: 60.4978, Epsilon: 0.540\n",
      "Q-values: [2.9339044 2.8996313 2.7657344 2.66631   3.1673245]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.47, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.47, Min Distance=0.00\n",
      "Moving: Velocity=2.47\n",
      "Step 47: Brake action applied! Velocity: 2.47\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3418\n",
      "Step 47: Action: 4, Reward: 1.5987, Total Reward: 62.0965, Epsilon: 0.539\n",
      "Q-values: [2.9183514 2.8785014 2.7469628 2.6609702 3.1436713]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.43, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.43, Min Distance=0.00\n",
      "Moving: Velocity=2.43\n",
      "Step 48: Brake action applied! Velocity: 2.43\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3364\n",
      "Step 48: Action: 4, Reward: 1.5972, Total Reward: 63.6937, Epsilon: 0.539\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.72\n",
      "Intersection detected: Velocity=2.72, Min Distance=0.00\n",
      "Moving: Velocity=2.72\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0531\n",
      "Step 49: Action: 0, Reward: 1.3687, Total Reward: 65.0624, Epsilon: 0.538\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.68, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.68, Min Distance=0.00\n",
      "Moving: Velocity=2.68\n",
      "Step 50: Brake action applied! Velocity: 2.68\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0727\n",
      "Step 50: Action: 4, Reward: 1.6072, Total Reward: 66.6696, Epsilon: 0.538\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.97\n",
      "Intersection detected: Velocity=2.97, Min Distance=0.00\n",
      "Moving: Velocity=2.97\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2845\n",
      "Step 51: Action: 0, Reward: 1.3787, Total Reward: 68.0484, Epsilon: 0.537\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.25\n",
      "Intersection detected: Velocity=3.25, Min Distance=0.00\n",
      "Moving: Velocity=3.25\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0403\n",
      "Step 52: Action: 0, Reward: 1.3902, Total Reward: 69.4386, Epsilon: 0.537\n",
      "Q-values: [2.8908856 2.8976612 2.75947   2.7133021 3.1632433]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.22, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.22, Min Distance=0.00\n",
      "Moving: Velocity=3.22\n",
      "Step 53: Brake action applied! Velocity: 3.22\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0487\n",
      "Step 53: Action: 4, Reward: 1.6287, Total Reward: 71.0673, Epsilon: 0.536\n",
      "Q-values: [2.946947  2.9558132 2.817497  2.7680206 3.2337403]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.18, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.18, Min Distance=0.00\n",
      "Moving: Velocity=3.18\n",
      "Step 54: Brake action applied! Velocity: 3.18\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3353\n",
      "Step 54: Action: 4, Reward: 1.6273, Total Reward: 72.6946, Epsilon: 0.536\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.15\n",
      "Intersection detected: Velocity=3.15, Min Distance=0.00\n",
      "Moving: Velocity=3.15\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0376\n",
      "Step 55: Action: 1, Reward: 1.3858, Total Reward: 74.0804, Epsilon: 0.535\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.25\n",
      "Intersection detected: Velocity=3.25, Min Distance=0.00\n",
      "Moving: Velocity=3.25\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0420\n",
      "Step 56: Action: 2, Reward: 1.0899, Total Reward: 75.1703, Epsilon: 0.535\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.50\n",
      "Intersection detected: Velocity=3.50, Min Distance=0.00\n",
      "Moving: Velocity=3.50\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.5964\n",
      "Step 57: Action: 0, Reward: 1.1001, Total Reward: 76.2704, Epsilon: 0.534\n",
      "Q-values: [2.886447  2.90513   2.7634838 2.709814  3.1845443]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.46, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.46, Min Distance=0.00\n",
      "Moving: Velocity=3.46\n",
      "Step 58: Brake action applied! Velocity: 3.46\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0544\n",
      "Step 58: Action: 4, Reward: 1.6386, Total Reward: 77.9090, Epsilon: 0.534\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.43, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.43, Min Distance=0.00\n",
      "Moving: Velocity=3.43\n",
      "Step 59: Brake action applied! Velocity: 3.43\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0448\n",
      "Step 59: Action: 4, Reward: 1.6371, Total Reward: 79.5461, Epsilon: 0.533\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.51\n",
      "Intersection detected: Velocity=3.51, Min Distance=0.00\n",
      "Moving: Velocity=3.51\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0410\n",
      "Step 60: Action: 2, Reward: 1.1006, Total Reward: 80.6467, Epsilon: 0.533\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.73\n",
      "Intersection detected: Velocity=3.73, Min Distance=0.00\n",
      "Moving: Velocity=3.73\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3265\n",
      "Step 61: Action: 2, Reward: 1.4091, Total Reward: 82.0558, Epsilon: 0.532\n",
      "Q-values: [2.8611093 2.8787978 2.7036963 2.6520705 3.140413 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.65, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.65, Min Distance=0.00\n",
      "Moving: Velocity=3.65\n",
      "Step 62: Brake action applied! Velocity: 3.65\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0591\n",
      "Step 62: Action: 4, Reward: 1.3462, Total Reward: 83.4020, Epsilon: 0.532\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.61, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.61, Min Distance=0.00\n",
      "Moving: Velocity=3.61\n",
      "Step 63: Brake action applied! Velocity: 3.61\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0500\n",
      "Step 63: Action: 4, Reward: 1.6446, Total Reward: 85.0466, Epsilon: 0.531\n",
      "Q-values: [2.9329066 2.9437437 2.7413514 2.7025237 3.199699 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.58, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.58, Min Distance=0.00\n",
      "Moving: Velocity=3.58\n",
      "Step 64: Brake action applied! Velocity: 3.58\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6838\n",
      "Step 64: Action: 4, Reward: 1.6431, Total Reward: 86.6897, Epsilon: 0.531\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.66\n",
      "Intersection detected: Velocity=3.66, Min Distance=0.00\n",
      "Moving: Velocity=3.66\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0417\n",
      "Step 65: Action: 3, Reward: 1.1063, Total Reward: 87.7960, Epsilon: 0.530\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.92\n",
      "Intersection detected: Velocity=3.92, Min Distance=0.00\n",
      "Moving: Velocity=3.92\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0447\n",
      "Step 66: Action: 0, Reward: 1.1167, Total Reward: 88.9128, Epsilon: 0.530\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.20\n",
      "Intersection detected: Velocity=4.20, Min Distance=0.00\n",
      "Moving: Velocity=4.20\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0355\n",
      "Step 67: Action: 0, Reward: 1.4282, Total Reward: 90.3409, Epsilon: 0.529\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.27\n",
      "Intersection detected: Velocity=4.27, Min Distance=0.00\n",
      "Moving: Velocity=4.27\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0358\n",
      "Step 68: Action: 3, Reward: 1.1309, Total Reward: 91.4719, Epsilon: 0.529\n",
      "Q-values: [2.9589856 2.9789226 2.730792  2.7125494 3.1840215]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.22, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.22, Min Distance=0.00\n",
      "Moving: Velocity=4.22\n",
      "Step 69: Brake action applied! Velocity: 4.22\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0385\n",
      "Step 69: Action: 4, Reward: 1.3690, Total Reward: 92.8409, Epsilon: 0.528\n",
      "Q-values: [3.0010588 3.0266707 2.7713716 2.753416  3.228891 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.19, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.19, Min Distance=0.00\n",
      "Moving: Velocity=4.19\n",
      "Step 70: Brake action applied! Velocity: 4.19\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0279\n",
      "Step 70: Action: 4, Reward: 1.6675, Total Reward: 94.5084, Epsilon: 0.528\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.24\n",
      "Intersection detected: Velocity=4.24, Min Distance=0.00\n",
      "Moving: Velocity=4.24\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0725\n",
      "Step 71: Action: 2, Reward: 1.1298, Total Reward: 95.6381, Epsilon: 0.527\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.51\n",
      "Intersection detected: Velocity=4.51, Min Distance=0.00\n",
      "Moving: Velocity=4.51\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0448\n",
      "Step 72: Action: 0, Reward: 1.1404, Total Reward: 96.7785, Epsilon: 0.527\n",
      "Q-values: [2.9677572 3.0039985 2.7583525 2.734221  3.2040174]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.47, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.47, Min Distance=0.00\n",
      "Moving: Velocity=4.47\n",
      "Step 73: Brake action applied! Velocity: 4.47\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6776\n",
      "Step 73: Action: 4, Reward: 1.6789, Total Reward: 98.4573, Epsilon: 0.526\n",
      "Q-values: [2.9770582 3.000964  2.768987  2.7399886 3.209629 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.44, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.44, Min Distance=0.00\n",
      "Moving: Velocity=4.44\n",
      "Step 74: Brake action applied! Velocity: 4.44\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0328\n",
      "Step 74: Action: 4, Reward: 1.6774, Total Reward: 100.1348, Epsilon: 0.526\n",
      "Q-values: [2.9525678 2.9632015 2.7517924 2.718791  3.184445 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.40, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.40, Min Distance=0.00\n",
      "Moving: Velocity=4.40\n",
      "Step 75: Brake action applied! Velocity: 4.40\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3439\n",
      "Step 75: Action: 4, Reward: 1.6760, Total Reward: 101.8107, Epsilon: 0.525\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.69\n",
      "Intersection detected: Velocity=4.69, Min Distance=0.00\n",
      "Moving: Velocity=4.69\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0557\n",
      "Step 76: Action: 0, Reward: 1.4474, Total Reward: 103.2582, Epsilon: 0.525\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.65, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.65, Min Distance=0.00\n",
      "Moving: Velocity=4.65\n",
      "Step 77: Brake action applied! Velocity: 4.65\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0543\n",
      "Step 77: Action: 4, Reward: 1.6860, Total Reward: 104.9442, Epsilon: 0.524\n",
      "Q-values: [2.9173505 2.8740332 2.7365417 2.684194  3.1555035]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.61, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.61, Min Distance=0.00\n",
      "Moving: Velocity=4.61\n",
      "Step 78: Brake action applied! Velocity: 4.61\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3426\n",
      "Step 78: Action: 4, Reward: 1.6845, Total Reward: 106.6287, Epsilon: 0.524\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.90\n",
      "Intersection detected: Velocity=4.90, Min Distance=0.00\n",
      "Moving: Velocity=4.90\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3491\n",
      "Step 79: Action: 0, Reward: 1.4560, Total Reward: 108.0847, Epsilon: 0.523\n",
      "Q-values: [2.8660524 2.801666  2.7021148 2.6344428 3.0983984]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=4.86, Min Distance=0.00\n",
      "Intersection detected: Velocity=4.86, Min Distance=0.00\n",
      "Moving: Velocity=4.86\n",
      "Step 80: Brake action applied! Velocity: 4.86\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0559\n",
      "Step 80: Action: 4, Reward: 1.6946, Total Reward: 109.7793, Epsilon: 0.523\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.15\n",
      "Intersection detected: Velocity=5.15, Min Distance=0.00\n",
      "Moving: Velocity=5.15\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2973\n",
      "Step 81: Action: 0, Reward: 1.4660, Total Reward: 111.2453, Epsilon: 0.522\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.20\n",
      "Intersection detected: Velocity=5.20, Min Distance=0.00\n",
      "Moving: Velocity=5.20\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3809\n",
      "Step 82: Action: 3, Reward: 1.1679, Total Reward: 112.4132, Epsilon: 0.522\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.15\n",
      "Intersection detected: Velocity=5.15, Min Distance=0.00\n",
      "Moving: Velocity=5.15\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0609\n",
      "Step 83: Action: 1, Reward: 1.1661, Total Reward: 113.5794, Epsilon: 0.521\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.18\n",
      "Intersection detected: Velocity=5.18, Min Distance=0.00\n",
      "Moving: Velocity=5.18\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0390\n",
      "Step 84: Action: 2, Reward: 1.1672, Total Reward: 114.7466, Epsilon: 0.521\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.14, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.14, Min Distance=0.00\n",
      "Moving: Velocity=5.14\n",
      "Step 85: Brake action applied! Velocity: 5.14\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0221\n",
      "Step 85: Action: 4, Reward: 1.4054, Total Reward: 116.1520, Epsilon: 0.520\n",
      "Q-values: [2.998916  2.9078262 2.8370047 2.7152438 3.2348127]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.10, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.10, Min Distance=0.00\n",
      "Moving: Velocity=5.10\n",
      "Step 86: Brake action applied! Velocity: 5.10\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0568\n",
      "Step 86: Action: 4, Reward: 1.7040, Total Reward: 117.8560, Epsilon: 0.520\n",
      "Q-values: [3.0441988 2.9526877 2.8769536 2.753091  3.2843437]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.06, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.06, Min Distance=0.00\n",
      "Moving: Velocity=5.06\n",
      "Step 87: Brake action applied! Velocity: 5.06\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0488\n",
      "Step 87: Action: 4, Reward: 1.7025, Total Reward: 119.5585, Epsilon: 0.519\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.35\n",
      "Intersection detected: Velocity=5.35, Min Distance=0.00\n",
      "Moving: Velocity=5.35\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0698\n",
      "Step 88: Action: 0, Reward: 1.4740, Total Reward: 121.0324, Epsilon: 0.519\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.64\n",
      "Intersection detected: Velocity=5.64, Min Distance=0.00\n",
      "Moving: Velocity=5.64\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0474\n",
      "Step 89: Action: 0, Reward: 1.4855, Total Reward: 122.5179, Epsilon: 0.518\n",
      "Q-values: [3.012083  2.9320643 2.8302875 2.7262774 3.255988 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.60, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.60, Min Distance=0.00\n",
      "Moving: Velocity=5.60\n",
      "Step 90: Brake action applied! Velocity: 5.60\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3312\n",
      "Step 90: Action: 4, Reward: 1.7240, Total Reward: 124.2419, Epsilon: 0.518\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.63\n",
      "Intersection detected: Velocity=5.63, Min Distance=0.00\n",
      "Moving: Velocity=5.63\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0294\n",
      "Step 91: Action: 3, Reward: 1.1854, Total Reward: 125.4273, Epsilon: 0.517\n",
      "Q-values: [2.9522588 2.8892713 2.7533894 2.6744668 3.178509 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.59, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.59, Min Distance=0.00\n",
      "Moving: Velocity=5.59\n",
      "Step 92: Brake action applied! Velocity: 5.59\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0535\n",
      "Step 92: Action: 4, Reward: 1.4236, Total Reward: 126.8509, Epsilon: 0.517\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.63\n",
      "Intersection detected: Velocity=5.63, Min Distance=0.00\n",
      "Moving: Velocity=5.63\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0517\n",
      "Step 93: Action: 3, Reward: 1.1852, Total Reward: 128.0361, Epsilon: 0.516\n",
      "Q-values: [2.9073682 2.8596373 2.697771  2.6423492 3.1269202]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.58, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.58, Min Distance=0.00\n",
      "Moving: Velocity=5.58\n",
      "Step 94: Brake action applied! Velocity: 5.58\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0445\n",
      "Step 94: Action: 4, Reward: 1.4233, Total Reward: 129.4594, Epsilon: 0.516\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=5.55, Min Distance=0.00\n",
      "Intersection detected: Velocity=5.55, Min Distance=0.00\n",
      "Moving: Velocity=5.55\n",
      "Step 95: Brake action applied! Velocity: 5.55\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3395\n",
      "Step 95: Action: 4, Reward: 1.7218, Total Reward: 131.1812, Epsilon: 0.515\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.83\n",
      "Intersection detected: Velocity=5.83, Min Distance=0.00\n",
      "Moving: Velocity=5.83\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0444\n",
      "Step 96: Action: 0, Reward: 1.4933, Total Reward: 132.6745, Epsilon: 0.515\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.80\n",
      "Intersection detected: Velocity=5.80, Min Distance=0.00\n",
      "Moving: Velocity=5.80\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0504\n",
      "Step 97: Action: 1, Reward: 1.4918, Total Reward: 134.1663, Epsilon: 0.514\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.83\n",
      "Intersection detected: Velocity=5.83, Min Distance=0.00\n",
      "Moving: Velocity=5.83\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3304\n",
      "Step 98: Action: 2, Reward: 1.1932, Total Reward: 135.3596, Epsilon: 0.514\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=5.91\n",
      "Intersection detected: Velocity=5.91, Min Distance=0.00\n",
      "Moving: Velocity=5.91\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3919\n",
      "Step 99: Action: 2, Reward: 1.4964, Total Reward: 136.8560, Epsilon: 0.513\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.14\n",
      "Intersection detected: Velocity=6.14, Min Distance=0.00\n",
      "Moving: Velocity=6.14\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3425\n",
      "Step 100: Action: 0, Reward: 1.2056, Total Reward: 138.0615, Epsilon: 0.513\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.16\n",
      "Intersection detected: Velocity=6.16, Min Distance=0.00\n",
      "Moving: Velocity=6.16\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0648\n",
      "Step 101: Action: 3, Reward: 1.2062, Total Reward: 139.2677, Epsilon: 0.512\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.12, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.12, Min Distance=0.00\n",
      "Moving: Velocity=6.12\n",
      "Step 102: Brake action applied! Velocity: 6.12\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0508\n",
      "Step 102: Action: 4, Reward: 1.4446, Total Reward: 140.7124, Epsilon: 0.512\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.40\n",
      "Intersection detected: Velocity=6.40, Min Distance=0.00\n",
      "Moving: Velocity=6.40\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3361\n",
      "Step 103: Action: 0, Reward: 1.5161, Total Reward: 142.2285, Epsilon: 0.511\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.43\n",
      "Intersection detected: Velocity=6.43, Min Distance=0.00\n",
      "Moving: Velocity=6.43\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0452\n",
      "Step 104: Action: 2, Reward: 1.2174, Total Reward: 143.4459, Epsilon: 0.511\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.39, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.39, Min Distance=0.00\n",
      "Moving: Velocity=6.39\n",
      "Step 105: Brake action applied! Velocity: 6.39\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3038\n",
      "Step 105: Action: 4, Reward: 1.4557, Total Reward: 144.9015, Epsilon: 0.510\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.41\n",
      "Intersection detected: Velocity=6.41, Min Distance=0.00\n",
      "Moving: Velocity=6.41\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3525\n",
      "Step 106: Action: 3, Reward: 1.2163, Total Reward: 146.1179, Epsilon: 0.510\n",
      "Q-values: [2.8235905 2.9186645 2.7109532 2.7248871 3.1408978]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.37, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.37, Min Distance=0.00\n",
      "Moving: Velocity=6.37\n",
      "Step 107: Brake action applied! Velocity: 6.37\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0717\n",
      "Step 107: Action: 4, Reward: 1.4546, Total Reward: 147.5725, Epsilon: 0.509\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.65\n",
      "Intersection detected: Velocity=6.65, Min Distance=0.00\n",
      "Moving: Velocity=6.65\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0436\n",
      "Step 108: Action: 0, Reward: 1.5261, Total Reward: 149.0986, Epsilon: 0.509\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.68\n",
      "Intersection detected: Velocity=6.68, Min Distance=0.00\n",
      "Moving: Velocity=6.68\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3380\n",
      "Step 109: Action: 2, Reward: 1.2274, Total Reward: 150.3260, Epsilon: 0.508\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.69\n",
      "Intersection detected: Velocity=6.69, Min Distance=0.00\n",
      "Moving: Velocity=6.69\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0279\n",
      "Step 110: Action: 3, Reward: 1.2276, Total Reward: 151.5536, Epsilon: 0.508\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.98\n",
      "Intersection detected: Velocity=6.98, Min Distance=0.00\n",
      "Moving: Velocity=6.98\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0292\n",
      "Step 111: Action: 0, Reward: 1.2391, Total Reward: 152.7926, Epsilon: 0.507\n",
      "Q-values: [2.8272662 2.8884714 2.7186148 2.740154  3.1332119]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.94, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.94, Min Distance=0.00\n",
      "Moving: Velocity=6.94\n",
      "Step 112: Brake action applied! Velocity: 6.94\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3635\n",
      "Step 112: Action: 4, Reward: 1.7776, Total Reward: 154.5703, Epsilon: 0.507\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.96\n",
      "Intersection detected: Velocity=6.96, Min Distance=0.00\n",
      "Moving: Velocity=6.96\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0249\n",
      "Step 113: Action: 2, Reward: 1.2385, Total Reward: 155.8087, Epsilon: 0.506\n",
      "Q-values: [2.8596165 2.8970206 2.7475111 2.762413  3.1481924]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.92, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.92, Min Distance=0.00\n",
      "Moving: Velocity=6.92\n",
      "Step 114: Brake action applied! Velocity: 6.92\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0339\n",
      "Step 114: Action: 4, Reward: 1.4768, Total Reward: 157.2855, Epsilon: 0.506\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.94\n",
      "Intersection detected: Velocity=6.94, Min Distance=0.00\n",
      "Moving: Velocity=6.94\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3713\n",
      "Step 115: Action: 2, Reward: 1.2377, Total Reward: 158.5232, Epsilon: 0.505\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.90, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.90, Min Distance=0.00\n",
      "Moving: Velocity=6.90\n",
      "Step 116: Brake action applied! Velocity: 6.90\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0289\n",
      "Step 116: Action: 4, Reward: 1.4760, Total Reward: 159.9992, Epsilon: 0.505\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=6.93\n",
      "Intersection detected: Velocity=6.93, Min Distance=0.00\n",
      "Moving: Velocity=6.93\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0366\n",
      "Step 117: Action: 2, Reward: 1.2371, Total Reward: 161.2363, Epsilon: 0.505\n",
      "Q-values: [2.8626282 2.839514  2.725669  2.7287974 3.0926867]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.88, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.88, Min Distance=0.00\n",
      "Moving: Velocity=6.88\n",
      "Step 118: Brake action applied! Velocity: 6.88\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0235\n",
      "Step 118: Action: 4, Reward: 1.4753, Total Reward: 162.7116, Epsilon: 0.504\n",
      "Q-values: [2.9027843 2.8615623 2.7544327 2.7505517 3.1212857]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.85, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.85, Min Distance=0.00\n",
      "Moving: Velocity=6.85\n",
      "Step 119: Brake action applied! Velocity: 6.85\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0502\n",
      "Step 119: Action: 4, Reward: 1.7739, Total Reward: 164.4854, Epsilon: 0.504\n",
      "Q-values: [2.9441972 2.8850133 2.783118  2.7728    3.152926 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.81, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.81, Min Distance=0.00\n",
      "Moving: Velocity=6.81\n",
      "Step 120: Brake action applied! Velocity: 6.81\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0538\n",
      "Step 120: Action: 4, Reward: 1.7724, Total Reward: 166.2578, Epsilon: 0.503\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=7.10\n",
      "Intersection detected: Velocity=7.10, Min Distance=0.00\n",
      "Moving: Velocity=7.10\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0435\n",
      "Step 121: Action: 0, Reward: 1.5439, Total Reward: 167.8017, Epsilon: 0.503\n",
      "Q-values: [2.951074  2.8739166 2.7776663 2.7560942 3.1522288]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=7.06, Min Distance=0.00\n",
      "Intersection detected: Velocity=7.06, Min Distance=0.00\n",
      "Moving: Velocity=7.06\n",
      "Step 122: Brake action applied! Velocity: 7.06\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0467\n",
      "Step 122: Action: 4, Reward: 1.7824, Total Reward: 169.5841, Epsilon: 0.502\n",
      "Q-values: [3.0076432 2.9221373 2.824151  2.792698  3.2092144]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=7.02, Min Distance=0.00\n",
      "Intersection detected: Velocity=7.02, Min Distance=0.00\n",
      "Moving: Velocity=7.02\n",
      "Step 123: Brake action applied! Velocity: 7.02\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2986\n",
      "Step 123: Action: 4, Reward: 1.7810, Total Reward: 171.3651, Epsilon: 0.502\n",
      "Q-values: [2.900821  2.8214352 2.7284515 2.6762388 3.1059885]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=6.99, Min Distance=0.00\n",
      "Intersection detected: Velocity=6.99, Min Distance=0.00\n",
      "Moving: Velocity=6.99\n",
      "Step 124: Brake action applied! Velocity: 6.99\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6183\n",
      "Step 124: Action: 4, Reward: 1.7795, Total Reward: 173.1446, Epsilon: 0.501\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=7.27\n",
      "Intersection detected: Velocity=7.27, Min Distance=0.00\n",
      "Off-road detected: Penalty applied\n",
      "Moving: Velocity=7.27\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0176\n",
      "Step 125: Action: 0, Reward: -1.3490, Total Reward: 171.7956, Epsilon: 0.501\n",
      "Episode 9 ended early: Terminated=True, Truncated=False\n",
      "Episode 9 completed. Total Reward: 171.7956\n",
      "Episode 10 started\n",
      "Initial observation shape: (259,)\n",
      "Q-values: [3.0168211 2.934276  2.8228922 2.7530458 3.2067118]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.03, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.03, Min Distance=0.00\n",
      "Step 1: Brake action applied! Velocity: 0.03\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6158\n",
      "Step 1: Action: 4, Reward: 1.5010, Total Reward: 1.5010, Epsilon: 0.500\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.04\n",
      "Intersection detected: Velocity=0.04, Min Distance=0.00\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0423\n",
      "Step 2: Action: 1, Reward: 1.2617, Total Reward: 2.7627, Epsilon: 0.500\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.02, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.02, Min Distance=0.00\n",
      "Step 3: Brake action applied! Velocity: 0.02\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0601\n",
      "Step 3: Action: 4, Reward: 1.5008, Total Reward: 4.2635, Epsilon: 0.499\n",
      "Q-values: [2.9786777 2.8860493 2.783726  2.6945016 3.1586373]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.02, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.02, Min Distance=0.00\n",
      "Step 4: Brake action applied! Velocity: 0.02\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0341\n",
      "Step 4: Action: 4, Reward: 1.5007, Total Reward: 5.7642, Epsilon: 0.499\n",
      "Q-values: [3.0042348 2.9095263 2.8077164 2.7101443 3.1888194]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.01, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.01, Min Distance=0.00\n",
      "Step 5: Brake action applied! Velocity: 0.01\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0326\n",
      "Step 5: Action: 4, Reward: 1.5005, Total Reward: 7.2647, Epsilon: 0.498\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.27\n",
      "Intersection detected: Velocity=0.27, Min Distance=0.00\n",
      "Moving: Velocity=0.27\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3269\n",
      "Step 6: Action: 2, Reward: 0.9707, Total Reward: 8.2354, Epsilon: 0.498\n",
      "Q-values: [3.0258765 2.9386847 2.8419049 2.7299047 3.2345843]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.23, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.23, Min Distance=0.00\n",
      "Moving: Velocity=0.23\n",
      "Step 7: Brake action applied! Velocity: 0.23\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0323\n",
      "Step 7: Action: 4, Reward: 1.2091, Total Reward: 9.4445, Epsilon: 0.497\n",
      "Q-values: [3.078247  2.9950624 2.895277  2.7765303 3.2995472]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.19, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.19, Min Distance=0.00\n",
      "Moving: Velocity=0.19\n",
      "Step 8: Brake action applied! Velocity: 0.19\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0328\n",
      "Step 8: Action: 4, Reward: 1.5076, Total Reward: 10.9521, Epsilon: 0.497\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.48\n",
      "Intersection detected: Velocity=0.48, Min Distance=0.00\n",
      "Moving: Velocity=0.48\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0352\n",
      "Step 9: Action: 0, Reward: 1.2791, Total Reward: 12.2312, Epsilon: 0.496\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.44, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.44, Min Distance=0.00\n",
      "Moving: Velocity=0.44\n",
      "Step 10: Brake action applied! Velocity: 0.44\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 1.0031\n",
      "Step 10: Action: 4, Reward: 1.5176, Total Reward: 13.7488, Epsilon: 0.496\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.40\n",
      "Intersection detected: Velocity=0.40, Min Distance=0.00\n",
      "Moving: Velocity=0.40\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3542\n",
      "Step 11: Action: 1, Reward: 1.2762, Total Reward: 15.0250, Epsilon: 0.495\n",
      "Q-values: [2.939773  2.9113266 2.797022  2.6782076 3.1790104]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.37, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.37, Min Distance=0.00\n",
      "Moving: Velocity=0.37\n",
      "Step 12: Brake action applied! Velocity: 0.37\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3865\n",
      "Step 12: Action: 4, Reward: 1.5147, Total Reward: 16.5397, Epsilon: 0.495\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.33\n",
      "Intersection detected: Velocity=0.33, Min Distance=0.00\n",
      "Moving: Velocity=0.33\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0588\n",
      "Step 13: Action: 1, Reward: 1.2733, Total Reward: 17.8130, Epsilon: 0.494\n",
      "Q-values: [2.8191257 2.8301184 2.7001112 2.5877635 3.051767 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.30, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.30, Min Distance=0.00\n",
      "Moving: Velocity=0.30\n",
      "Step 14: Brake action applied! Velocity: 0.30\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0756\n",
      "Step 14: Action: 4, Reward: 1.5118, Total Reward: 19.3248, Epsilon: 0.494\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.26, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.26, Min Distance=0.00\n",
      "Moving: Velocity=0.26\n",
      "Step 15: Brake action applied! Velocity: 0.26\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3858\n",
      "Step 15: Action: 4, Reward: 1.5104, Total Reward: 20.8352, Epsilon: 0.493\n",
      "Q-values: [2.834376  2.873687  2.7230883 2.6180274 3.0733123]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.22, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.22, Min Distance=0.00\n",
      "Moving: Velocity=0.22\n",
      "Step 16: Brake action applied! Velocity: 0.22\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0675\n",
      "Step 16: Action: 4, Reward: 1.5089, Total Reward: 22.3441, Epsilon: 0.493\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.49\n",
      "Intersection detected: Velocity=0.49, Min Distance=0.00\n",
      "Moving: Velocity=0.49\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0358\n",
      "Step 17: Action: 2, Reward: 0.9797, Total Reward: 23.3238, Epsilon: 0.492\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.45, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.45, Min Distance=0.00\n",
      "Moving: Velocity=0.45\n",
      "Step 18: Brake action applied! Velocity: 0.45\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3021\n",
      "Step 18: Action: 4, Reward: 1.2179, Total Reward: 24.5417, Epsilon: 0.492\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.71\n",
      "Intersection detected: Velocity=0.71, Min Distance=0.00\n",
      "Moving: Velocity=0.71\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3566\n",
      "Step 19: Action: 2, Reward: 0.9886, Total Reward: 25.5303, Epsilon: 0.491\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.67, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.67, Min Distance=0.00\n",
      "Moving: Velocity=0.67\n",
      "Step 20: Brake action applied! Velocity: 0.67\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3457\n",
      "Step 20: Action: 4, Reward: 1.2267, Total Reward: 26.7570, Epsilon: 0.491\n",
      "Q-values: [3.0282667 3.0881832 2.9132516 2.8132517 3.2944078]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.63, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.63, Min Distance=0.00\n",
      "Moving: Velocity=0.63\n",
      "Step 21: Brake action applied! Velocity: 0.63\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0261\n",
      "Step 21: Action: 4, Reward: 1.5252, Total Reward: 28.2822, Epsilon: 0.490\n",
      "Q-values: [3.0181289 3.072771  2.9016547 2.8034947 3.2862446]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.59, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.59, Min Distance=0.00\n",
      "Moving: Velocity=0.59\n",
      "Step 22: Brake action applied! Velocity: 0.59\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3094\n",
      "Step 22: Action: 4, Reward: 1.5238, Total Reward: 29.8060, Epsilon: 0.490\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.84\n",
      "Intersection detected: Velocity=0.84, Min Distance=0.00\n",
      "Moving: Velocity=0.84\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0299\n",
      "Step 23: Action: 2, Reward: 0.9938, Total Reward: 30.7997, Epsilon: 0.489\n",
      "Q-values: [2.8947566 2.9468322 2.7940729 2.7068522 3.174904 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.80, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.80, Min Distance=0.00\n",
      "Moving: Velocity=0.80\n",
      "Step 24: Brake action applied! Velocity: 0.80\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3351\n",
      "Step 24: Action: 4, Reward: 1.2319, Total Reward: 32.0316, Epsilon: 0.489\n",
      "Q-values: [2.8854387 2.922818  2.7838163 2.6993132 3.1698868]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.76, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.76, Min Distance=0.00\n",
      "Moving: Velocity=0.76\n",
      "Step 25: Brake action applied! Velocity: 0.76\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3227\n",
      "Step 25: Action: 4, Reward: 1.5304, Total Reward: 33.5620, Epsilon: 0.488\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.05\n",
      "Intersection detected: Velocity=1.05, Min Distance=0.00\n",
      "Moving: Velocity=1.05\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0424\n",
      "Step 26: Action: 0, Reward: 1.3019, Total Reward: 34.8639, Epsilon: 0.488\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.01, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.01, Min Distance=0.00\n",
      "Moving: Velocity=1.01\n",
      "Step 27: Brake action applied! Velocity: 1.01\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6672\n",
      "Step 27: Action: 4, Reward: 1.5404, Total Reward: 36.4043, Epsilon: 0.487\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.24\n",
      "Intersection detected: Velocity=1.24, Min Distance=0.00\n",
      "Moving: Velocity=1.24\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2955\n",
      "Step 28: Action: 2, Reward: 1.0096, Total Reward: 37.4139, Epsilon: 0.487\n",
      "Q-values: [2.820197  2.7605681 2.7120385 2.6354184 3.106553 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.19, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.19, Min Distance=0.00\n",
      "Moving: Velocity=1.19\n",
      "Step 29: Brake action applied! Velocity: 1.19\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0614\n",
      "Step 29: Action: 4, Reward: 1.2475, Total Reward: 38.6614, Epsilon: 0.486\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.15\n",
      "Intersection detected: Velocity=1.15, Min Distance=0.00\n",
      "Moving: Velocity=1.15\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3116\n",
      "Step 30: Action: 1, Reward: 1.3060, Total Reward: 39.9674, Epsilon: 0.486\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.44\n",
      "Intersection detected: Velocity=1.44, Min Distance=0.00\n",
      "Moving: Velocity=1.44\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3251\n",
      "Step 31: Action: 0, Reward: 1.3175, Total Reward: 41.2849, Epsilon: 0.485\n",
      "Q-values: [2.8996878 2.8019204 2.7772536 2.6976357 3.1942465]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.40, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.40, Min Distance=0.00\n",
      "Moving: Velocity=1.40\n",
      "Step 32: Brake action applied! Velocity: 1.40\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3656\n",
      "Step 32: Action: 4, Reward: 1.5561, Total Reward: 42.8410, Epsilon: 0.485\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.61\n",
      "Intersection detected: Velocity=1.61, Min Distance=0.00\n",
      "Moving: Velocity=1.61\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0270\n",
      "Step 33: Action: 2, Reward: 1.0244, Total Reward: 43.8654, Epsilon: 0.484\n",
      "Q-values: [2.923533  2.8409724 2.8002326 2.7284262 3.2195845]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.56, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.56, Min Distance=0.00\n",
      "Moving: Velocity=1.56\n",
      "Step 34: Brake action applied! Velocity: 1.56\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6104\n",
      "Step 34: Action: 4, Reward: 1.2622, Total Reward: 45.1277, Epsilon: 0.484\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.52, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.52, Min Distance=0.00\n",
      "Moving: Velocity=1.52\n",
      "Step 35: Brake action applied! Velocity: 1.52\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6359\n",
      "Step 35: Action: 4, Reward: 1.5607, Total Reward: 46.6884, Epsilon: 0.483\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.73\n",
      "Intersection detected: Velocity=1.73, Min Distance=0.00\n",
      "Moving: Velocity=1.73\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0397\n",
      "Step 36: Action: 2, Reward: 1.0290, Total Reward: 47.7174, Epsilon: 0.483\n",
      "Q-values: [2.8507385 2.8373597 2.7480087 2.6570284 3.151173 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.67, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.67, Min Distance=0.00\n",
      "Moving: Velocity=1.67\n",
      "Step 37: Brake action applied! Velocity: 1.67\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0361\n",
      "Step 37: Action: 4, Reward: 1.2668, Total Reward: 48.9842, Epsilon: 0.482\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.63\n",
      "Intersection detected: Velocity=1.63, Min Distance=0.00\n",
      "Moving: Velocity=1.63\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.9040\n",
      "Step 38: Action: 1, Reward: 1.3253, Total Reward: 50.3094, Epsilon: 0.482\n",
      "Q-values: [2.8797    2.8945842 2.769198  2.6635914 3.1610827]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.60, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.60, Min Distance=0.00\n",
      "Moving: Velocity=1.60\n",
      "Step 39: Brake action applied! Velocity: 1.60\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3389\n",
      "Step 39: Action: 4, Reward: 1.5638, Total Reward: 51.8733, Epsilon: 0.481\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.88\n",
      "Intersection detected: Velocity=1.88, Min Distance=0.00\n",
      "Moving: Velocity=1.88\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0382\n",
      "Step 40: Action: 0, Reward: 1.3353, Total Reward: 53.2086, Epsilon: 0.481\n",
      "Q-values: [2.8513258 2.8869035 2.737769  2.6179204 3.1037552]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.85, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.85, Min Distance=0.00\n",
      "Moving: Velocity=1.85\n",
      "Step 41: Brake action applied! Velocity: 1.85\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0511\n",
      "Step 41: Action: 4, Reward: 1.5738, Total Reward: 54.7824, Epsilon: 0.480\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.03\n",
      "Intersection detected: Velocity=2.03, Min Distance=0.00\n",
      "Moving: Velocity=2.03\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3720\n",
      "Step 42: Action: 2, Reward: 1.0412, Total Reward: 55.8236, Epsilon: 0.480\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.07\n",
      "Intersection detected: Velocity=2.07, Min Distance=0.00\n",
      "Moving: Velocity=2.07\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0450\n",
      "Step 43: Action: 3, Reward: 1.0430, Total Reward: 56.8666, Epsilon: 0.479\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.28\n",
      "Intersection detected: Velocity=2.28, Min Distance=0.00\n",
      "Moving: Velocity=2.28\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3225\n",
      "Step 44: Action: 3, Reward: 1.3512, Total Reward: 58.2178, Epsilon: 0.479\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.22, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.22, Min Distance=0.00\n",
      "Moving: Velocity=2.22\n",
      "Step 45: Brake action applied! Velocity: 2.22\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6258\n",
      "Step 45: Action: 4, Reward: 1.2886, Total Reward: 59.5064, Epsilon: 0.478\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.34\n",
      "Intersection detected: Velocity=2.34, Min Distance=0.00\n",
      "Moving: Velocity=2.34\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0321\n",
      "Step 46: Action: 2, Reward: 1.0534, Total Reward: 60.5598, Epsilon: 0.478\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.58\n",
      "Intersection detected: Velocity=2.58, Min Distance=0.00\n",
      "Moving: Velocity=2.58\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0625\n",
      "Step 47: Action: 2, Reward: 1.3632, Total Reward: 61.9231, Epsilon: 0.477\n",
      "Q-values: [2.871808  2.9943368 2.750929  2.6549857 3.105788 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.51, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.51, Min Distance=0.00\n",
      "Moving: Velocity=2.51\n",
      "Step 48: Brake action applied! Velocity: 2.51\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0368\n",
      "Step 48: Action: 4, Reward: 1.3003, Total Reward: 63.2233, Epsilon: 0.477\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.60\n",
      "Intersection detected: Velocity=2.60, Min Distance=0.00\n",
      "Moving: Velocity=2.60\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0430\n",
      "Step 49: Action: 3, Reward: 1.0639, Total Reward: 64.2872, Epsilon: 0.476\n",
      "Q-values: [2.8606458 3.007224  2.7634244 2.6702416 3.119361 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.54, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.54, Min Distance=0.00\n",
      "Moving: Velocity=2.54\n",
      "Step 50: Brake action applied! Velocity: 2.54\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0650\n",
      "Step 50: Action: 4, Reward: 1.3017, Total Reward: 65.5889, Epsilon: 0.476\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.50\n",
      "Intersection detected: Velocity=2.50, Min Distance=0.00\n",
      "Moving: Velocity=2.50\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3475\n",
      "Step 51: Action: 1, Reward: 1.3602, Total Reward: 66.9491, Epsilon: 0.475\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.79\n",
      "Intersection detected: Velocity=2.79, Min Distance=0.00\n",
      "Moving: Velocity=2.79\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0355\n",
      "Step 52: Action: 0, Reward: 1.3717, Total Reward: 68.3208, Epsilon: 0.475\n",
      "Q-values: [2.8720882 3.0471945 2.8089204 2.7151012 3.1818125]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.76, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.76, Min Distance=0.00\n",
      "Moving: Velocity=2.76\n",
      "Step 53: Brake action applied! Velocity: 2.76\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3780\n",
      "Step 53: Action: 4, Reward: 1.6102, Total Reward: 69.9310, Epsilon: 0.474\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.88\n",
      "Intersection detected: Velocity=2.88, Min Distance=0.00\n",
      "Moving: Velocity=2.88\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0497\n",
      "Step 54: Action: 2, Reward: 1.0752, Total Reward: 71.0062, Epsilon: 0.474\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.82\n",
      "Intersection detected: Velocity=2.82, Min Distance=0.00\n",
      "Moving: Velocity=2.82\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0444\n",
      "Step 55: Action: 1, Reward: 1.0728, Total Reward: 72.0790, Epsilon: 0.473\n",
      "Q-values: [2.8846188 3.0557017 2.8298287 2.7445025 3.2141304]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.78, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.78, Min Distance=0.00\n",
      "Moving: Velocity=2.78\n",
      "Step 56: Brake action applied! Velocity: 2.78\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3417\n",
      "Step 56: Action: 4, Reward: 1.6113, Total Reward: 73.6903, Epsilon: 0.473\n",
      "Q-values: [2.8953962 3.0481713 2.8369853 2.7574732 3.2280698]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.75, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.75, Min Distance=0.00\n",
      "Moving: Velocity=2.75\n",
      "Step 57: Brake action applied! Velocity: 2.75\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0244\n",
      "Step 57: Action: 4, Reward: 1.6099, Total Reward: 75.3002, Epsilon: 0.472\n",
      "Q-values: [2.9015348 3.035569  2.8403172 2.7698643 3.2377634]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.71, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.71, Min Distance=0.00\n",
      "Moving: Velocity=2.71\n",
      "Step 58: Brake action applied! Velocity: 2.71\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0225\n",
      "Step 58: Action: 4, Reward: 1.6084, Total Reward: 76.9086, Epsilon: 0.472\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.67\n",
      "Intersection detected: Velocity=2.67, Min Distance=0.00\n",
      "Moving: Velocity=2.67\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0523\n",
      "Step 59: Action: 1, Reward: 1.3670, Total Reward: 78.2755, Epsilon: 0.471\n",
      "Q-values: [2.9172966 3.0120633 2.8383029 2.7934604 3.255527 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.64, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.64, Min Distance=0.00\n",
      "Moving: Velocity=2.64\n",
      "Step 60: Brake action applied! Velocity: 2.64\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0227\n",
      "Step 60: Action: 4, Reward: 1.6055, Total Reward: 79.8810, Epsilon: 0.471\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.60, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.60, Min Distance=0.00\n",
      "Moving: Velocity=2.60\n",
      "Step 61: Brake action applied! Velocity: 2.60\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0212\n",
      "Step 61: Action: 4, Reward: 1.6040, Total Reward: 81.4851, Epsilon: 0.470\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.74\n",
      "Intersection detected: Velocity=2.74, Min Distance=0.00\n",
      "Moving: Velocity=2.74\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0322\n",
      "Step 62: Action: 2, Reward: 1.0694, Total Reward: 82.5545, Epsilon: 0.470\n",
      "Q-values: [2.9028358 2.9386024 2.797622  2.7847989 3.2397416]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.68, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.68, Min Distance=0.00\n",
      "Moving: Velocity=2.68\n",
      "Step 63: Brake action applied! Velocity: 2.68\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 1.0136\n",
      "Step 63: Action: 4, Reward: 1.3070, Total Reward: 83.8615, Epsilon: 0.469\n",
      "Q-values: [2.8930736 2.9128067 2.775243  2.7719324 3.2086582]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.64, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.64, Min Distance=0.00\n",
      "Moving: Velocity=2.64\n",
      "Step 64: Brake action applied! Velocity: 2.64\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6514\n",
      "Step 64: Action: 4, Reward: 1.6055, Total Reward: 85.4670, Epsilon: 0.469\n",
      "Q-values: [2.8598373 2.8613088 2.7322228 2.7375271 3.1525493]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.60, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.60, Min Distance=0.00\n",
      "Moving: Velocity=2.60\n",
      "Step 65: Brake action applied! Velocity: 2.60\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3264\n",
      "Step 65: Action: 4, Reward: 1.6040, Total Reward: 87.0710, Epsilon: 0.468\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.89\n",
      "Intersection detected: Velocity=2.89, Min Distance=0.00\n",
      "Moving: Velocity=2.89\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0506\n",
      "Step 66: Action: 0, Reward: 1.3755, Total Reward: 88.4466, Epsilon: 0.468\n",
      "Q-values: [2.7700925 2.7588449 2.6428044 2.666192  3.0449157]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.85, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.85, Min Distance=0.00\n",
      "Moving: Velocity=2.85\n",
      "Step 67: Brake action applied! Velocity: 2.85\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0539\n",
      "Step 67: Action: 4, Reward: 1.6141, Total Reward: 90.0606, Epsilon: 0.467\n",
      "Q-values: [2.8359778 2.8115792 2.6972716 2.7246203 3.1058884]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.82, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.82, Min Distance=0.00\n",
      "Moving: Velocity=2.82\n",
      "Step 68: Brake action applied! Velocity: 2.82\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0602\n",
      "Step 68: Action: 4, Reward: 1.6126, Total Reward: 91.6732, Epsilon: 0.467\n",
      "Q-values: [2.892159  2.855408  2.7437162 2.773752  3.1607003]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.78, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.78, Min Distance=0.00\n",
      "Moving: Velocity=2.78\n",
      "Step 69: Brake action applied! Velocity: 2.78\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0505\n",
      "Step 69: Action: 4, Reward: 1.6112, Total Reward: 93.2844, Epsilon: 0.466\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.07\n",
      "Intersection detected: Velocity=3.07, Min Distance=0.00\n",
      "Moving: Velocity=3.07\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0322\n",
      "Step 70: Action: 0, Reward: 1.3826, Total Reward: 94.6670, Epsilon: 0.466\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.35\n",
      "Intersection detected: Velocity=3.35, Min Distance=0.00\n",
      "Moving: Velocity=3.35\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3192\n",
      "Step 71: Action: 0, Reward: 1.3941, Total Reward: 96.0611, Epsilon: 0.465\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.44\n",
      "Intersection detected: Velocity=3.44, Min Distance=0.00\n",
      "Moving: Velocity=3.44\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0240\n",
      "Step 72: Action: 3, Reward: 1.0977, Total Reward: 97.1589, Epsilon: 0.465\n",
      "Q-values: [3.0558667 2.9703999 2.8752854 2.8943741 3.3276987]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.39, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.39, Min Distance=0.00\n",
      "Moving: Velocity=3.39\n",
      "Step 73: Brake action applied! Velocity: 3.39\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3504\n",
      "Step 73: Action: 4, Reward: 1.3356, Total Reward: 98.4945, Epsilon: 0.464\n",
      "Q-values: [3.0683064 2.9816744 2.8890123 2.902629  3.3453004]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.35, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.35, Min Distance=0.00\n",
      "Moving: Velocity=3.35\n",
      "Step 74: Brake action applied! Velocity: 3.35\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0283\n",
      "Step 74: Action: 4, Reward: 1.6341, Total Reward: 100.1286, Epsilon: 0.464\n",
      "Q-values: [3.0584497 2.971765  2.8823252 2.8914642 3.338079 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.32, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.32, Min Distance=0.00\n",
      "Moving: Velocity=3.32\n",
      "Step 75: Brake action applied! Velocity: 3.32\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0437\n",
      "Step 75: Action: 4, Reward: 1.6327, Total Reward: 101.7613, Epsilon: 0.463\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.60\n",
      "Intersection detected: Velocity=3.60, Min Distance=0.00\n",
      "Moving: Velocity=3.60\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3524\n",
      "Step 76: Action: 0, Reward: 1.4042, Total Reward: 103.1655, Epsilon: 0.463\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.57, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.57, Min Distance=0.00\n",
      "Moving: Velocity=3.57\n",
      "Step 77: Brake action applied! Velocity: 3.57\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3445\n",
      "Step 77: Action: 4, Reward: 1.6427, Total Reward: 104.8082, Epsilon: 0.462\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.53\n",
      "Intersection detected: Velocity=3.53, Min Distance=0.00\n",
      "Moving: Velocity=3.53\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6957\n",
      "Step 78: Action: 1, Reward: 1.4013, Total Reward: 106.2095, Epsilon: 0.462\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.61\n",
      "Intersection detected: Velocity=3.61, Min Distance=0.00\n",
      "Moving: Velocity=3.61\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3293\n",
      "Step 79: Action: 3, Reward: 1.1046, Total Reward: 107.3140, Epsilon: 0.461\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.62\n",
      "Intersection detected: Velocity=3.62, Min Distance=0.00\n",
      "Moving: Velocity=3.62\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3599\n",
      "Step 80: Action: 2, Reward: 1.1047, Total Reward: 108.4187, Epsilon: 0.461\n",
      "Q-values: [2.6610198 2.6704476 2.5410361 2.5339801 2.91107  ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.58, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.58, Min Distance=0.00\n",
      "Moving: Velocity=3.58\n",
      "Step 81: Brake action applied! Velocity: 3.58\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.1016\n",
      "Step 81: Action: 4, Reward: 1.3432, Total Reward: 109.7619, Epsilon: 0.460\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.54, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.54, Min Distance=0.00\n",
      "Moving: Velocity=3.54\n",
      "Step 82: Brake action applied! Velocity: 3.54\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0801\n",
      "Step 82: Action: 4, Reward: 1.6417, Total Reward: 111.4036, Epsilon: 0.460\n",
      "Q-values: [2.8294814 2.8548472 2.6941085 2.6777158 3.075732 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.51, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.51, Min Distance=0.00\n",
      "Moving: Velocity=3.51\n",
      "Step 83: Brake action applied! Velocity: 3.51\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3319\n",
      "Step 83: Action: 4, Reward: 1.6403, Total Reward: 113.0439, Epsilon: 0.459\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.47\n",
      "Intersection detected: Velocity=3.47, Min Distance=0.00\n",
      "Moving: Velocity=3.47\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6006\n",
      "Step 84: Action: 1, Reward: 1.3988, Total Reward: 114.4428, Epsilon: 0.459\n",
      "Q-values: [2.9620433 3.008667  2.8325906 2.7964776 3.2353203]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.43, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.43, Min Distance=0.00\n",
      "Moving: Velocity=3.43\n",
      "Step 85: Brake action applied! Velocity: 3.43\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6346\n",
      "Step 85: Action: 4, Reward: 1.6374, Total Reward: 116.0802, Epsilon: 0.458\n",
      "Q-values: [2.9912674 3.044023  2.8646843 2.8100748 3.269518 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.40, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.40, Min Distance=0.00\n",
      "Moving: Velocity=3.40\n",
      "Step 86: Brake action applied! Velocity: 3.40\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0221\n",
      "Step 86: Action: 4, Reward: 1.6359, Total Reward: 117.7161, Epsilon: 0.458\n",
      "Q-values: [3.0125618 3.0717602 2.8892295 2.8201327 3.2961702]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.36, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.36, Min Distance=0.00\n",
      "Moving: Velocity=3.36\n",
      "Step 87: Brake action applied! Velocity: 3.36\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3182\n",
      "Step 87: Action: 4, Reward: 1.6345, Total Reward: 119.3506, Epsilon: 0.457\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.45\n",
      "Intersection detected: Velocity=3.45, Min Distance=0.00\n",
      "Moving: Velocity=3.45\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3454\n",
      "Step 88: Action: 2, Reward: 1.0980, Total Reward: 120.4486, Epsilon: 0.457\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.40\n",
      "Intersection detected: Velocity=3.40, Min Distance=0.00\n",
      "Moving: Velocity=3.40\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0228\n",
      "Step 89: Action: 1, Reward: 1.0958, Total Reward: 121.5444, Epsilon: 0.456\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.36, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.36, Min Distance=0.00\n",
      "Moving: Velocity=3.36\n",
      "Step 90: Brake action applied! Velocity: 3.36\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0210\n",
      "Step 90: Action: 4, Reward: 1.6343, Total Reward: 123.1788, Epsilon: 0.456\n",
      "Q-values: [2.8632755 2.9832327 2.808804  2.707301  3.2071247]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.32, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.32, Min Distance=0.00\n",
      "Moving: Velocity=3.32\n",
      "Step 91: Brake action applied! Velocity: 3.32\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0465\n",
      "Step 91: Action: 4, Reward: 1.6329, Total Reward: 124.8116, Epsilon: 0.456\n",
      "Q-values: [2.834657  2.9620674 2.7894673 2.68404   3.1870916]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.29, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.29, Min Distance=0.00\n",
      "Moving: Velocity=3.29\n",
      "Step 92: Brake action applied! Velocity: 3.29\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0524\n",
      "Step 92: Action: 4, Reward: 1.6314, Total Reward: 126.4430, Epsilon: 0.455\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.25\n",
      "Intersection detected: Velocity=3.25, Min Distance=0.00\n",
      "Moving: Velocity=3.25\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0205\n",
      "Step 93: Action: 1, Reward: 1.3900, Total Reward: 127.8330, Epsilon: 0.455\n",
      "Q-values: [2.7960026 2.9252527 2.7537494 2.6439557 3.1560838]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.21, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.21, Min Distance=0.00\n",
      "Moving: Velocity=3.21\n",
      "Step 94: Brake action applied! Velocity: 3.21\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.8068\n",
      "Step 94: Action: 4, Reward: 1.6285, Total Reward: 129.4615, Epsilon: 0.454\n",
      "Q-values: [2.7686396 2.9026024 2.7292979 2.61388   3.1308017]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.18, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.18, Min Distance=0.00\n",
      "Moving: Velocity=3.18\n",
      "Step 95: Brake action applied! Velocity: 3.18\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0506\n",
      "Step 95: Action: 4, Reward: 1.6271, Total Reward: 131.0886, Epsilon: 0.454\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.27\n",
      "Intersection detected: Velocity=3.27, Min Distance=0.00\n",
      "Moving: Velocity=3.27\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0606\n",
      "Step 96: Action: 3, Reward: 1.0910, Total Reward: 132.1796, Epsilon: 0.453\n",
      "Q-values: [2.7600496 2.8866372 2.7159872 2.5935621 3.1243236]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.22, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.22, Min Distance=0.00\n",
      "Moving: Velocity=3.22\n",
      "Step 97: Brake action applied! Velocity: 3.22\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6514\n",
      "Step 97: Action: 4, Reward: 1.3287, Total Reward: 133.5083, Epsilon: 0.453\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.18\n",
      "Intersection detected: Velocity=3.18, Min Distance=0.00\n",
      "Moving: Velocity=3.18\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0396\n",
      "Step 98: Action: 1, Reward: 1.3872, Total Reward: 134.8955, Epsilon: 0.452\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.14\n",
      "Intersection detected: Velocity=3.14, Min Distance=0.00\n",
      "Moving: Velocity=3.14\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3524\n",
      "Step 99: Action: 1, Reward: 1.3858, Total Reward: 136.2813, Epsilon: 0.452\n",
      "Q-values: [2.8764327 2.9865782 2.8036802 2.6754723 3.2314105]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.11, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.11, Min Distance=0.00\n",
      "Moving: Velocity=3.11\n",
      "Step 100: Brake action applied! Velocity: 3.11\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.6298\n",
      "Step 100: Action: 4, Reward: 1.6243, Total Reward: 137.9056, Epsilon: 0.451\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.07, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.07, Min Distance=0.00\n",
      "Moving: Velocity=3.07\n",
      "Step 101: Brake action applied! Velocity: 3.07\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0447\n",
      "Step 101: Action: 4, Reward: 1.6228, Total Reward: 139.5284, Epsilon: 0.451\n",
      "Q-values: [2.8712375 2.965716  2.7644675 2.6599312 3.180032 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.03, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.03, Min Distance=0.00\n",
      "Moving: Velocity=3.03\n",
      "Step 102: Brake action applied! Velocity: 3.03\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0447\n",
      "Step 102: Action: 4, Reward: 1.6214, Total Reward: 141.1498, Epsilon: 0.450\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.32\n",
      "Intersection detected: Velocity=3.32, Min Distance=0.00\n",
      "Moving: Velocity=3.32\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3548\n",
      "Step 103: Action: 0, Reward: 1.3929, Total Reward: 142.5427, Epsilon: 0.450\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.41\n",
      "Intersection detected: Velocity=3.41, Min Distance=0.00\n",
      "Moving: Velocity=3.41\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.5759\n",
      "Step 104: Action: 2, Reward: 1.0965, Total Reward: 143.6392, Epsilon: 0.449\n",
      "Q-values: [2.8280144 2.9110992 2.6926575 2.632912  3.082637 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.36, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.36, Min Distance=0.00\n",
      "Moving: Velocity=3.36\n",
      "Step 105: Brake action applied! Velocity: 3.36\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0454\n",
      "Step 105: Action: 4, Reward: 1.3344, Total Reward: 144.9735, Epsilon: 0.449\n",
      "Q-values: [2.8667123 2.9453716 2.7185311 2.6730394 3.108017 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.32, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.32, Min Distance=0.00\n",
      "Moving: Velocity=3.32\n",
      "Step 106: Brake action applied! Velocity: 3.32\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0769\n",
      "Step 106: Action: 4, Reward: 1.6329, Total Reward: 146.6064, Epsilon: 0.448\n",
      "Q-values: [2.9001951 2.9756272 2.7420707 2.7104914 3.135361 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.29, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.29, Min Distance=0.00\n",
      "Moving: Velocity=3.29\n",
      "Step 107: Brake action applied! Velocity: 3.29\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2941\n",
      "Step 107: Action: 4, Reward: 1.6314, Total Reward: 148.2379, Epsilon: 0.448\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.57\n",
      "Intersection detected: Velocity=3.57, Min Distance=0.00\n",
      "Moving: Velocity=3.57\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0677\n",
      "Step 108: Action: 0, Reward: 1.4029, Total Reward: 149.6408, Epsilon: 0.447\n",
      "Q-values: [2.8856227 2.9628444 2.7353535 2.7258458 3.1311216]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.54, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.54, Min Distance=0.00\n",
      "Moving: Velocity=3.54\n",
      "Step 109: Brake action applied! Velocity: 3.54\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3344\n",
      "Step 109: Action: 4, Reward: 1.6415, Total Reward: 151.2823, Epsilon: 0.447\n",
      "Q-values: [2.933992  3.0097277 2.7796106 2.7772357 3.1820426]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.50, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.50, Min Distance=0.00\n",
      "Moving: Velocity=3.50\n",
      "Step 110: Brake action applied! Velocity: 3.50\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0354\n",
      "Step 110: Action: 4, Reward: 1.6400, Total Reward: 152.9223, Epsilon: 0.446\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.58\n",
      "Intersection detected: Velocity=3.58, Min Distance=0.00\n",
      "Moving: Velocity=3.58\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0169\n",
      "Step 111: Action: 3, Reward: 1.1034, Total Reward: 154.0256, Epsilon: 0.446\n",
      "Q-values: [2.906583  2.9756343 2.7569776 2.7711957 3.1652312]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.53, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.53, Min Distance=0.00\n",
      "Moving: Velocity=3.53\n",
      "Step 112: Brake action applied! Velocity: 3.53\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0320\n",
      "Step 112: Action: 4, Reward: 1.3411, Total Reward: 155.3668, Epsilon: 0.445\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.64\n",
      "Intersection detected: Velocity=3.64, Min Distance=0.00\n",
      "Moving: Velocity=3.64\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0507\n",
      "Step 113: Action: 3, Reward: 1.1057, Total Reward: 156.4725, Epsilon: 0.445\n",
      "Q-values: [2.9192967 2.9762385 2.7692714 2.791714  3.189653 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.58, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.58, Min Distance=0.00\n",
      "Moving: Velocity=3.58\n",
      "Step 114: Brake action applied! Velocity: 3.58\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0444\n",
      "Step 114: Action: 4, Reward: 1.3432, Total Reward: 157.8157, Epsilon: 0.444\n",
      "Q-values: [2.9394407 2.9912024 2.780857  2.8088644 3.2101557]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.54, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.54, Min Distance=0.00\n",
      "Moving: Velocity=3.54\n",
      "Step 115: Brake action applied! Velocity: 3.54\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0371\n",
      "Step 115: Action: 4, Reward: 1.6417, Total Reward: 159.4574, Epsilon: 0.444\n",
      "Q-values: [2.947974  2.9943793 2.7844107 2.8145702 3.2212892]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.51, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.51, Min Distance=0.00\n",
      "Moving: Velocity=3.51\n",
      "Step 116: Brake action applied! Velocity: 3.51\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0373\n",
      "Step 116: Action: 4, Reward: 1.6403, Total Reward: 161.0977, Epsilon: 0.443\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.47\n",
      "Intersection detected: Velocity=3.47, Min Distance=0.00\n",
      "Moving: Velocity=3.47\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0366\n",
      "Step 117: Action: 1, Reward: 1.3988, Total Reward: 162.4965, Epsilon: 0.443\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.76\n",
      "Intersection detected: Velocity=3.76, Min Distance=0.00\n",
      "Moving: Velocity=3.76\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0217\n",
      "Step 118: Action: 0, Reward: 1.4103, Total Reward: 163.9068, Epsilon: 0.442\n",
      "Q-values: [2.8743653 2.9002259 2.6990986 2.7390864 3.1428568]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.72, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.72, Min Distance=0.00\n",
      "Moving: Velocity=3.72\n",
      "Step 119: Brake action applied! Velocity: 3.72\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.5652\n",
      "Step 119: Action: 4, Reward: 1.6488, Total Reward: 165.5556, Epsilon: 0.442\n",
      "Q-values: [2.8919237 2.9186509 2.7123954 2.7454011 3.1640198]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.68, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.68, Min Distance=0.00\n",
      "Moving: Velocity=3.68\n",
      "Step 120: Brake action applied! Velocity: 3.68\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0358\n",
      "Step 120: Action: 4, Reward: 1.6474, Total Reward: 167.2030, Epsilon: 0.441\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.65, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.65, Min Distance=0.00\n",
      "Moving: Velocity=3.65\n",
      "Step 121: Brake action applied! Velocity: 3.65\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0426\n",
      "Step 121: Action: 4, Reward: 1.6459, Total Reward: 168.8489, Epsilon: 0.441\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.61\n",
      "Intersection detected: Velocity=3.61, Min Distance=0.00\n",
      "Moving: Velocity=3.61\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3414\n",
      "Step 122: Action: 1, Reward: 1.4045, Total Reward: 170.2533, Epsilon: 0.440\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.90\n",
      "Intersection detected: Velocity=3.90, Min Distance=0.00\n",
      "Moving: Velocity=3.90\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.4013\n",
      "Step 123: Action: 0, Reward: 1.4159, Total Reward: 171.6693, Epsilon: 0.440\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.97\n",
      "Intersection detected: Velocity=3.97, Min Distance=0.00\n",
      "Moving: Velocity=3.97\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3429\n",
      "Step 124: Action: 3, Reward: 1.1188, Total Reward: 172.7881, Epsilon: 0.439\n",
      "Q-values: [2.837377  2.8552842 2.6580107 2.6510746 3.1074657]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.92, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.92, Min Distance=0.00\n",
      "Moving: Velocity=3.92\n",
      "Step 125: Brake action applied! Velocity: 3.92\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3631\n",
      "Step 125: Action: 4, Reward: 1.3568, Total Reward: 174.1449, Epsilon: 0.439\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.88, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.88, Min Distance=0.00\n",
      "Moving: Velocity=3.88\n",
      "Step 126: Brake action applied! Velocity: 3.88\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3202\n",
      "Step 126: Action: 4, Reward: 1.6554, Total Reward: 175.8003, Epsilon: 0.438\n",
      "Q-values: [2.8676605 2.8683145 2.6782389 2.658268  3.1168103]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=3.85, Min Distance=0.00\n",
      "Intersection detected: Velocity=3.85, Min Distance=0.00\n",
      "Moving: Velocity=3.85\n",
      "Step 127: Brake action applied! Velocity: 3.85\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.3625\n",
      "Step 127: Action: 4, Reward: 1.6539, Total Reward: 177.4542, Epsilon: 0.438\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=3.92\n",
      "Intersection detected: Velocity=3.92, Min Distance=0.00\n",
      "Moving: Velocity=3.92\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0360\n",
      "Step 128: Action: 2, Reward: 1.1167, Total Reward: 178.5709, Epsilon: 0.437\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.10\n",
      "Intersection detected: Velocity=4.10, Min Distance=0.00\n",
      "Moving: Velocity=4.10\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.2994\n",
      "Step 129: Action: 2, Reward: 1.4240, Total Reward: 179.9949, Epsilon: 0.437\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=4.35\n",
      "Intersection detected: Velocity=4.35, Min Distance=0.00\n",
      "Off-road detected: Penalty applied\n",
      "Moving: Velocity=4.35\n",
      "Training - States shape: torch.Size([64, 259])\n",
      "Training - Loss: 0.0509\n",
      "Step 130: Action: 2, Reward: -1.4660, Total Reward: 178.5289, Epsilon: 0.436\n",
      "Episode 10 ended early: Terminated=True, Truncated=False\n",
      "Episode 10 completed. Total Reward: 178.5289\n",
      "Model saved to dueling_dqn_model.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots saved as 'training_plots.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m[INFO] Environment: MetaDriveEnv\u001b[0m\n",
      "\u001b[38;20m[INFO] MetaDrive version: 0.4.3\u001b[0m\n",
      "\u001b[38;20m[INFO] Sensors: [lidar: Lidar(), side_detector: SideDetector(), lane_line_detector: LaneLineDetector()]\u001b[0m\n",
      "\u001b[38;20m[INFO] Render Mode: none\u001b[0m\n",
      "\u001b[38;20m[INFO] Horizon (Max steps per agent): 1000\u001b[0m\n",
      "\u001b[38;20m[INFO] Assets version: 0.4.3\u001b[0m\n",
      "\u001b[38;20m[INFO] Known Pipes: CocoaGraphicsPipe\u001b[0m\n",
      "\u001b[38;20m[INFO] Start Scenario Index: 42, Num Scenarios : 1\u001b[0m\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating GIF for greedy episode...\n",
      "Q-values: [2.9982433 2.9611866 2.7859018 2.7393196 3.2151284]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.03, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.03, Min Distance=0.00\n",
      "Warning: Step 1 - Render returned None, frame skipped.\n",
      "Greedy Step 1: Action: 4, Reward: 1.1010, Total Reward: 1.1010\n",
      "Q-values: [2.9981308 2.9610796 2.7858071 2.7392156 3.2150187]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.04, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.04, Min Distance=0.00\n",
      "Warning: Step 2 - Render returned None, frame skipped.\n",
      "Greedy Step 2: Action: 4, Reward: 1.5017, Total Reward: 2.6027\n",
      "Q-values: [2.9980605 2.9610126 2.785748  2.7391512 3.2149503]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.02, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.02, Min Distance=0.00\n",
      "Warning: Step 3 - Render returned None, frame skipped.\n",
      "Greedy Step 3: Action: 4, Reward: 1.5008, Total Reward: 4.1035\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.02\n",
      "Intersection detected: Velocity=0.02, Min Distance=0.00\n",
      "Warning: Step 4 - Render returned None, frame skipped.\n",
      "Greedy Step 4: Action: 1, Reward: 1.2607, Total Reward: 5.3642\n",
      "Q-values: [2.9981627 2.9611099 2.7858338 2.739246  3.2150497]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.01, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.01, Min Distance=0.00\n",
      "Warning: Step 5 - Render returned None, frame skipped.\n",
      "Greedy Step 5: Action: 4, Reward: 1.5005, Total Reward: 6.8647\n",
      "Q-values: [2.99818   2.9611263 2.7858484 2.7392616 3.2150664]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.00, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.00, Min Distance=0.00\n",
      "Warning: Step 6 - Render returned None, frame skipped.\n",
      "Greedy Step 6: Action: 4, Reward: 1.5002, Total Reward: 8.3649\n",
      "Q-values: [2.9982185 2.9611633 2.7858808 2.7392972 3.215104 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.00, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.00, Min Distance=0.00\n",
      "Warning: Step 7 - Render returned None, frame skipped.\n",
      "Greedy Step 7: Action: 4, Reward: 1.5001, Total Reward: 9.8650\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.29\n",
      "Intersection detected: Velocity=0.29, Min Distance=0.00\n",
      "Moving: Velocity=0.29\n",
      "Warning: Step 8 - Render returned None, frame skipped.\n",
      "Greedy Step 8: Action: 0, Reward: 1.2716, Total Reward: 11.1366\n",
      "Q-values: [2.9506824 2.9155    2.746164  2.7002945 3.1688297]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.25, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.25, Min Distance=0.00\n",
      "Moving: Velocity=0.25\n",
      "Warning: Step 9 - Render returned None, frame skipped.\n",
      "Greedy Step 9: Action: 4, Reward: 1.5102, Total Reward: 12.6468\n",
      "Q-values: [2.997115  2.9601128 2.784953  2.738283  3.2140293]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.22, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.22, Min Distance=0.00\n",
      "Moving: Velocity=0.22\n",
      "Warning: Step 10 - Render returned None, frame skipped.\n",
      "Greedy Step 10: Action: 4, Reward: 1.5087, Total Reward: 14.1555\n",
      "Q-values: [2.9972544 2.9602456 2.7850702 2.7384133 3.214165 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.18, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.18, Min Distance=0.00\n",
      "Moving: Velocity=0.18\n",
      "Warning: Step 11 - Render returned None, frame skipped.\n",
      "Greedy Step 11: Action: 4, Reward: 1.5073, Total Reward: 15.6628\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.45\n",
      "Intersection detected: Velocity=0.45, Min Distance=0.00\n",
      "Moving: Velocity=0.45\n",
      "Warning: Step 12 - Render returned None, frame skipped.\n",
      "Greedy Step 12: Action: 2, Reward: 0.9781, Total Reward: 16.6409\n",
      "Q-values: [2.9477923 2.913537  2.7440543 2.6980238 3.1661232]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.41, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.41, Min Distance=0.00\n",
      "Moving: Velocity=0.41\n",
      "Warning: Step 13 - Render returned None, frame skipped.\n",
      "Greedy Step 13: Action: 4, Reward: 1.2164, Total Reward: 17.8572\n",
      "Q-values: [2.991621  2.954896  2.780184  2.7335627 3.2084942]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.37, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.37, Min Distance=0.00\n",
      "Moving: Velocity=0.37\n",
      "Warning: Step 14 - Render returned None, frame skipped.\n",
      "Greedy Step 14: Action: 4, Reward: 1.5149, Total Reward: 19.3722\n",
      "Q-values: [2.995047  2.9581337 2.783168  2.7364914 3.211956 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.34, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.34, Min Distance=0.00\n",
      "Moving: Velocity=0.34\n",
      "Warning: Step 15 - Render returned None, frame skipped.\n",
      "Greedy Step 15: Action: 4, Reward: 1.5135, Total Reward: 20.8856\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.30\n",
      "Intersection detected: Velocity=0.30, Min Distance=0.00\n",
      "Moving: Velocity=0.30\n",
      "Warning: Step 16 - Render returned None, frame skipped.\n",
      "Greedy Step 16: Action: 1, Reward: 1.2720, Total Reward: 22.1576\n",
      "Q-values: [2.9965982 2.9596014 2.7845118 2.737836  3.213515 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.26, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.26, Min Distance=0.00\n",
      "Moving: Velocity=0.26\n",
      "Warning: Step 17 - Render returned None, frame skipped.\n",
      "Greedy Step 17: Action: 4, Reward: 1.5105, Total Reward: 23.6682\n",
      "Q-values: [2.9968095 2.959802  2.7846913 2.7380276 3.2137234]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.23, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.23, Min Distance=0.00\n",
      "Moving: Velocity=0.23\n",
      "Warning: Step 18 - Render returned None, frame skipped.\n",
      "Greedy Step 18: Action: 4, Reward: 1.5091, Total Reward: 25.1773\n",
      "Q-values: [2.9969676 2.9599524 2.7848248 2.738174  3.2138777]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.19, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.19, Min Distance=0.00\n",
      "Moving: Velocity=0.19\n",
      "Warning: Step 19 - Render returned None, frame skipped.\n",
      "Greedy Step 19: Action: 4, Reward: 1.5076, Total Reward: 26.6849\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.46\n",
      "Intersection detected: Velocity=0.46, Min Distance=0.00\n",
      "Moving: Velocity=0.46\n",
      "Warning: Step 20 - Render returned None, frame skipped.\n",
      "Greedy Step 20: Action: 3, Reward: 0.9785, Total Reward: 27.6634\n",
      "Q-values: [2.948441  2.912579  2.7438502 2.6981096 3.1664028]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.42, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.42, Min Distance=0.00\n",
      "Moving: Velocity=0.42\n",
      "Warning: Step 21 - Render returned None, frame skipped.\n",
      "Greedy Step 21: Action: 4, Reward: 1.2167, Total Reward: 28.8801\n",
      "Q-values: [2.9913402 2.954641  2.7799437 2.733328  3.2082174]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.38, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.38, Min Distance=0.00\n",
      "Moving: Velocity=0.38\n",
      "Warning: Step 22 - Render returned None, frame skipped.\n",
      "Greedy Step 22: Action: 4, Reward: 1.5153, Total Reward: 30.3954\n",
      "Q-values: [2.9948463 2.957962  2.7829974 2.7363253 3.2117617]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.35, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.35, Min Distance=0.00\n",
      "Moving: Velocity=0.35\n",
      "Warning: Step 23 - Render returned None, frame skipped.\n",
      "Greedy Step 23: Action: 4, Reward: 1.5138, Total Reward: 31.9092\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.61\n",
      "Intersection detected: Velocity=0.61, Min Distance=0.00\n",
      "Moving: Velocity=0.61\n",
      "Warning: Step 24 - Render returned None, frame skipped.\n",
      "Greedy Step 24: Action: 3, Reward: 0.9843, Total Reward: 32.8935\n",
      "Q-values: [2.947017  2.9112508 2.7426302 2.6968575 3.164992 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.56, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.56, Min Distance=0.00\n",
      "Moving: Velocity=0.56\n",
      "Warning: Step 25 - Render returned None, frame skipped.\n",
      "Greedy Step 25: Action: 4, Reward: 1.2225, Total Reward: 34.1161\n",
      "Q-values: [2.9891922 2.9526322 2.7780924 2.7314608 3.2060745]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.53, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.53, Min Distance=0.00\n",
      "Moving: Velocity=0.53\n",
      "Warning: Step 26 - Render returned None, frame skipped.\n",
      "Greedy Step 26: Action: 4, Reward: 1.5211, Total Reward: 35.6371\n",
      "Q-values: [2.9937332 2.956933  2.7820487 2.735339  3.2106664]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.49, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.49, Min Distance=0.00\n",
      "Moving: Velocity=0.49\n",
      "Warning: Step 27 - Render returned None, frame skipped.\n",
      "Greedy Step 27: Action: 4, Reward: 1.5196, Total Reward: 37.1567\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.75\n",
      "Intersection detected: Velocity=0.75, Min Distance=0.00\n",
      "Moving: Velocity=0.75\n",
      "Warning: Step 28 - Render returned None, frame skipped.\n",
      "Greedy Step 28: Action: 3, Reward: 0.9898, Total Reward: 38.1466\n",
      "Q-values: [2.945725  2.9100552 2.741525  2.6957223 3.1637156]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.70, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.70, Min Distance=0.00\n",
      "Moving: Velocity=0.70\n",
      "Warning: Step 29 - Render returned None, frame skipped.\n",
      "Greedy Step 29: Action: 4, Reward: 1.2280, Total Reward: 39.3746\n",
      "Q-values: [2.9871776 2.9507573 2.776357  2.7297122 3.2040675]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.66, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.66, Min Distance=0.00\n",
      "Moving: Velocity=0.66\n",
      "Warning: Step 30 - Render returned None, frame skipped.\n",
      "Greedy Step 30: Action: 4, Reward: 1.5265, Total Reward: 40.9011\n",
      "Q-values: [2.9926739 2.955963  2.7811468 2.7344043 3.209627 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.63, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.63, Min Distance=0.00\n",
      "Moving: Velocity=0.63\n",
      "Warning: Step 31 - Render returned None, frame skipped.\n",
      "Greedy Step 31: Action: 4, Reward: 1.5250, Total Reward: 42.4261\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.91\n",
      "Intersection detected: Velocity=0.91, Min Distance=0.00\n",
      "Moving: Velocity=0.91\n",
      "Warning: Step 32 - Render returned None, frame skipped.\n",
      "Greedy Step 32: Action: 0, Reward: 1.2965, Total Reward: 43.7226\n",
      "Q-values: [2.947276  2.9123263 2.7432923 2.6972375 3.1655145]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.88, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.88, Min Distance=0.00\n",
      "Moving: Velocity=0.88\n",
      "Warning: Step 33 - Render returned None, frame skipped.\n",
      "Greedy Step 33: Action: 4, Reward: 1.5351, Total Reward: 45.2577\n",
      "Q-values: [2.9937928 2.9570198 2.7821558 2.7353003 3.2108011]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.84, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.84, Min Distance=0.00\n",
      "Moving: Velocity=0.84\n",
      "Warning: Step 34 - Render returned None, frame skipped.\n",
      "Greedy Step 34: Action: 4, Reward: 1.5336, Total Reward: 46.7913\n",
      "Q-values: [2.9939258 2.9571474 2.782268  2.735428  3.210932 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.80, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.80, Min Distance=0.00\n",
      "Moving: Velocity=0.80\n",
      "Warning: Step 35 - Render returned None, frame skipped.\n",
      "Greedy Step 35: Action: 4, Reward: 1.5322, Total Reward: 48.3235\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.04\n",
      "Intersection detected: Velocity=1.04, Min Distance=0.00\n",
      "Moving: Velocity=1.04\n",
      "Warning: Step 36 - Render returned None, frame skipped.\n",
      "Greedy Step 36: Action: 3, Reward: 1.0018, Total Reward: 49.3253\n",
      "Q-values: [2.9429765 2.9074922 2.7391777 2.6933165 3.1610043]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.99, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.99, Min Distance=0.00\n",
      "Moving: Velocity=0.99\n",
      "Warning: Step 37 - Render returned None, frame skipped.\n",
      "Greedy Step 37: Action: 4, Reward: 1.2398, Total Reward: 50.5650\n",
      "Q-values: [2.9827092 2.9465756 2.772509  2.7258446 3.1996164]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.96, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.96, Min Distance=0.00\n",
      "Moving: Velocity=0.96\n",
      "Warning: Step 38 - Render returned None, frame skipped.\n",
      "Greedy Step 38: Action: 4, Reward: 1.5383, Total Reward: 52.1033\n",
      "Q-values: [2.9902465 2.9537153 2.77908   2.7322762 3.2072437]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.92, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.92, Min Distance=0.00\n",
      "Moving: Velocity=0.92\n",
      "Warning: Step 39 - Render returned None, frame skipped.\n",
      "Greedy Step 39: Action: 4, Reward: 1.5368, Total Reward: 53.6401\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.88\n",
      "Intersection detected: Velocity=0.88, Min Distance=0.00\n",
      "Moving: Velocity=0.88\n",
      "Warning: Step 40 - Render returned None, frame skipped.\n",
      "Greedy Step 40: Action: 1, Reward: 1.2954, Total Reward: 54.9355\n",
      "Q-values: [2.9933    2.956611  2.7817361 2.7349057 3.210328 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.85, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.85, Min Distance=0.00\n",
      "Moving: Velocity=0.85\n",
      "Warning: Step 41 - Render returned None, frame skipped.\n",
      "Greedy Step 41: Action: 4, Reward: 1.5339, Total Reward: 56.4694\n",
      "Q-values: [2.9935737 2.9568727 2.7819712 2.735154  3.2106016]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.81, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.81, Min Distance=0.00\n",
      "Moving: Velocity=0.81\n",
      "Warning: Step 42 - Render returned None, frame skipped.\n",
      "Greedy Step 42: Action: 4, Reward: 1.5325, Total Reward: 58.0018\n",
      "Q-values: [2.9937222 2.9570158 2.782097  2.7352953 3.2107484]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.78, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.78, Min Distance=0.00\n",
      "Moving: Velocity=0.78\n",
      "Warning: Step 43 - Render returned None, frame skipped.\n",
      "Greedy Step 43: Action: 4, Reward: 1.5310, Total Reward: 59.5328\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.74\n",
      "Intersection detected: Velocity=0.74, Min Distance=0.00\n",
      "Moving: Velocity=0.74\n",
      "Warning: Step 44 - Render returned None, frame skipped.\n",
      "Greedy Step 44: Action: 1, Reward: 1.2895, Total Reward: 60.8224\n",
      "Q-values: [2.9939547 2.957241  2.7822924 2.735523  3.2109764]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.70, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.70, Min Distance=0.00\n",
      "Moving: Velocity=0.70\n",
      "Warning: Step 45 - Render returned None, frame skipped.\n",
      "Greedy Step 45: Action: 4, Reward: 1.5281, Total Reward: 62.3505\n",
      "Q-values: [2.9940689 2.9573514 2.782388  2.7356348 3.211088 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.67, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.67, Min Distance=0.00\n",
      "Moving: Velocity=0.67\n",
      "Warning: Step 46 - Render returned None, frame skipped.\n",
      "Greedy Step 46: Action: 4, Reward: 1.5266, Total Reward: 63.8771\n",
      "Q-values: [2.9941864 2.957465  2.7824867 2.7357492 3.2112029]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.63, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.63, Min Distance=0.00\n",
      "Moving: Velocity=0.63\n",
      "Warning: Step 47 - Render returned None, frame skipped.\n",
      "Greedy Step 47: Action: 4, Reward: 1.5252, Total Reward: 65.4023\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=0.92\n",
      "Intersection detected: Velocity=0.92, Min Distance=0.00\n",
      "Moving: Velocity=0.92\n",
      "Warning: Step 48 - Render returned None, frame skipped.\n",
      "Greedy Step 48: Action: 0, Reward: 1.2967, Total Reward: 66.6990\n",
      "Q-values: [2.94673   2.9118812 2.7428365 2.6968317 3.1650074]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.88, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.88, Min Distance=0.00\n",
      "Moving: Velocity=0.88\n",
      "Warning: Step 49 - Render returned None, frame skipped.\n",
      "Greedy Step 49: Action: 4, Reward: 1.5352, Total Reward: 68.2342\n",
      "Q-values: [2.9931288 2.9564643 2.7815974 2.734795  3.2101755]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.84, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.84, Min Distance=0.00\n",
      "Moving: Velocity=0.84\n",
      "Warning: Step 50 - Render returned None, frame skipped.\n",
      "Greedy Step 50: Action: 4, Reward: 1.5338, Total Reward: 69.7679\n",
      "Q-values: [2.9932353 2.956568  2.7816868 2.734901  3.21028  ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.81, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.81, Min Distance=0.00\n",
      "Moving: Velocity=0.81\n",
      "Warning: Step 51 - Render returned None, frame skipped.\n",
      "Greedy Step 51: Action: 4, Reward: 1.5323, Total Reward: 71.3002\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.09\n",
      "Intersection detected: Velocity=1.09, Min Distance=0.00\n",
      "Moving: Velocity=1.09\n",
      "Warning: Step 52 - Render returned None, frame skipped.\n",
      "Greedy Step 52: Action: 0, Reward: 1.3038, Total Reward: 72.6040\n",
      "Q-values: [2.9457576 2.9109647 2.7420187 2.695967  3.164064 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.06, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.06, Min Distance=0.00\n",
      "Moving: Velocity=1.06\n",
      "Warning: Step 53 - Render returned None, frame skipped.\n",
      "Greedy Step 53: Action: 4, Reward: 1.5423, Total Reward: 74.1463\n",
      "Q-values: [2.9921467 2.9555361 2.780771  2.733923  3.2092218]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.02, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.02, Min Distance=0.00\n",
      "Moving: Velocity=1.02\n",
      "Warning: Step 54 - Render returned None, frame skipped.\n",
      "Greedy Step 54: Action: 4, Reward: 1.5409, Total Reward: 75.6872\n",
      "Q-values: [2.99224   2.9556184 2.7808487 2.7340188 3.2093103]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=0.99, Min Distance=0.00\n",
      "Intersection detected: Velocity=0.99, Min Distance=0.00\n",
      "Moving: Velocity=0.99\n",
      "Warning: Step 55 - Render returned None, frame skipped.\n",
      "Greedy Step 55: Action: 4, Reward: 1.5394, Total Reward: 77.2266\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.27\n",
      "Intersection detected: Velocity=1.27, Min Distance=0.00\n",
      "Moving: Velocity=1.27\n",
      "Warning: Step 56 - Render returned None, frame skipped.\n",
      "Greedy Step 56: Action: 0, Reward: 1.3109, Total Reward: 78.5375\n",
      "Q-values: [2.9447308 2.909968  2.7411566 2.6950598 3.1630576]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.24, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.24, Min Distance=0.00\n",
      "Moving: Velocity=1.24\n",
      "Warning: Step 57 - Render returned None, frame skipped.\n",
      "Greedy Step 57: Action: 4, Reward: 1.5494, Total Reward: 80.0869\n",
      "Q-values: [2.9911034 2.954516  2.779897  2.7330027 3.2081969]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.20, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.20, Min Distance=0.00\n",
      "Moving: Velocity=1.20\n",
      "Warning: Step 58 - Render returned None, frame skipped.\n",
      "Greedy Step 58: Action: 4, Reward: 1.5480, Total Reward: 81.6349\n",
      "Q-values: [2.9911823 2.9545834 2.7799644 2.7330868 3.208271 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.16, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.16, Min Distance=0.00\n",
      "Moving: Velocity=1.16\n",
      "Warning: Step 59 - Render returned None, frame skipped.\n",
      "Greedy Step 59: Action: 4, Reward: 1.5465, Total Reward: 83.1814\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.13\n",
      "Intersection detected: Velocity=1.13, Min Distance=0.00\n",
      "Moving: Velocity=1.13\n",
      "Warning: Step 60 - Render returned None, frame skipped.\n",
      "Greedy Step 60: Action: 1, Reward: 1.3051, Total Reward: 84.4865\n",
      "Q-values: [2.991347  2.9547255 2.780105  2.7332606 3.2084262]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.09, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.09, Min Distance=0.00\n",
      "Moving: Velocity=1.09\n",
      "Warning: Step 61 - Render returned None, frame skipped.\n",
      "Greedy Step 61: Action: 4, Reward: 1.5436, Total Reward: 86.0301\n",
      "Q-values: [2.9914336 2.954801  2.780179  2.733351  3.208508 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.05, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.05, Min Distance=0.00\n",
      "Moving: Velocity=1.05\n",
      "Warning: Step 62 - Render returned None, frame skipped.\n",
      "Greedy Step 62: Action: 4, Reward: 1.5422, Total Reward: 87.5723\n",
      "Q-values: [2.9915218 2.954878  2.7802541 2.7334423 3.2085915]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.02, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.02, Min Distance=0.00\n",
      "Moving: Velocity=1.02\n",
      "Warning: Step 63 - Render returned None, frame skipped.\n",
      "Greedy Step 63: Action: 4, Reward: 1.5407, Total Reward: 89.1130\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.25\n",
      "Intersection detected: Velocity=1.25, Min Distance=0.00\n",
      "Moving: Velocity=1.25\n",
      "Warning: Step 64 - Render returned None, frame skipped.\n",
      "Greedy Step 64: Action: 2, Reward: 1.0099, Total Reward: 90.1229\n",
      "Q-values: [2.9386904 2.90496   2.7362995 2.6902065 3.15713  ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.19, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.19, Min Distance=0.00\n",
      "Moving: Velocity=1.19\n",
      "Warning: Step 65 - Render returned None, frame skipped.\n",
      "Greedy Step 65: Action: 4, Reward: 1.2478, Total Reward: 91.3707\n",
      "Q-values: [2.9781241 2.9422545 2.7686167 2.7220058 3.1950884]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.16, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.16, Min Distance=0.00\n",
      "Moving: Velocity=1.16\n",
      "Warning: Step 66 - Render returned None, frame skipped.\n",
      "Greedy Step 66: Action: 4, Reward: 1.5463, Total Reward: 92.9170\n",
      "Q-values: [2.9870188 2.9506605 2.7763753 2.729593  3.2040877]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.12, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.12, Min Distance=0.00\n",
      "Moving: Velocity=1.12\n",
      "Warning: Step 67 - Render returned None, frame skipped.\n",
      "Greedy Step 67: Action: 4, Reward: 1.5448, Total Reward: 94.4618\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.34\n",
      "Intersection detected: Velocity=1.34, Min Distance=0.00\n",
      "Moving: Velocity=1.34\n",
      "Warning: Step 68 - Render returned None, frame skipped.\n",
      "Greedy Step 68: Action: 2, Reward: 1.0138, Total Reward: 95.4756\n",
      "Q-values: [2.937135  2.903544  2.7349942 2.6888666 3.1556144]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.29, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.29, Min Distance=0.00\n",
      "Moving: Velocity=1.29\n",
      "Warning: Step 69 - Render returned None, frame skipped.\n",
      "Greedy Step 69: Action: 4, Reward: 1.2517, Total Reward: 96.7273\n",
      "Q-values: [2.975976  2.9402118 2.7667866 2.7201364 3.1929429]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.25, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.25, Min Distance=0.00\n",
      "Moving: Velocity=1.25\n",
      "Warning: Step 70 - Render returned None, frame skipped.\n",
      "Greedy Step 70: Action: 4, Reward: 1.5502, Total Reward: 98.2774\n",
      "Q-values: [2.9855986 2.9493086 2.7751672 2.728342  3.2026777]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.22, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.22, Min Distance=0.00\n",
      "Moving: Velocity=1.22\n",
      "Warning: Step 71 - Render returned None, frame skipped.\n",
      "Greedy Step 71: Action: 4, Reward: 1.5487, Total Reward: 99.8261\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.18\n",
      "Intersection detected: Velocity=1.18, Min Distance=0.00\n",
      "Moving: Velocity=1.18\n",
      "Warning: Step 72 - Render returned None, frame skipped.\n",
      "Greedy Step 72: Action: 1, Reward: 1.3073, Total Reward: 101.1334\n",
      "Q-values: [2.9893973 2.9529088 2.7784474 2.7316048 3.2065136]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.15, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.15, Min Distance=0.00\n",
      "Moving: Velocity=1.15\n",
      "Warning: Step 73 - Render returned None, frame skipped.\n",
      "Greedy Step 73: Action: 4, Reward: 1.5458, Total Reward: 102.6792\n",
      "Q-values: [3.0049438 2.9668455 2.7904692 2.743001  3.2210872]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.11, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.11, Min Distance=0.00\n",
      "Moving: Velocity=1.11\n",
      "Warning: Step 74 - Render returned None, frame skipped.\n",
      "Greedy Step 74: Action: 4, Reward: 1.5443, Total Reward: 104.2235\n",
      "Q-values: [3.0051074 2.9670067 2.7906122 2.7431552 3.2212508]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.07, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.07, Min Distance=0.00\n",
      "Moving: Velocity=1.07\n",
      "Warning: Step 75 - Render returned None, frame skipped.\n",
      "Greedy Step 75: Action: 4, Reward: 1.5429, Total Reward: 105.7664\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.30\n",
      "Intersection detected: Velocity=1.30, Min Distance=0.00\n",
      "Moving: Velocity=1.30\n",
      "Warning: Step 76 - Render returned None, frame skipped.\n",
      "Greedy Step 76: Action: 2, Reward: 1.0119, Total Reward: 106.7784\n",
      "Q-values: [2.9521308 2.9169774 2.746524  2.6997962 3.169652 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.25, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.25, Min Distance=0.00\n",
      "Moving: Velocity=1.25\n",
      "Warning: Step 77 - Render returned None, frame skipped.\n",
      "Greedy Step 77: Action: 4, Reward: 1.2498, Total Reward: 108.0282\n",
      "Q-values: [2.9902606 2.9531112 2.7777786 2.730454  3.2064164]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.21, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.21, Min Distance=0.00\n",
      "Moving: Velocity=1.21\n",
      "Warning: Step 78 - Render returned None, frame skipped.\n",
      "Greedy Step 78: Action: 4, Reward: 1.5483, Total Reward: 109.5766\n",
      "Q-values: [2.9995236 2.961871  2.7858617 2.7383547 3.2157936]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.17, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.17, Min Distance=0.00\n",
      "Moving: Velocity=1.17\n",
      "Warning: Step 79 - Render returned None, frame skipped.\n",
      "Greedy Step 79: Action: 4, Reward: 1.5469, Total Reward: 111.1235\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.46\n",
      "Intersection detected: Velocity=1.46, Min Distance=0.00\n",
      "Moving: Velocity=1.46\n",
      "Warning: Step 80 - Render returned None, frame skipped.\n",
      "Greedy Step 80: Action: 0, Reward: 1.3184, Total Reward: 112.4418\n",
      "Q-values: [2.955576  2.9196029 2.7492814 2.7024286 3.1731522]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.42, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.42, Min Distance=0.00\n",
      "Moving: Velocity=1.42\n",
      "Warning: Step 81 - Render returned None, frame skipped.\n",
      "Greedy Step 81: Action: 4, Reward: 1.5569, Total Reward: 113.9987\n",
      "Q-values: [3.002196  2.9643931 2.7882395 2.7405825 3.2185438]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.39, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.39, Min Distance=0.00\n",
      "Moving: Velocity=1.39\n",
      "Warning: Step 82 - Render returned None, frame skipped.\n",
      "Greedy Step 82: Action: 4, Reward: 1.5555, Total Reward: 115.5542\n",
      "Q-values: [3.0023808 2.964566  2.7884002 2.7407577 3.2187252]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.35, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.35, Min Distance=0.00\n",
      "Moving: Velocity=1.35\n",
      "Warning: Step 83 - Render returned None, frame skipped.\n",
      "Greedy Step 83: Action: 4, Reward: 1.5540, Total Reward: 117.1082\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.31\n",
      "Intersection detected: Velocity=1.31, Min Distance=0.00\n",
      "Moving: Velocity=1.31\n",
      "Warning: Step 84 - Render returned None, frame skipped.\n",
      "Greedy Step 84: Action: 1, Reward: 1.3126, Total Reward: 118.4208\n",
      "Q-values: [3.0026915 2.964849  2.788667  2.7410605 3.2190235]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.28, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.28, Min Distance=0.00\n",
      "Moving: Velocity=1.28\n",
      "Warning: Step 85 - Render returned None, frame skipped.\n",
      "Greedy Step 85: Action: 4, Reward: 1.5511, Total Reward: 119.9719\n",
      "Q-values: [3.0028646 2.9650035 2.7888138 2.7412279 3.2191875]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.24, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.24, Min Distance=0.00\n",
      "Moving: Velocity=1.24\n",
      "Warning: Step 86 - Render returned None, frame skipped.\n",
      "Greedy Step 86: Action: 4, Reward: 1.5496, Total Reward: 121.5215\n",
      "Q-values: [3.0030537 2.9651709 2.7889738 2.7414095 3.2193666]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.20, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.20, Min Distance=0.00\n",
      "Moving: Velocity=1.20\n",
      "Warning: Step 87 - Render returned None, frame skipped.\n",
      "Greedy Step 87: Action: 4, Reward: 1.5482, Total Reward: 123.0697\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.42\n",
      "Intersection detected: Velocity=1.42, Min Distance=0.00\n",
      "Moving: Velocity=1.42\n",
      "Warning: Step 88 - Render returned None, frame skipped.\n",
      "Greedy Step 88: Action: 2, Reward: 1.0170, Total Reward: 124.0867\n",
      "Q-values: [2.949697  2.91474   2.744552  2.6977398 3.1673582]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.37, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.37, Min Distance=0.00\n",
      "Moving: Velocity=1.37\n",
      "Warning: Step 89 - Render returned None, frame skipped.\n",
      "Greedy Step 89: Action: 4, Reward: 1.2548, Total Reward: 125.3415\n",
      "Q-values: [2.988402  2.951175  2.7762055 2.7289572 3.20453  ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.33, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.33, Min Distance=0.00\n",
      "Moving: Velocity=1.33\n",
      "Warning: Step 90 - Render returned None, frame skipped.\n",
      "Greedy Step 90: Action: 4, Reward: 1.5533, Total Reward: 126.8948\n",
      "Q-values: [2.9986248 2.960821  2.7851171 2.7376783 3.2148623]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.30, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.30, Min Distance=0.00\n",
      "Moving: Velocity=1.30\n",
      "Warning: Step 91 - Render returned None, frame skipped.\n",
      "Greedy Step 91: Action: 4, Reward: 1.5519, Total Reward: 128.4467\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.26\n",
      "Intersection detected: Velocity=1.26, Min Distance=0.00\n",
      "Moving: Velocity=1.26\n",
      "Warning: Step 92 - Render returned None, frame skipped.\n",
      "Greedy Step 92: Action: 1, Reward: 1.3104, Total Reward: 129.7571\n",
      "Q-values: [3.0028722 2.9648013 2.788806  2.7413323 3.2191234]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.22, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.22, Min Distance=0.00\n",
      "Moving: Velocity=1.22\n",
      "Warning: Step 93 - Render returned None, frame skipped.\n",
      "Greedy Step 93: Action: 4, Reward: 1.5490, Total Reward: 131.3060\n",
      "Q-values: [3.0033202 2.9652047 2.7891867 2.7417328 3.2195544]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.19, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.19, Min Distance=0.00\n",
      "Moving: Velocity=1.19\n",
      "Warning: Step 94 - Render returned None, frame skipped.\n",
      "Greedy Step 94: Action: 4, Reward: 1.5475, Total Reward: 132.8535\n",
      "Q-values: [3.0036056 2.9654527 2.789425  2.7419953 3.2198195]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.15, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.15, Min Distance=0.00\n",
      "Moving: Velocity=1.15\n",
      "Warning: Step 95 - Render returned None, frame skipped.\n",
      "Greedy Step 95: Action: 4, Reward: 1.5460, Total Reward: 134.3996\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.37\n",
      "Intersection detected: Velocity=1.37, Min Distance=0.00\n",
      "Moving: Velocity=1.37\n",
      "Warning: Step 96 - Render returned None, frame skipped.\n",
      "Greedy Step 96: Action: 3, Reward: 1.0149, Total Reward: 135.4145\n",
      "Q-values: [2.9514256 2.9146202 2.7452583 2.6988444 3.168628 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.32, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.32, Min Distance=0.00\n",
      "Moving: Velocity=1.32\n",
      "Warning: Step 97 - Render returned None, frame skipped.\n",
      "Greedy Step 97: Action: 4, Reward: 1.2528, Total Reward: 136.6673\n",
      "Q-values: [2.989443  2.9520845 2.7770944 2.7299135 3.2054956]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.28, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.28, Min Distance=0.00\n",
      "Moving: Velocity=1.28\n",
      "Warning: Step 98 - Render returned None, frame skipped.\n",
      "Greedy Step 98: Action: 4, Reward: 1.5513, Total Reward: 138.2186\n",
      "Q-values: [2.999318  2.9614356 2.7857072 2.7383351 3.215487 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.25, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.25, Min Distance=0.00\n",
      "Moving: Velocity=1.25\n",
      "Warning: Step 99 - Render returned None, frame skipped.\n",
      "Greedy Step 99: Action: 4, Reward: 1.5499, Total Reward: 139.7685\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.46\n",
      "Intersection detected: Velocity=1.46, Min Distance=0.00\n",
      "Moving: Velocity=1.46\n",
      "Warning: Step 100 - Render returned None, frame skipped.\n",
      "Greedy Step 100: Action: 3, Reward: 1.0185, Total Reward: 140.7870\n",
      "Q-values: [2.950406  2.913714  2.7443984 2.6979673 3.1676154]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.41, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.41, Min Distance=0.00\n",
      "Moving: Velocity=1.41\n",
      "Warning: Step 101 - Render returned None, frame skipped.\n",
      "Greedy Step 101: Action: 4, Reward: 1.2564, Total Reward: 142.0434\n",
      "Q-values: [2.9881546 2.950928  2.7759998 2.728809  3.204212 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.37, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.37, Min Distance=0.00\n",
      "Moving: Velocity=1.37\n",
      "Warning: Step 102 - Render returned None, frame skipped.\n",
      "Greedy Step 102: Action: 4, Reward: 1.5549, Total Reward: 143.5982\n",
      "Q-values: [2.9987285 2.9609427 2.785223  2.7378275 3.2149122]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.34, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.34, Min Distance=0.00\n",
      "Moving: Velocity=1.34\n",
      "Warning: Step 103 - Render returned None, frame skipped.\n",
      "Greedy Step 103: Action: 4, Reward: 1.5534, Total Reward: 145.1517\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.62\n",
      "Intersection detected: Velocity=1.62, Min Distance=0.00\n",
      "Moving: Velocity=1.62\n",
      "Warning: Step 104 - Render returned None, frame skipped.\n",
      "Greedy Step 104: Action: 0, Reward: 1.3249, Total Reward: 146.4765\n",
      "Q-values: [2.9552402 2.9191182 2.749045  2.7022946 3.1727374]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.59, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.59, Min Distance=0.00\n",
      "Moving: Velocity=1.59\n",
      "Warning: Step 105 - Render returned None, frame skipped.\n",
      "Greedy Step 105: Action: 4, Reward: 1.5634, Total Reward: 148.0400\n",
      "Q-values: [3.0018795 2.9639306 2.7880213 2.7404659 3.2181509]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.55, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.55, Min Distance=0.00\n",
      "Moving: Velocity=1.55\n",
      "Warning: Step 106 - Render returned None, frame skipped.\n",
      "Greedy Step 106: Action: 4, Reward: 1.5620, Total Reward: 149.6020\n",
      "Q-values: [3.0020514 2.964098  2.7881734 2.740631  3.2183237]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.51, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.51, Min Distance=0.00\n",
      "Moving: Velocity=1.51\n",
      "Warning: Step 107 - Render returned None, frame skipped.\n",
      "Greedy Step 107: Action: 4, Reward: 1.5605, Total Reward: 151.1625\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.72\n",
      "Intersection detected: Velocity=1.72, Min Distance=0.00\n",
      "Moving: Velocity=1.72\n",
      "Warning: Step 108 - Render returned None, frame skipped.\n",
      "Greedy Step 108: Action: 3, Reward: 1.0287, Total Reward: 152.1912\n",
      "Q-values: [2.9484816 2.9119768 2.7428029 2.6963093 3.16574  ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.66, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.66, Min Distance=0.00\n",
      "Moving: Velocity=1.66\n",
      "Warning: Step 109 - Render returned None, frame skipped.\n",
      "Greedy Step 109: Action: 4, Reward: 1.2664, Total Reward: 153.4576\n",
      "Q-values: [2.984619  2.9476757 2.7729995 2.725784  3.2007072]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.62, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.62, Min Distance=0.00\n",
      "Moving: Velocity=1.62\n",
      "Warning: Step 110 - Render returned None, frame skipped.\n",
      "Greedy Step 110: Action: 4, Reward: 1.5649, Total Reward: 155.0225\n",
      "Q-values: [2.9968946 2.9593046 2.7837086 2.7362542 3.2131321]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.59, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.59, Min Distance=0.00\n",
      "Moving: Velocity=1.59\n",
      "Warning: Step 111 - Render returned None, frame skipped.\n",
      "Greedy Step 111: Action: 4, Reward: 1.5634, Total Reward: 156.5859\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.55\n",
      "Intersection detected: Velocity=1.55, Min Distance=0.00\n",
      "Moving: Velocity=1.55\n",
      "Warning: Step 112 - Render returned None, frame skipped.\n",
      "Greedy Step 112: Action: 1, Reward: 1.3220, Total Reward: 157.9079\n",
      "Q-values: [3.0017657 2.9639294 2.7879622 2.7404418 3.2180629]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.51, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.51, Min Distance=0.00\n",
      "Moving: Velocity=1.51\n",
      "Warning: Step 113 - Render returned None, frame skipped.\n",
      "Greedy Step 113: Action: 4, Reward: 1.5605, Total Reward: 159.4684\n",
      "Q-values: [3.0021603 2.9643102 2.788309  2.7407987 3.2184625]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.48, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.48, Min Distance=0.00\n",
      "Moving: Velocity=1.48\n",
      "Warning: Step 114 - Render returned None, frame skipped.\n",
      "Greedy Step 114: Action: 4, Reward: 1.5591, Total Reward: 161.0275\n",
      "Q-values: [3.0023546 2.964501  2.7884808 2.7409847 3.2186592]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.44, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.44, Min Distance=0.00\n",
      "Moving: Velocity=1.44\n",
      "Warning: Step 115 - Render returned None, frame skipped.\n",
      "Greedy Step 115: Action: 4, Reward: 1.5576, Total Reward: 162.5851\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.65\n",
      "Intersection detected: Velocity=1.65, Min Distance=0.00\n",
      "Moving: Velocity=1.65\n",
      "Warning: Step 116 - Render returned None, frame skipped.\n",
      "Greedy Step 116: Action: 3, Reward: 1.0259, Total Reward: 163.6110\n",
      "Q-values: [2.9490707 2.9126537 2.7433596 2.6969078 3.166368 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.59, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.59, Min Distance=0.00\n",
      "Moving: Velocity=1.59\n",
      "Warning: Step 117 - Render returned None, frame skipped.\n",
      "Greedy Step 117: Action: 4, Reward: 1.2637, Total Reward: 164.8747\n",
      "Q-values: [2.985607  2.948731  2.7739046 2.7267237 3.2017412]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.55, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.55, Min Distance=0.00\n",
      "Moving: Velocity=1.55\n",
      "Warning: Step 118 - Render returned None, frame skipped.\n",
      "Greedy Step 118: Action: 4, Reward: 1.5622, Total Reward: 166.4369\n",
      "Q-values: [2.9974136 2.959918  2.7842045 2.7367966 3.2136927]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.52, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.52, Min Distance=0.00\n",
      "Moving: Velocity=1.52\n",
      "Warning: Step 119 - Render returned None, frame skipped.\n",
      "Greedy Step 119: Action: 4, Reward: 1.5607, Total Reward: 167.9976\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.48\n",
      "Intersection detected: Velocity=1.48, Min Distance=0.00\n",
      "Moving: Velocity=1.48\n",
      "Warning: Step 120 - Render returned None, frame skipped.\n",
      "Greedy Step 120: Action: 1, Reward: 1.3193, Total Reward: 169.3168\n",
      "Q-values: [3.0021281 2.9643989 2.7883215 2.7408538 3.218467 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.45, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.45, Min Distance=0.00\n",
      "Moving: Velocity=1.45\n",
      "Warning: Step 121 - Render returned None, frame skipped.\n",
      "Greedy Step 121: Action: 4, Reward: 1.5578, Total Reward: 170.8746\n",
      "Q-values: [3.0025306 2.964789  2.788675  2.7412186 3.2188756]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.41, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.41, Min Distance=0.00\n",
      "Moving: Velocity=1.41\n",
      "Warning: Step 122 - Render returned None, frame skipped.\n",
      "Greedy Step 122: Action: 4, Reward: 1.5564, Total Reward: 172.4310\n",
      "Q-values: [3.002736  2.9649925 2.7888565 2.7414155 3.2190847]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.37, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.37, Min Distance=0.00\n",
      "Moving: Velocity=1.37\n",
      "Warning: Step 123 - Render returned None, frame skipped.\n",
      "Greedy Step 123: Action: 4, Reward: 1.5549, Total Reward: 173.9859\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.58\n",
      "Intersection detected: Velocity=1.58, Min Distance=0.00\n",
      "Moving: Velocity=1.58\n",
      "Warning: Step 124 - Render returned None, frame skipped.\n",
      "Greedy Step 124: Action: 3, Reward: 1.0233, Total Reward: 175.0092\n",
      "Q-values: [2.949698  2.913381  2.7439501 2.6975493 3.167045 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.53, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.53, Min Distance=0.00\n",
      "Moving: Velocity=1.53\n",
      "Warning: Step 125 - Render returned None, frame skipped.\n",
      "Greedy Step 125: Action: 4, Reward: 1.2611, Total Reward: 176.2703\n",
      "Q-values: [2.986598  2.9498029 2.7748127 2.7276764 3.2027884]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.49, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.49, Min Distance=0.00\n",
      "Moving: Velocity=1.49\n",
      "Warning: Step 126 - Render returned None, frame skipped.\n",
      "Greedy Step 126: Action: 4, Reward: 1.5596, Total Reward: 177.8300\n",
      "Q-values: [2.9979796 2.9605896 2.7847416 2.7373886 3.2143106]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.45, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.45, Min Distance=0.00\n",
      "Moving: Velocity=1.45\n",
      "Warning: Step 127 - Render returned None, frame skipped.\n",
      "Greedy Step 127: Action: 4, Reward: 1.5582, Total Reward: 179.3881\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.74\n",
      "Intersection detected: Velocity=1.74, Min Distance=0.00\n",
      "Moving: Velocity=1.74\n",
      "Warning: Step 128 - Render returned None, frame skipped.\n",
      "Greedy Step 128: Action: 0, Reward: 1.3296, Total Reward: 180.7178\n",
      "Q-values: [2.9548635 2.919132  2.7488904 2.7021842 3.172521 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.70, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.70, Min Distance=0.00\n",
      "Moving: Velocity=1.70\n",
      "Warning: Step 129 - Render returned None, frame skipped.\n",
      "Greedy Step 129: Action: 4, Reward: 1.5682, Total Reward: 182.2860\n",
      "Q-values: [3.0015643 2.964011  2.787922  2.7404149 3.218002 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.67, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.67, Min Distance=0.00\n",
      "Moving: Velocity=1.67\n",
      "Warning: Step 130 - Render returned None, frame skipped.\n",
      "Greedy Step 130: Action: 4, Reward: 1.5667, Total Reward: 183.8527\n",
      "Q-values: [3.0017865 2.9642344 2.7881196 2.7406301 3.2182307]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.63, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.63, Min Distance=0.00\n",
      "Moving: Velocity=1.63\n",
      "Warning: Step 131 - Render returned None, frame skipped.\n",
      "Greedy Step 131: Action: 4, Reward: 1.5653, Total Reward: 185.4180\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.83\n",
      "Intersection detected: Velocity=1.83, Min Distance=0.00\n",
      "Moving: Velocity=1.83\n",
      "Warning: Step 132 - Render returned None, frame skipped.\n",
      "Greedy Step 132: Action: 3, Reward: 1.0331, Total Reward: 186.4511\n",
      "Q-values: [2.9479628 2.9118905 2.7425292 2.6961079 3.1653993]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.77, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.77, Min Distance=0.00\n",
      "Moving: Velocity=1.77\n",
      "Warning: Step 133 - Render returned None, frame skipped.\n",
      "Greedy Step 133: Action: 4, Reward: 1.2708, Total Reward: 187.7220\n",
      "Q-values: [2.983377  2.9469168 2.7720962 2.7249749 3.199641 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.73, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.73, Min Distance=0.00\n",
      "Moving: Velocity=1.73\n",
      "Warning: Step 134 - Render returned None, frame skipped.\n",
      "Greedy Step 134: Action: 4, Reward: 1.5693, Total Reward: 189.2913\n",
      "Q-values: [2.9964502 2.9593098 2.783502  2.7361317 3.2128787]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.70, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.70, Min Distance=0.00\n",
      "Moving: Velocity=1.70\n",
      "Warning: Step 135 - Render returned None, frame skipped.\n",
      "Greedy Step 135: Action: 4, Reward: 1.5679, Total Reward: 190.8592\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.98\n",
      "Intersection detected: Velocity=1.98, Min Distance=0.00\n",
      "Moving: Velocity=1.98\n",
      "Warning: Step 136 - Render returned None, frame skipped.\n",
      "Greedy Step 136: Action: 0, Reward: 1.3394, Total Reward: 192.1986\n",
      "Q-values: [2.9540336 2.9185238 2.748264  2.7015316 3.1718037]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.95, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.95, Min Distance=0.00\n",
      "Moving: Velocity=1.95\n",
      "Warning: Step 137 - Render returned None, frame skipped.\n",
      "Greedy Step 137: Action: 4, Reward: 1.5779, Total Reward: 193.7765\n",
      "Q-values: [3.000788  2.9634585 2.787344  2.7398126 3.2173421]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.91, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.91, Min Distance=0.00\n",
      "Moving: Velocity=1.91\n",
      "Warning: Step 138 - Render returned None, frame skipped.\n",
      "Greedy Step 138: Action: 4, Reward: 1.5765, Total Reward: 195.3529\n",
      "Q-values: [3.001039  2.9637144 2.787568  2.740057  3.2176034]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.88, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.88, Min Distance=0.00\n",
      "Moving: Velocity=1.88\n",
      "Warning: Step 139 - Render returned None, frame skipped.\n",
      "Greedy Step 139: Action: 4, Reward: 1.5750, Total Reward: 196.9280\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.06\n",
      "Intersection detected: Velocity=2.06, Min Distance=0.00\n",
      "Moving: Velocity=2.06\n",
      "Warning: Step 140 - Render returned None, frame skipped.\n",
      "Greedy Step 140: Action: 2, Reward: 1.0423, Total Reward: 197.9703\n",
      "Q-values: [2.9455066 2.9112854 2.7412665 2.6945634 3.1634285]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.00, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.00, Min Distance=0.00\n",
      "Moving: Velocity=2.00\n",
      "Warning: Step 141 - Render returned None, frame skipped.\n",
      "Greedy Step 141: Action: 4, Reward: 1.2800, Total Reward: 199.2502\n",
      "Q-values: [2.9801185 2.94391   2.7693698 2.72228   3.1964839]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.96, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.96, Min Distance=0.00\n",
      "Moving: Velocity=1.96\n",
      "Warning: Step 142 - Render returned None, frame skipped.\n",
      "Greedy Step 142: Action: 4, Reward: 1.5785, Total Reward: 200.8287\n",
      "Q-values: [2.9946783 2.957683  2.7820764 2.734703  3.2112284]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.92, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.92, Min Distance=0.00\n",
      "Moving: Velocity=1.92\n",
      "Warning: Step 143 - Render returned None, frame skipped.\n",
      "Greedy Step 143: Action: 4, Reward: 1.5770, Total Reward: 202.4057\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=1.89\n",
      "Intersection detected: Velocity=1.89, Min Distance=0.00\n",
      "Moving: Velocity=1.89\n",
      "Warning: Step 144 - Render returned None, frame skipped.\n",
      "Greedy Step 144: Action: 1, Reward: 1.3355, Total Reward: 203.7412\n",
      "Q-values: [3.000569  2.9632816 2.787225  2.7397745 3.217203 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.85, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.85, Min Distance=0.00\n",
      "Moving: Velocity=1.85\n",
      "Warning: Step 145 - Render returned None, frame skipped.\n",
      "Greedy Step 145: Action: 4, Reward: 1.5741, Total Reward: 205.3153\n",
      "Q-values: [3.0010433 2.9637446 2.7876434 2.7402055 3.217688 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.82, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.82, Min Distance=0.00\n",
      "Moving: Velocity=1.82\n",
      "Warning: Step 146 - Render returned None, frame skipped.\n",
      "Greedy Step 146: Action: 4, Reward: 1.5726, Total Reward: 206.8880\n",
      "Q-values: [3.0012767 2.9639792 2.7878513 2.740431  3.2179286]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.78, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.78, Min Distance=0.00\n",
      "Moving: Velocity=1.78\n",
      "Warning: Step 147 - Render returned None, frame skipped.\n",
      "Greedy Step 147: Action: 4, Reward: 1.5712, Total Reward: 208.4591\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.07\n",
      "Intersection detected: Velocity=2.07, Min Distance=0.00\n",
      "Moving: Velocity=2.07\n",
      "Warning: Step 148 - Render returned None, frame skipped.\n",
      "Greedy Step 148: Action: 0, Reward: 1.3427, Total Reward: 209.8018\n",
      "Q-values: [2.953915  2.9185078 2.7483006 2.7016194 3.1718462]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.03, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.03, Min Distance=0.00\n",
      "Moving: Velocity=2.03\n",
      "Warning: Step 149 - Render returned None, frame skipped.\n",
      "Greedy Step 149: Action: 4, Reward: 1.5812, Total Reward: 211.3830\n",
      "Q-values: [3.0003655 2.9631522 2.7871153 2.7396398 3.2170756]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.99, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.99, Min Distance=0.00\n",
      "Moving: Velocity=1.99\n",
      "Warning: Step 150 - Render returned None, frame skipped.\n",
      "Greedy Step 150: Action: 4, Reward: 1.5797, Total Reward: 212.9627\n",
      "Q-values: [3.0005214 2.963315  2.7872567 2.739801  3.217239 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=1.96, Min Distance=0.00\n",
      "Intersection detected: Velocity=1.96, Min Distance=0.00\n",
      "Moving: Velocity=1.96\n",
      "Warning: Step 151 - Render returned None, frame skipped.\n",
      "Greedy Step 151: Action: 4, Reward: 1.5783, Total Reward: 214.5410\n",
      "Applying action 2: [-0.5  1.   0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.14\n",
      "Intersection detected: Velocity=2.14, Min Distance=0.00\n",
      "Moving: Velocity=2.14\n",
      "Warning: Step 152 - Render returned None, frame skipped.\n",
      "Greedy Step 152: Action: 2, Reward: 1.0454, Total Reward: 215.5865\n",
      "Q-values: [2.9447525 2.9106555 2.7407484 2.6941032 3.1628203]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.08, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.08, Min Distance=0.00\n",
      "Moving: Velocity=2.08\n",
      "Warning: Step 153 - Render returned None, frame skipped.\n",
      "Greedy Step 153: Action: 4, Reward: 1.2830, Total Reward: 216.8695\n",
      "Q-values: [2.978788  2.9427283 2.7683482 2.7213268 3.1952891]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.04, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.04, Min Distance=0.00\n",
      "Moving: Velocity=2.04\n",
      "Warning: Step 154 - Render returned None, frame skipped.\n",
      "Greedy Step 154: Action: 4, Reward: 1.5815, Total Reward: 218.4510\n",
      "Q-values: [2.9938242 2.9569485 2.7814703 2.7341533 3.2105143]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.00, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.00, Min Distance=0.00\n",
      "Moving: Velocity=2.00\n",
      "Warning: Step 155 - Render returned None, frame skipped.\n",
      "Greedy Step 155: Action: 4, Reward: 1.5801, Total Reward: 220.0311\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.29\n",
      "Intersection detected: Velocity=2.29, Min Distance=0.00\n",
      "Moving: Velocity=2.29\n",
      "Warning: Step 156 - Render returned None, frame skipped.\n",
      "Greedy Step 156: Action: 0, Reward: 1.3516, Total Reward: 221.3827\n",
      "Q-values: [2.9521847 2.9168813 2.746913  2.700211  3.170223 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.25, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.25, Min Distance=0.00\n",
      "Moving: Velocity=2.25\n",
      "Warning: Step 157 - Render returned None, frame skipped.\n",
      "Greedy Step 157: Action: 4, Reward: 1.5901, Total Reward: 222.9728\n",
      "Q-values: [2.9989393 2.9618106 2.7859938 2.7384892 3.2157593]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.22, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.22, Min Distance=0.00\n",
      "Moving: Velocity=2.22\n",
      "Warning: Step 158 - Render returned None, frame skipped.\n",
      "Greedy Step 158: Action: 4, Reward: 1.5886, Total Reward: 224.5614\n",
      "Q-values: [2.9991548 2.9620266 2.786188  2.7386994 3.2159817]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.18, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.18, Min Distance=0.00\n",
      "Moving: Velocity=2.18\n",
      "Warning: Step 159 - Render returned None, frame skipped.\n",
      "Greedy Step 159: Action: 4, Reward: 1.5872, Total Reward: 226.1486\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.47\n",
      "Intersection detected: Velocity=2.47, Min Distance=0.00\n",
      "Moving: Velocity=2.47\n",
      "Warning: Step 160 - Render returned None, frame skipped.\n",
      "Greedy Step 160: Action: 0, Reward: 1.3587, Total Reward: 227.5073\n",
      "Q-values: [2.9517353 2.9164972 2.74659   2.6998382 3.16984  ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.43, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.43, Min Distance=0.00\n",
      "Moving: Velocity=2.43\n",
      "Warning: Step 161 - Render returned None, frame skipped.\n",
      "Greedy Step 161: Action: 4, Reward: 1.5972, Total Reward: 229.1045\n",
      "Q-values: [2.9981575 2.961113  2.7853816 2.7378342 3.2150404]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.39, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.39, Min Distance=0.00\n",
      "Moving: Velocity=2.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n",
      "\u001b[33;20m[WARNING] Panda Rendering is off now, can not render. Please set config['use_render'] = True! (base_env.py:506)\u001b[0m\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Step 162 - Render returned None, frame skipped.\n",
      "Greedy Step 162: Action: 4, Reward: 1.5958, Total Reward: 230.7002\n",
      "Q-values: [2.9982843 2.961246  2.785499  2.7379704 3.2151742]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.36, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.36, Min Distance=0.00\n",
      "Moving: Velocity=2.36\n",
      "Warning: Step 163 - Render returned None, frame skipped.\n",
      "Greedy Step 163: Action: 4, Reward: 1.5943, Total Reward: 232.2945\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.51\n",
      "Intersection detected: Velocity=2.51, Min Distance=0.00\n",
      "Moving: Velocity=2.51\n",
      "Warning: Step 164 - Render returned None, frame skipped.\n",
      "Greedy Step 164: Action: 3, Reward: 1.0604, Total Reward: 233.3549\n",
      "Q-values: [2.9433165 2.9078248 2.738911  2.6924918 3.1611803]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.45, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.45, Min Distance=0.00\n",
      "Moving: Velocity=2.45\n",
      "Warning: Step 165 - Render returned None, frame skipped.\n",
      "Greedy Step 165: Action: 4, Reward: 1.2980, Total Reward: 234.6529\n",
      "Q-values: [2.9741428 2.9385273 2.764478  2.7174563 3.1907806]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.41, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.41, Min Distance=0.00\n",
      "Moving: Velocity=2.41\n",
      "Warning: Step 166 - Render returned None, frame skipped.\n",
      "Greedy Step 166: Action: 4, Reward: 1.5965, Total Reward: 236.2494\n",
      "Q-values: [2.9912524 2.9547443 2.7794075 2.7320518 3.2081068]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.37, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.37, Min Distance=0.00\n",
      "Moving: Velocity=2.37\n",
      "Warning: Step 167 - Render returned None, frame skipped.\n",
      "Greedy Step 167: Action: 4, Reward: 1.5950, Total Reward: 237.8444\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.66\n",
      "Intersection detected: Velocity=2.66, Min Distance=0.00\n",
      "Moving: Velocity=2.66\n",
      "Warning: Step 168 - Render returned None, frame skipped.\n",
      "Greedy Step 168: Action: 0, Reward: 1.3665, Total Reward: 239.2108\n",
      "Q-values: [2.9505243 2.91556   2.7456484 2.6988957 3.1687453]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.63, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.63, Min Distance=0.00\n",
      "Moving: Velocity=2.63\n",
      "Warning: Step 169 - Render returned None, frame skipped.\n",
      "Greedy Step 169: Action: 4, Reward: 1.6050, Total Reward: 240.8159\n",
      "Q-values: [2.9973462 2.9605606 2.7847905 2.7372375 3.2143543]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.59, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.59, Min Distance=0.00\n",
      "Moving: Velocity=2.59\n",
      "Warning: Step 170 - Render returned None, frame skipped.\n",
      "Greedy Step 170: Action: 4, Reward: 1.6036, Total Reward: 242.4194\n",
      "Q-values: [2.997605  2.9608254 2.7850246 2.737492  3.2146258]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.55, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.55, Min Distance=0.00\n",
      "Moving: Velocity=2.55\n",
      "Warning: Step 171 - Render returned None, frame skipped.\n",
      "Greedy Step 171: Action: 4, Reward: 1.6021, Total Reward: 244.0215\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.84\n",
      "Intersection detected: Velocity=2.84, Min Distance=0.00\n",
      "Moving: Velocity=2.84\n",
      "Warning: Step 172 - Render returned None, frame skipped.\n",
      "Greedy Step 172: Action: 0, Reward: 1.3736, Total Reward: 245.3951\n",
      "Q-values: [2.9502478 2.9153705 2.7454855 2.698698  3.1685572]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.80, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.80, Min Distance=0.00\n",
      "Moving: Velocity=2.80\n",
      "Warning: Step 173 - Render returned None, frame skipped.\n",
      "Greedy Step 173: Action: 4, Reward: 1.6121, Total Reward: 247.0073\n",
      "Q-values: [2.9967015 2.9600239 2.7843072 2.7367282 3.2137947]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.77, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.77, Min Distance=0.00\n",
      "Moving: Velocity=2.77\n",
      "Warning: Step 174 - Render returned None, frame skipped.\n",
      "Greedy Step 174: Action: 4, Reward: 1.6107, Total Reward: 248.6179\n",
      "Q-values: [2.9968607 2.960196  2.7844553 2.7368996 3.2139664]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.73, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.73, Min Distance=0.00\n",
      "Moving: Velocity=2.73\n",
      "Warning: Step 175 - Render returned None, frame skipped.\n",
      "Greedy Step 175: Action: 4, Reward: 1.6092, Total Reward: 250.2272\n",
      "Applying action 3: [0.5 1.  0. ]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.86\n",
      "Intersection detected: Velocity=2.86, Min Distance=0.00\n",
      "Moving: Velocity=2.86\n",
      "Warning: Step 176 - Render returned None, frame skipped.\n",
      "Greedy Step 176: Action: 3, Reward: 1.0743, Total Reward: 251.3015\n",
      "Q-values: [2.9420798 2.9069684 2.7380314 2.6916027 3.1601686]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.80, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.80, Min Distance=0.00\n",
      "Moving: Velocity=2.80\n",
      "Warning: Step 177 - Render returned None, frame skipped.\n",
      "Greedy Step 177: Action: 4, Reward: 1.3119, Total Reward: 252.6134\n",
      "Q-values: [2.9709444 2.9358287 2.7618892 2.7149045 3.18779  ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.76, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.76, Min Distance=0.00\n",
      "Moving: Velocity=2.76\n",
      "Warning: Step 178 - Render returned None, frame skipped.\n",
      "Greedy Step 178: Action: 4, Reward: 1.6104, Total Reward: 254.2238\n",
      "Q-values: [2.989353  2.9532847 2.777954  2.7306137 3.2064373]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.72, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.72, Min Distance=0.00\n",
      "Moving: Velocity=2.72\n",
      "Warning: Step 179 - Render returned None, frame skipped.\n",
      "Greedy Step 179: Action: 4, Reward: 1.6089, Total Reward: 255.8327\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.69\n",
      "Intersection detected: Velocity=2.69, Min Distance=0.00\n",
      "Moving: Velocity=2.69\n",
      "Warning: Step 180 - Render returned None, frame skipped.\n",
      "Greedy Step 180: Action: 1, Reward: 1.3675, Total Reward: 257.2001\n",
      "Q-values: [2.9970348 2.960609  2.784673  2.7372308 3.2142396]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.65, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.65, Min Distance=0.00\n",
      "Moving: Velocity=2.65\n",
      "Warning: Step 181 - Render returned None, frame skipped.\n",
      "Greedy Step 181: Action: 4, Reward: 1.6060, Total Reward: 258.8062\n",
      "Q-values: [2.997633  2.961202  2.785204  2.7377794 3.2148583]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.61, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.61, Min Distance=0.00\n",
      "Moving: Velocity=2.61\n",
      "Warning: Step 182 - Render returned None, frame skipped.\n",
      "Greedy Step 182: Action: 4, Reward: 1.6046, Total Reward: 260.4107\n",
      "Q-values: [2.997927  2.9615064 2.7854695 2.7380688 3.215169 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.58, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.58, Min Distance=0.00\n",
      "Moving: Velocity=2.58\n",
      "Warning: Step 183 - Render returned None, frame skipped.\n",
      "Greedy Step 183: Action: 4, Reward: 1.6031, Total Reward: 262.0138\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.54\n",
      "Intersection detected: Velocity=2.54, Min Distance=0.00\n",
      "Moving: Velocity=2.54\n",
      "Warning: Step 184 - Render returned None, frame skipped.\n",
      "Greedy Step 184: Action: 1, Reward: 1.3617, Total Reward: 263.3755\n",
      "Q-values: [2.9983401 2.9619493 2.7858474 2.7384975 3.2156126]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.50, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.50, Min Distance=0.00\n",
      "Moving: Velocity=2.50\n",
      "Warning: Step 185 - Render returned None, frame skipped.\n",
      "Greedy Step 185: Action: 4, Reward: 1.6002, Total Reward: 264.9757\n",
      "Q-values: [2.9985337 2.962158  2.7860248 2.7387004 3.2158208]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.47, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.47, Min Distance=0.00\n",
      "Moving: Velocity=2.47\n",
      "Warning: Step 186 - Render returned None, frame skipped.\n",
      "Greedy Step 186: Action: 4, Reward: 1.5987, Total Reward: 266.5744\n",
      "Q-values: [2.9987264 2.9623654 2.786201  2.7389019 3.216028 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.43, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.43, Min Distance=0.00\n",
      "Moving: Velocity=2.43\n",
      "Warning: Step 187 - Render returned None, frame skipped.\n",
      "Greedy Step 187: Action: 4, Reward: 1.5973, Total Reward: 268.1717\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.40\n",
      "Intersection detected: Velocity=2.40, Min Distance=0.00\n",
      "Moving: Velocity=2.40\n",
      "Warning: Step 188 - Render returned None, frame skipped.\n",
      "Greedy Step 188: Action: 1, Reward: 1.3558, Total Reward: 269.5275\n",
      "Q-values: [2.9991107 2.962778  2.7865522 2.739303  3.2164404]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.36, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.36, Min Distance=0.00\n",
      "Moving: Velocity=2.36\n",
      "Warning: Step 189 - Render returned None, frame skipped.\n",
      "Greedy Step 189: Action: 4, Reward: 1.5944, Total Reward: 271.1219\n",
      "Q-values: [2.9993014 2.962983  2.7867262 2.739502  3.2166448]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.32, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.32, Min Distance=0.00\n",
      "Moving: Velocity=2.32\n",
      "Warning: Step 190 - Render returned None, frame skipped.\n",
      "Greedy Step 190: Action: 4, Reward: 1.5929, Total Reward: 272.7148\n",
      "Q-values: [2.9994924 2.9631872 2.7869003 2.7397008 3.2168493]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.29, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.29, Min Distance=0.00\n",
      "Moving: Velocity=2.29\n",
      "Warning: Step 191 - Render returned None, frame skipped.\n",
      "Greedy Step 191: Action: 4, Reward: 1.5915, Total Reward: 274.3063\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.57\n",
      "Intersection detected: Velocity=2.57, Min Distance=0.00\n",
      "Moving: Velocity=2.57\n",
      "Warning: Step 192 - Render returned None, frame skipped.\n",
      "Greedy Step 192: Action: 0, Reward: 1.3629, Total Reward: 275.6693\n",
      "Q-values: [2.9521804 2.9177825 2.7473989 2.7009492 3.1708298]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.54, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.54, Min Distance=0.00\n",
      "Moving: Velocity=2.54\n",
      "Warning: Step 193 - Render returned None, frame skipped.\n",
      "Greedy Step 193: Action: 4, Reward: 1.6015, Total Reward: 277.2707\n",
      "Q-values: [2.998669  2.9624732 2.7862499 2.7390113 3.2161043]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.50, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.50, Min Distance=0.00\n",
      "Moving: Velocity=2.50\n",
      "Warning: Step 194 - Render returned None, frame skipped.\n",
      "Greedy Step 194: Action: 4, Reward: 1.6000, Total Reward: 278.8708\n",
      "Q-values: [2.9988618 2.9626813 2.7864268 2.7392137 3.216312 ]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.46, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.46, Min Distance=0.00\n",
      "Moving: Velocity=2.46\n",
      "Warning: Step 195 - Render returned None, frame skipped.\n",
      "Greedy Step 195: Action: 4, Reward: 1.5986, Total Reward: 280.4694\n",
      "Applying action 0: [0. 1. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.75\n",
      "Intersection detected: Velocity=2.75, Min Distance=0.00\n",
      "Moving: Velocity=2.75\n",
      "Warning: Step 196 - Render returned None, frame skipped.\n",
      "Greedy Step 196: Action: 0, Reward: 1.3701, Total Reward: 281.8394\n",
      "Q-values: [2.9515545 2.9172843 2.7469313 2.7004697 3.1702998]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.72, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.72, Min Distance=0.00\n",
      "Moving: Velocity=2.72\n",
      "Warning: Step 197 - Render returned None, frame skipped.\n",
      "Greedy Step 197: Action: 4, Reward: 1.6086, Total Reward: 283.4480\n",
      "Q-values: [2.998045  2.9619787 2.785785  2.7385354 3.2155776]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.68, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.68, Min Distance=0.00\n",
      "Moving: Velocity=2.68\n",
      "Warning: Step 198 - Render returned None, frame skipped.\n",
      "Greedy Step 198: Action: 4, Reward: 1.6072, Total Reward: 285.0552\n",
      "Q-values: [2.99824   2.9621906 2.7859645 2.7387416 3.2157886]\n",
      "Applying action 4: [0. 0. 1.]\n",
      "Intersection Brake Rewarded: Velocity=2.64, Min Distance=0.00\n",
      "Intersection detected: Velocity=2.64, Min Distance=0.00\n",
      "Moving: Velocity=2.64\n",
      "Warning: Step 199 - Render returned None, frame skipped.\n",
      "Greedy Step 199: Action: 4, Reward: 1.6057, Total Reward: 286.6609\n",
      "Applying action 1: [0. 0. 0.]\n",
      "Intersection Slow Speed Rewarded: Velocity=2.61\n",
      "Intersection detected: Velocity=2.61, Min Distance=0.00\n",
      "Moving: Velocity=2.61\n",
      "Warning: Step 200 - Render returned None, frame skipped.\n",
      "Greedy Step 200: Action: 1, Reward: 1.3642, Total Reward: 288.0251\n",
      "No frames captured, GIF not created.\n",
      "Greedy episode completed. Total Reward: 288.0251\n",
      "Environment closed\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from metadrive.envs import MetaDriveEnv\n",
    "from metadrive.engine.engine_utils import close_engine\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "# --- SeedWrapper ---\n",
    "class SeedWrapper(gym.Wrapper):\n",
    "    def reset(self, seed=None, **kwargs):\n",
    "        return self.env.reset(**kwargs)\n",
    "\n",
    "# --- DiscreteActionWrapper ---\n",
    "class DiscreteActionWrapper(gym.ActionWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.discrete_actions = [\n",
    "            np.array([0.0, 1.0, 0.0]),   # accelerate\n",
    "            np.array([0.0, 0.0, 0.0]),   # no-op\n",
    "            np.array([-0.5, 1.0, 0.0]),  # turn left while accelerating\n",
    "            np.array([0.5, 1.0, 0.0]),   # turn right while accelerating\n",
    "            np.array([0.0, 0.0, 1.0]),   # brake\n",
    "        ]\n",
    "        self.action_space = gym.spaces.Discrete(len(self.discrete_actions))\n",
    "        \n",
    "    def action(self, action_idx):\n",
    "        action = self.discrete_actions[action_idx]\n",
    "        print(f\"Applying action {action_idx}: {action}\")\n",
    "        return action\n",
    "    \n",
    "    def reset(self, **kwargs):\n",
    "        kwargs.pop(\"options\", None)\n",
    "        return self.env.reset(**kwargs)\n",
    "\n",
    "# --- Custom Reward Wrapper ---\n",
    "class CustomRewardWrapper(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.max_speed = 20.0\n",
    "        self.lane_reward = 0.4  # Increased to encourage lane-keeping\n",
    "        self.progress_reward = 0.8  # Increased to encourage movement\n",
    "        self.brake_reward = 0.8  # Reduced to balance braking\n",
    "        self.smooth_turn_reward = 0.3  # Increased for smoother driving\n",
    "        self.collision_penalty = -1.5  # Increased penalty\n",
    "        self.off_road_penalty = -1.0  # Increased penalty\n",
    "        self.speed_penalty = -0.5  # Increased penalty\n",
    "        self.intersection_speed_threshold = 0.4 * self.max_speed\n",
    "        self.prev_steering = 0.0\n",
    "        self.prev_velocity = 0.0\n",
    "        \n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        velocity = info.get(\"velocity\", 0.0)\n",
    "        cost = info.get(\"cost\", 0.0)\n",
    "        steering = self.env.discrete_actions[action][0]\n",
    "        \n",
    "        lidar_data = obs[:240]\n",
    "        min_distance = np.min(lidar_data) if len(lidar_data) > 0 else 1.0\n",
    "        \n",
    "        out_of_road = info.get(\"out_of_road\", False)\n",
    "        near_intersection = min_distance < 0.4\n",
    "\n",
    "        lane_bonus = self.lane_reward if not out_of_road else 0.0\n",
    "        progress = (velocity / self.max_speed) * self.progress_reward\n",
    "        \n",
    "        brake_bonus = 0.0\n",
    "        if near_intersection:\n",
    "            if action == 4:\n",
    "                if self.prev_velocity == 0.0:\n",
    "                    brake_bonus = 0.4  # Reduced for stopped braking\n",
    "                else:\n",
    "                    brake_bonus = self.brake_reward\n",
    "                print(f\"Intersection Brake Rewarded: Velocity={velocity:.2f}, Min Distance={min_distance:.2f}\")\n",
    "            elif velocity < self.intersection_speed_threshold and velocity > 0.0:\n",
    "                brake_bonus = self.brake_reward * 0.7\n",
    "                print(f\"Intersection Slow Speed Rewarded: Velocity={velocity:.2f}\")\n",
    "        \n",
    "        steering_diff = abs(steering - self.prev_steering)\n",
    "        smooth_turn = self.smooth_turn_reward if steering_diff < 0.3 else 0.0\n",
    "        self.prev_steering = steering\n",
    "        self.prev_velocity = velocity\n",
    "        \n",
    "        collision_cost = self.collision_penalty if cost > 0 else 0.0\n",
    "        off_road_cost = self.off_road_penalty if out_of_road else 0.0\n",
    "        speed_cost = self.speed_penalty if (velocity > self.intersection_speed_threshold and near_intersection) else 0.0\n",
    "        \n",
    "        custom_reward = (lane_bonus + progress + brake_bonus + smooth_turn + \n",
    "                        collision_cost + off_road_cost + speed_cost)\n",
    "        custom_reward = np.clip(custom_reward, -2.0, 2.0)  # Adjusted clipping range\n",
    "        \n",
    "        if near_intersection:\n",
    "            print(f\"Intersection detected: Velocity={velocity:.2f}, Min Distance={min_distance:.2f}\")\n",
    "        if out_of_road:\n",
    "            print(f\"Off-road detected: Penalty applied\")\n",
    "        if velocity > 0.1:\n",
    "            print(f\"Moving: Velocity={velocity:.2f}\")\n",
    "        \n",
    "        return obs, custom_reward, terminated, truncated, info\n",
    "\n",
    "# --- Dueling DQN Network ---\n",
    "class DuelingDQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DuelingDQN, self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        self.advantage = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.feature(x)\n",
    "        value = self.value(features)\n",
    "        advantage = self.advantage(features)\n",
    "        q_values = value + (advantage - advantage.mean(dim=1, keepdim=True))\n",
    "        return q_values\n",
    "\n",
    "# --- Replay Buffer ---\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        states, actions, rewards, next_states, dones = zip(*random.sample(self.buffer, batch_size))\n",
    "        return (np.array(states), np.array(actions), np.array(rewards),\n",
    "                np.array(next_states), np.array(dones))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "# --- Dueling DQN Agent ---\n",
    "class DuelingDQNAgent:\n",
    "    def __init__(self, input_dim, output_dim, lr=0.0003, gamma=0.98, epsilon=1.0, epsilon_min=0.01, epsilon_decay_steps=2000, buffer_size=20000, batch_size=64):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.policy_net = DuelingDQN(input_dim, output_dim).to(self.device)\n",
    "        self.target_net = DuelingDQN(input_dim, output_dim).to(self.device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        self.target_net.eval()\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=lr)\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay_steps = epsilon_decay_steps\n",
    "        self.buffer = ReplayBuffer(buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.output_dim = output_dim\n",
    "        self.step_count = 0\n",
    "        self.consecutive_brakes = 0\n",
    "        self.max_consecutive_brakes = 3\n",
    "        self.epsilon_history = []\n",
    "    \n",
    "    def select_action(self, state, greedy=False):\n",
    "        self.step_count += 1\n",
    "        if greedy:\n",
    "            epsilon = 0.0\n",
    "        else:\n",
    "            epsilon = max(self.epsilon_min, self.epsilon - (self.epsilon - self.epsilon_min) * min(self.step_count, self.epsilon_decay_steps) / self.epsilon_decay_steps)\n",
    "        self.epsilon_history.append(epsilon)\n",
    "        \n",
    "        if self.consecutive_brakes >= self.max_consecutive_brakes:\n",
    "            action = random.choice([0, 1, 2, 3])\n",
    "            self.consecutive_brakes = 0\n",
    "        elif random.random() < epsilon:\n",
    "            action = random.randrange(self.output_dim)\n",
    "        else:\n",
    "            state = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                q_values = self.policy_net(state)\n",
    "                print(f\"Q-values: {q_values.cpu().numpy()[0]}\")\n",
    "            action = q_values.argmax().item()\n",
    "        \n",
    "        if action == 4:\n",
    "            self.consecutive_brakes += 1\n",
    "        else:\n",
    "            self.consecutive_brakes = 0\n",
    "        \n",
    "        return action, epsilon  # Return epsilon for logging\n",
    "    \n",
    "    def train(self):\n",
    "        if len(self.buffer) < self.batch_size:\n",
    "            return\n",
    "        states, actions, rewards, next_states, dones = self.buffer.sample(self.batch_size)\n",
    "        \n",
    "        states = torch.FloatTensor(states).to(self.device)\n",
    "        actions = torch.LongTensor(actions).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).to(self.device)\n",
    "        next_states = torch.FloatTensor(next_states).to(self.device)\n",
    "        dones = torch.FloatTensor(dones).to(self.device)\n",
    "        \n",
    "        print(\"Training - States shape:\", states.shape)\n",
    "        \n",
    "        q_values = self.policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            next_q_values = self.target_net(next_states).max(1)[0]\n",
    "            targets = rewards + self.gamma * next_q_values * (1 - dones)\n",
    "        \n",
    "        loss = nn.MSELoss()(q_values, targets)\n",
    "        print(f\"Training - Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "    \n",
    "    def update_target(self):\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "    \n",
    "    def save_model(self, filepath=\"dueling_dqn_model.pth\"):\n",
    "        torch.save(self.policy_net.state_dict(), filepath)\n",
    "        print(f\"Model saved to {filepath}\")\n",
    "\n",
    "# --- Main Training Loop ---\n",
    "if __name__ == \"__main__\":\n",
    "    close_engine()\n",
    "    \n",
    "    # Training config (human rendering)\n",
    "    train_config = {\n",
    "        \"use_render\": True,\n",
    "        \"manual_control\": False,\n",
    "        \"traffic_density\": 0.1,\n",
    "        \"num_scenarios\": 1,\n",
    "        \"start_seed\": 42,\n",
    "        \"vehicle_config\": {\n",
    "            \"lidar\": {\"num_lasers\": 240, \"distance\": 50.0},\n",
    "            \"side_detector\": {\"num_lasers\": 0},\n",
    "            \"lane_line_detector\": {\"num_lasers\": 0}\n",
    "        },\n",
    "        \"image_observation\": False\n",
    "    }\n",
    "    \n",
    "    # GIF config (top-down view for rgb_array)\n",
    "    gif_config = {\n",
    "        \"use_render\": False,\n",
    "        \"manual_control\": False,\n",
    "        \"traffic_density\": 0.1,\n",
    "        \"num_scenarios\": 1,\n",
    "        \"start_seed\": 42,\n",
    "        \"vehicle_config\": {\n",
    "            \"lidar\": {\"num_lasers\": 240, \"distance\": 50.0},\n",
    "            \"side_detector\": {\"num_lasers\": 0},\n",
    "            \"lane_line_detector\": {\"num_lasers\": 0}\n",
    "        },\n",
    "        \"image_observation\": False,\n",
    "        \"top_down_camera_initial_x\": 0,\n",
    "        \"top_down_camera_initial_y\": 0,\n",
    "        \"top_down_camera_initial_z\": 50\n",
    "    }\n",
    "    \n",
    "    # Training environment\n",
    "    env = MetaDriveEnv(train_config)\n",
    "    env = SeedWrapper(env)\n",
    "    env = DiscreteActionWrapper(env)\n",
    "    env = CustomRewardWrapper(env)\n",
    "    \n",
    "    check_env(env)\n",
    "    print(\"Observation space:\", env.observation_space)\n",
    "    print(\"Action space:\", env.action_space)\n",
    "    \n",
    "    input_dim = env.observation_space.shape[0]\n",
    "    output_dim = env.action_space.n\n",
    "    agent = DuelingDQNAgent(input_dim, output_dim)\n",
    "    \n",
    "    num_episodes = 10  # Reduced for testing\n",
    "    max_steps = 200\n",
    "    target_update_freq = 5  # More frequent updates\n",
    "    rewards_per_episode = []\n",
    "    epsilon_history = []\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        obs, info = env.reset()\n",
    "        total_reward = 0\n",
    "        \n",
    "        print(f\"Episode {episode + 1} started\")\n",
    "        print(\"Initial observation shape:\", obs.shape)\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            action, epsilon = agent.select_action(obs)\n",
    "            epsilon_history.append(epsilon)\n",
    "            next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            \n",
    "            if action == 4:\n",
    "                print(f\"Step {step + 1}: Brake action applied! Velocity: {info.get('velocity', 0.0):.2f}\")\n",
    "            \n",
    "            done = terminated or truncated\n",
    "            agent.buffer.push(obs, action, reward, next_obs, done)\n",
    "            \n",
    "            agent.train()\n",
    "            env.render()\n",
    "            \n",
    "            print(f\"Step {step + 1}: Action: {action}, Reward: {reward:.4f}, Total Reward: {total_reward:.4f}, Epsilon: {epsilon:.3f}\")\n",
    "            \n",
    "            obs = next_obs\n",
    "            if done:\n",
    "                print(f\"Episode {episode + 1} ended early: Terminated={terminated}, Truncated={truncated}\")\n",
    "                break\n",
    "        \n",
    "        rewards_per_episode.append(total_reward)\n",
    "        print(f\"Episode {episode + 1} completed. Total Reward: {total_reward:.4f}\")\n",
    "        \n",
    "        if episode % target_update_freq == 0:\n",
    "            agent.update_target()\n",
    "            print(\"Target network updated\")\n",
    "    \n",
    "    # Save the model\n",
    "    agent.save_model(\"dueling_dqn_model.pth\")\n",
    "    \n",
    "    # Plot rewards and epsilon\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, num_episodes + 1), rewards_per_episode, label=\"Total Reward\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Total Reward\")\n",
    "    plt.title(\"Reward per Episode\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epsilon_history, label=\"Epsilon\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Epsilon\")\n",
    "    plt.title(\"Epsilon Decay\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"training_plots.png\")\n",
    "    plt.show()\n",
    "    print(\"Plots saved as 'training_plots.png'\")\n",
    "    \n",
    "    # Close training environment\n",
    "    env.close()\n",
    "    close_engine()\n",
    "    \n",
    "    # GIF creation environment\n",
    "    env = MetaDriveEnv(gif_config)\n",
    "    env = SeedWrapper(env)\n",
    "    env = DiscreteActionWrapper(env)\n",
    "    env = CustomRewardWrapper(env)\n",
    "    \n",
    "    obs, info = env.reset()\n",
    "    total_reward = 0\n",
    "    frames = []\n",
    "    print(\"Creating GIF for greedy episode...\")\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        action, _ = agent.select_action(obs, greedy=True)\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "        rgb_array = env.render()\n",
    "        if rgb_array is not None:\n",
    "            frames.append(rgb_array)\n",
    "        else:\n",
    "            print(f\"Warning: Step {step + 1} - Render returned None, frame skipped.\")\n",
    "        \n",
    "        print(f\"Greedy Step {step + 1}: Action: {action}, Reward: {reward:.4f}, Total Reward: {total_reward:.4f}\")\n",
    "        \n",
    "        obs = next_obs\n",
    "        if terminated or truncated:\n",
    "            print(f\"Greedy episode ended: Terminated={terminated}, Truncated={truncated}\")\n",
    "            break\n",
    "    \n",
    "    # Save frames as GIF\n",
    "    if frames:\n",
    "        gif_path = \"greedy_episode.gif\"\n",
    "        imageio.mimsave(gif_path, frames, fps=30)\n",
    "        print(f\"GIF saved as '{gif_path}' with {len(frames)} frames\")\n",
    "    else:\n",
    "        print(\"No frames captured, GIF not created.\")\n",
    "    \n",
    "    print(f\"Greedy episode completed. Total Reward: {total_reward:.4f}\")\n",
    "    env.close()\n",
    "    print(\"Environment closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metadrive-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
